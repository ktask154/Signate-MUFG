{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyMgiXHmF/Zmu5DsqJTpDi7Q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"0de6cbfc6fab425db3cc24f0766913aa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f18ecde8fe11437d8e8281d52018d7ff","IPY_MODEL_d0cb44d2243e41519e62a46ae669b5b1","IPY_MODEL_9c2e9be2df6f407d877d1828d5c7add6"],"layout":"IPY_MODEL_ddde238b51784abaa64a1c634017c542"}},"f18ecde8fe11437d8e8281d52018d7ff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_98d9e8c321cf403f8e69a6a43dc84f59","placeholder":"​","style":"IPY_MODEL_86ecc777af5d47d693ed6b9412a4a59c","value":""}},"d0cb44d2243e41519e62a46ae669b5b1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ea60e021f5a4789b2afa21119a8d703","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_214c67b6dbe141a1bd9f66b0da750b65","value":0}},"9c2e9be2df6f407d877d1828d5c7add6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb5a875120864ea7b7a2fa76b7e2f827","placeholder":"​","style":"IPY_MODEL_88a5d15ebc7d4694b8ac17b7ff2dca3d","value":" 0/0 [00:00&lt;?, ?it/s]"}},"ddde238b51784abaa64a1c634017c542":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98d9e8c321cf403f8e69a6a43dc84f59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86ecc777af5d47d693ed6b9412a4a59c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2ea60e021f5a4789b2afa21119a8d703":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"214c67b6dbe141a1bd9f66b0da750b65":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cb5a875120864ea7b7a2fa76b7e2f827":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88a5d15ebc7d4694b8ac17b7ff2dca3d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ytTpOEfiJnd5","executionInfo":{"status":"ok","timestamp":1663814859043,"user_tz":-540,"elapsed":19442,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"7899182d-b4ef-46fd-c999-7647ed5d690a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","source":["!pip install transformers\n","!pip install datasets\n","!pip install sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vvJnJZ3aJ028","executionInfo":{"status":"ok","timestamp":1663814880141,"user_tz":-540,"elapsed":21100,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"4d6d0a25-aa06-4ffe-d704-7513b728ebf7"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.22.1-py3-none-any.whl (4.9 MB)\n","\u001b[K     |████████████████████████████████| 4.9 MB 8.4 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 42.8 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Collecting huggingface-hub<1.0,>=0.9.0\n","  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n","\u001b[K     |████████████████████████████████| 120 kB 63.7 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.22.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.5.1-py3-none-any.whl (431 kB)\n","\u001b[K     |████████████████████████████████| 431 kB 9.8 MB/s \n","\u001b[?25hCollecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 57.0 MB/s \n","\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.9.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.12.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.8.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n","\u001b[K     |████████████████████████████████| 115 kB 43.0 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 52.0 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.2.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: urllib3, xxhash, responses, multiprocess, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed datasets-2.5.1 multiprocess-0.70.13 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 7.9 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n"]}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vzNlSn6jJ3lh","executionInfo":{"status":"ok","timestamp":1663814880141,"user_tz":-540,"elapsed":16,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"cc7861b3-5833-4832-9732-68079f5c066d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Sep 22 02:47:59 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   45C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["import os\n","import gc\n","import math\n","import time\n","import random\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.simplefilter('ignore')\n","from tqdm import tqdm\n","import re\n","import html\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim import Adam, SGD, AdamW, RAdam\n","from torch.optim import lr_scheduler\n","from torch.utils.data import DataLoader, Dataset\n","\n","from sklearn.model_selection import StratifiedKFold,StratifiedGroupKFold,GroupKFold\n","from sklearn.metrics import log_loss,f1_score\n","\n","from transformers import AutoModel, AutoConfig, AutoTokenizer, AdamW, DataCollatorWithPadding\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"g4-XpIZPJ6lb","executionInfo":{"status":"ok","timestamp":1663814886830,"user_tz":-540,"elapsed":6692,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"colab":{"base_uri":"https://localhost:8080/","height":105,"referenced_widgets":["0de6cbfc6fab425db3cc24f0766913aa","f18ecde8fe11437d8e8281d52018d7ff","d0cb44d2243e41519e62a46ae669b5b1","9c2e9be2df6f407d877d1828d5c7add6","ddde238b51784abaa64a1c634017c542","98d9e8c321cf403f8e69a6a43dc84f59","86ecc777af5d47d693ed6b9412a4a59c","2ea60e021f5a4789b2afa21119a8d703","214c67b6dbe141a1bd9f66b0da750b65","cb5a875120864ea7b7a2fa76b7e2f827","88a5d15ebc7d4694b8ac17b7ff2dca3d"]},"outputId":"899bd24a-bb8e-465c-c0ee-12c196694136"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"]},{"output_type":"stream","name":"stdout","text":["Moving 0 files to the new cache system\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0de6cbfc6fab425db3cc24f0766913aa"}},"metadata":{}}]},{"cell_type":"code","source":["DIR = '/content/drive/MyDrive/Competitions/Signate/MUFJ'\n","INPUT_DIR = os.path.join(DIR,'input')\n","OUTPUT_DIR = os.path.join(DIR,'output')\n","OUTPUT_SUB_DIR = os.path.join(OUTPUT_DIR,'submission')\n","#OUTPUT_MODEL_DIR = os.path.join(OUTPUT_DIR,'model')\n","OUTPUT_MODEL_DIR19 = DIR + '/output/model/EXP19/'\n","OUTPUT_MODEL_DIR20 = DIR + '/output/model/EXP20/'\n","OUTPUT_MODEL_DIR22 = DIR + '/output/model/EXP22/'\n","OUTPUT_MODEL_DIR23 = DIR + '/output/model/EXP23/'\n","OUTPUT_MODEL_DIR24 = DIR + '/output/model/EXP24/'\n","OUTPUT_MODEL_DIR25 = DIR + '/output/model/EXP25/'\n","OUTPUT_MODEL_DIR27 = DIR + '/output/model/EXP27/'\n","OUTPUT_MODEL_DIR28 = DIR + '/output/model/EXP28/'\n","OUTPUT_MODEL_DIR31 = DIR + '/output/model/EXP31/'\n","OUTPUT_MODEL_DIR41 = DIR + '/output/model/EXP41/'\n","OUTPUT_MODEL_DIR42 = DIR + '/output/model/EXP42/'\n","\n","OUTPUT_MODEL_DIR21 = DIR + '/output/model/EXP21/'\n","OUTPUT_MODEL_DIR43 = DIR + '/output/model/EXP43/'\n","OUTPUT_MODEL_DIR44 = DIR + '/output/model/EXP44/'\n","OUTPUT_MODEL_DIR45 = DIR + '/output/model/EXP45/'\n","OUTPUT_MODEL_DIR46 = DIR + '/output/model/EXP46/'\n","\n","OUTPUT_MODEL_DIR34 = DIR + '/output/model/EXP34/'\n","OUTPUT_MODEL_DIR39 = DIR + '/output/model/EXP39/'\n","OUTPUT_MODEL_DIR40 = DIR + '/output/model/EXP40/'\n","OUTPUT_MODEL_DIR47 = DIR + '/output/model/EXP47/'\n","OUTPUT_MODEL_DIR48 = DIR + '/output/model/EXP48/'"],"metadata":{"id":"RGGBH4TNJ-Ro","executionInfo":{"status":"ok","timestamp":1663814886831,"user_tz":-540,"elapsed":8,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["class CFG19:\n","    num_workers=4\n","    path=OUTPUT_MODEL_DIR19\n","    config_path=path+'config.pth'\n","    model=\"microsoft/deberta-v3-base\"\n","    batch_size=32\n","    fc_dropout=0.2\n","    target_size=1\n","    max_len=256\n","    seed=42\n","    n_fold=4\n","    trn_fold=[0, 1, 2, 3]\n","    gradient_checkpointing=True\n","    freezing=True\n","    clean_content = True\n","    target2col = False\n","\n","class CFG20:\n","    num_workers=4\n","    path=OUTPUT_MODEL_DIR20\n","    config_path=path+'config.pth'\n","    model=\"microsoft/deberta-v3-large\"\n","    batch_size=32\n","    fc_dropout=0.2\n","    target_size=1\n","    max_len=256\n","    seed=42\n","    n_fold=4\n","    trn_fold=[0, 1, 2, 3]\n","    gradient_checkpointing=True\n","    freezing=True\n","    clean_content = True\n","    target2col = False\n","\n","class CFG22:\n","    num_workers=4\n","    path=OUTPUT_MODEL_DIR22\n","    config_path=path+'config.pth'\n","    model=\"facebook/bart-large\"\n","    batch_size=32\n","    fc_dropout=0.2\n","    target_size=1\n","    max_len=128\n","    seed=42\n","    n_fold=4\n","    trn_fold=[0, 1, 2, 3]\n","    gradient_checkpointing=False\n","    freezing=False\n","    clean_content = True\n","    target2col = False\n","\n","class CFG23:\n","    num_workers=4\n","    path=OUTPUT_MODEL_DIR23\n","    config_path=path+'config.pth'\n","    model=\"microsoft/deberta-large\"\n","    batch_size=32\n","    fc_dropout=0.2\n","    target_size=1\n","    max_len=256\n","    seed=42\n","    n_fold=4\n","    trn_fold=[0, 1, 2, 3]\n","    gradient_checkpointing=True\n","    freezing=True\n","    clean_content = True\n","    target2col = False\n","\n","class CFG24:\n","    num_workers=4\n","    path=OUTPUT_MODEL_DIR24\n","    config_path=path+'config.pth'\n","    model=\"funnel-transformer/large\"\n","    batch_size=32\n","    fc_dropout=0.2\n","    target_size=1\n","    max_len=256\n","    seed=42\n","    n_fold=4\n","    trn_fold=[0, 1, 2, 3]\n","    gradient_checkpointing=False\n","    freezing=False\n","    clean_content = True\n","    target2col = False\n","\n","class CFG25:\n","    num_workers=4\n","    path=OUTPUT_MODEL_DIR25\n","    config_path=path+'config.pth'\n","    model=\"xlnet-large-cased\"\n","    batch_size=32\n","    fc_dropout=0.2\n","    target_size=1\n","    max_len=128\n","    seed=42\n","    n_fold=4\n","    trn_fold=[1, 2, 3]\n","    gradient_checkpointing=False\n","    freezing=False\n","    clean_content = True\n","    target2col = False\n","\n","class CFG27:\n","    num_workers=4\n","    path=OUTPUT_MODEL_DIR27\n","    config_path=path+'config.pth'\n","    model=\"microsoft/deberta-xlarge\"\n","    batch_size=32\n","    fc_dropout=0.2\n","    target_size=1\n","    max_len=256\n","    seed=42\n","    n_fold=4\n","    trn_fold=[0, 1, 2, 3]\n","    gradient_checkpointing=True\n","    freezing=True\n","    clean_content = True\n","    target2col = False\n","\n","class CFG28:\n","    num_workers=4\n","    path=OUTPUT_MODEL_DIR28\n","    config_path=path+'config.pth'\n","    model=\"microsoft/deberta-base\"\n","    batch_size=32\n","    fc_dropout=0.2\n","    target_size=1\n","    max_len=256\n","    seed=42\n","    n_fold=4\n","    trn_fold=[0, 1, 2, 3]\n","    gradient_checkpointing=True\n","    freezing=True\n","    clean_content = True\n","    target2col = False\n","\n","class CFG31:\n","    num_workers=4\n","    path=OUTPUT_MODEL_DIR31\n","    config_path=path+'config.pth'\n","    model=\"funnel-transformer/medium\"\n","    batch_size=32\n","    fc_dropout=0.2\n","    target_size=1\n","    max_len=256\n","    seed=42\n","    n_fold=4\n","    trn_fold=[0, 1, 2, 3]\n","    gradient_checkpointing=False\n","    freezing=False\n","    clean_content = True\n","    target2col = False\n","\n","class CFG41:\n","    num_workers=4\n","    path=OUTPUT_MODEL_DIR41\n","    config_path=path+'config.pth'\n","    model=\"facebook/bart-base\"\n","    batch_size=32\n","    fc_dropout=0.2\n","    target_size=1\n","    max_len=256\n","    seed=42\n","    n_fold=4\n","    trn_fold=[0, 1, 2, 3]\n","    gradient_checkpointing=False\n","    freezing=False\n","    clean_content = True\n","    target2col = False\n","\n","class CFG42:\n","    num_workers=4\n","    path=OUTPUT_MODEL_DIR42\n","    config_path=path+'config.pth'\n","    model=\"facebook/bart-large-mnli\"\n","    batch_size=32\n","    fc_dropout=0.2\n","    target_size=1\n","    max_len=180\n","    seed=42\n","    n_fold=4\n","    trn_fold=[0, 1, 2, 3]\n","    gradient_checkpointing=False\n","    freezing=False\n","    clean_content = True\n","    target2col = False\n","\n","\n","class CFG21:\n","    num_workers=4\n","    path=OUTPUT_MODEL_DIR21\n","    config_path=path+'config.pth'\n","    model=\"microsoft/deberta-v3-base\"\n","    batch_size=32\n","    fc_dropout=0.2\n","    target_size=1\n","    max_len=256\n","    seed=42\n","    n_fold=4\n","    trn_fold=[0, 1, 2, 3]\n","    gradient_checkpointing=True\n","    freezing=True\n","    clean_content = True\n","    target2col = False\n","\n","class CFG43:\n","    num_workers=4\n","    path=OUTPUT_MODEL_DIR43\n","    config_path=path+'config.pth'\n","    model=\"funnel-transformer/large\"\n","    batch_size=32\n","    fc_dropout=0.2\n","    target_size=1\n","    max_len=256\n","    seed=42\n","    n_fold=4\n","    trn_fold=[0, 1, 2, 3]\n","    gradient_checkpointing=False\n","    freezing=False\n","    clean_content = False\n","    target2col = False\n","\n","class CFG44:\n","    num_workers=4\n","    path=OUTPUT_MODEL_DIR44\n","    config_path=path+'config.pth'\n","    model=\"microsoft/deberta-v3-large\"\n","    batch_size=32\n","    fc_dropout=0.2\n","    target_size=1\n","    max_len=256\n","    seed=42\n","    n_fold=4\n","    trn_fold=[0, 1, 2, 3]\n","    gradient_checkpointing=False\n","    freezing=True\n","    clean_content = True\n","    target2col = False\n","\n","class CFG45:\n","    num_workers=4\n","    path=OUTPUT_MODEL_DIR45\n","    config_path=path+'config.pth'\n","    model=\"facebook/bart-large-mnli\"\n","    batch_size=32\n","    fc_dropout=0.2\n","    target_size=1\n","    max_len=180\n","    seed=42\n","    n_fold=4\n","    trn_fold=[0, 1, 2, 3]\n","    gradient_checkpointing=False\n","    freezing=False\n","    clean_content = False\n","    target2col = False\n","\n","class CFG46:\n","    num_workers=4\n","    path=OUTPUT_MODEL_DIR46\n","    config_path=path+'config.pth'\n","    model=\"microsoft/deberta-base\"\n","    batch_size=32\n","    fc_dropout=0.2\n","    target_size=1\n","    max_len=256\n","    seed=42\n","    n_fold=4\n","    trn_fold=[0, 1, 2, 3]\n","    gradient_checkpointing=True\n","    freezing=True\n","    clean_content = True\n","    target2col = False\n","\n","\n","class CFG34:\n","    num_workers=4\n","    path=OUTPUT_MODEL_DIR34\n","    config_path=path+'config.pth'\n","    model=\"microsoft/deberta-v3-base\"\n","    batch_size=32\n","    fc_dropout=0.2\n","    target_size=2\n","    max_len=256\n","    seed=42\n","    n_fold=4\n","    trn_fold=[0, 1, 2, 3]\n","    gradient_checkpointing=True\n","    freezing=True\n","    clean_content = True\n","    target_cols = [\"state\",\"category1\"]\n","    target2col = True\n","\n","class CFG39:\n","    num_workers=4\n","    path=OUTPUT_MODEL_DIR39\n","    config_path=path+'config.pth'\n","    model=\"microsoft/deberta-v3-large\"\n","    batch_size=32\n","    fc_dropout=0.2\n","    target_size=2\n","    max_len=256\n","    seed=42\n","    n_fold=4\n","    trn_fold=[0, 1, 2, 3]\n","    gradient_checkpointing=True\n","    freezing=True\n","    clean_content = True\n","    target_cols = [\"state\",\"category1\"]\n","    target2col = True\n","\n","class CFG40:\n","    num_workers=4\n","    path=OUTPUT_MODEL_DIR40\n","    config_path=path+'config.pth'\n","    model=\"microsoft/deberta-xlarge\"\n","    batch_size=32\n","    fc_dropout=0.2\n","    target_size=2\n","    max_len=256\n","    seed=42\n","    n_fold=4\n","    trn_fold=[0, 1, 2, 3]\n","    gradient_checkpointing=True\n","    freezing=True\n","    clean_content = True\n","    target_cols = [\"state\",\"category1\"]\n","    target2col = True\n","\n","class CFG47:\n","    num_workers=4\n","    path=OUTPUT_MODEL_DIR47\n","    config_path=path+'config.pth'\n","    model=\"funnel-transformer/large\"\n","    batch_size=32\n","    fc_dropout=0.2\n","    target_size=2\n","    max_len=256\n","    seed=42\n","    n_fold=4\n","    trn_fold=[0, 1, 2, 3]\n","    gradient_checkpointing=False\n","    freezing=False\n","    clean_content = True\n","    target_cols = [\"state\",\"category1\"]\n","    target2col = True\n","\n","class CFG48:\n","    num_workers=4\n","    path=OUTPUT_MODEL_DIR48\n","    config_path=path+'config.pth'\n","    model=\"facebook/bart-large-mnli\"\n","    batch_size=32\n","    fc_dropout=0.2\n","    target_size=2\n","    max_len=180\n","    seed=42\n","    n_fold=4\n","    trn_fold=[1, 2, 3]\n","    gradient_checkpointing=False\n","    freezing=False\n","    clean_content = True\n","    target_cols = [\"state\",\"category1\"]\n","    target2col = True"],"metadata":{"id":"YR4j4hxxKLo_","executionInfo":{"status":"ok","timestamp":1663814886831,"user_tz":-540,"elapsed":8,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def get_score(labels, outputs):\n","    thresh = 0.5\n","    y_pred = outputs\n","    y_true = labels\n","    return f1_score(y_true, (y_pred>thresh).astype(int))\n","\n","\n","def get_logger(filename=OUTPUT_DIR+'/infrence'):\n","    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","def seed_everything(seed=CFG25.seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(seed=CFG25.seed)"],"metadata":{"id":"Kxfj00EuK4kL","executionInfo":{"status":"ok","timestamp":1663814887570,"user_tz":-540,"elapsed":746,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def freeze(module):\n","    \"\"\"\n","    Freezes module's parameters.\n","    \"\"\"\n","    \n","    for parameter in module.parameters():\n","        parameter.requires_grad = False\n","        \n","def get_freezed_parameters(module):\n","    \"\"\"\n","    Returns names of freezed parameters of the given module.\n","    \"\"\"\n","    \n","    freezed_parameters = []\n","    for name, parameter in module.named_parameters():\n","        if not parameter.requires_grad:\n","            freezed_parameters.append(name)\n","            \n","    return freezed_parameters\n","\n","def set_embedding_parameters_bits(embeddings_path, optim_bits=32):\n","    \"\"\"\n","    https://github.com/huggingface/transformers/issues/14819#issuecomment-1003427930\n","    \"\"\"\n","    \n","    embedding_types = (\"word\", \"position\", \"token_type\")\n","    for embedding_type in embedding_types:\n","        attr_name = f\"{embedding_type}_embeddings\"\n","        \n","        if hasattr(embeddings_path, attr_name): \n","            bnb.optim.GlobalOptimManager.get_instance().register_module_override(\n","                getattr(embeddings_path, attr_name), 'weight', {'optim_bits': optim_bits}\n","            )"],"metadata":{"id":"yj8DrnllLRqs","executionInfo":{"status":"ok","timestamp":1663814887571,"user_tz":-540,"elapsed":3,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["oof_19 = pd.read_pickle(CFG19.path+'oof_df.pkl')\n","oof_20 = pd.read_pickle(CFG20.path+'oof_df.pkl')\n","oof_22 = pd.read_pickle(CFG22.path+'oof_df.pkl')\n","oof_23 = pd.read_pickle(CFG23.path+'oof_df.pkl')\n","oof_24 = pd.read_pickle(CFG24.path+'oof_df.pkl')\n","oof_25 = pd.read_pickle(CFG25.path+'oof_df.pkl')\n","oof_27 = pd.read_pickle(CFG27.path+'oof_df.pkl')\n","oof_28 = pd.read_pickle(CFG28.path+'oof_df.pkl')\n","oof_31 = pd.read_pickle(CFG31.path+'oof_df.pkl')\n","oof_41 = pd.read_pickle(CFG41.path+'oof_df.pkl')\n","oof_42 = pd.read_pickle(CFG42.path+'oof_df.pkl')\n","\n","oof_21 = pd.read_pickle(CFG21.path+'oof_df.pkl')\n","oof_43 = pd.read_pickle(CFG43.path+'oof_df.pkl')\n","oof_44 = pd.read_pickle(CFG44.path+'oof_df.pkl')\n","oof_45 = pd.read_pickle(CFG45.path+'oof_df.pkl')\n","oof_46 = pd.read_pickle(CFG46.path+'oof_df.pkl')\n","\n","oof_34 = pd.read_pickle(CFG34.path+'oof_df.pkl')\n","oof_39 = pd.read_pickle(CFG39.path+'oof_df.pkl')\n","oof_40 = pd.read_pickle(CFG40.path+'oof_df.pkl')\n","oof_47 = pd.read_pickle(CFG47.path+'oof_df.pkl')\n","oof_48 = pd.read_pickle(CFG48.path+'oof_df.pkl')"],"metadata":{"id":"4CuyEeG7K5K0","executionInfo":{"status":"ok","timestamp":1663814904841,"user_tz":-540,"elapsed":17272,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["labels = oof_25['state'].values\n","\n","preds_19 = oof_19['pred'].values\n","preds_20 = oof_20['pred'].values\n","preds_22 = oof_22['pred'].values\n","preds_23 = oof_23['pred'].values\n","preds_24 = oof_24['pred'].values\n","preds_25 = oof_25['pred'].values\n","preds_27 = oof_27['pred'].values\n","preds_28 = oof_28['pred'].values\n","preds_31 = oof_31['pred'].values\n","preds_41 = oof_41['pred'].values\n","preds_42 = oof_42['pred'].values\n","\n","preds_21 = oof_21['pred'].values\n","preds_43 = oof_43['pred'].values\n","preds_44 = oof_44['pred'].values\n","preds_45 = oof_45['pred'].values\n","preds_46 = oof_46['pred'].values\n","\n","preds_34 = oof_34[\"pred_state\"].values\n","preds_39 = oof_39[\"pred_state\"].values\n","preds_40 = oof_40[\"pred_state\"].values\n","preds_47 = oof_47[\"pred_state\"].values\n","preds_48 = oof_48[\"pred_state\"].values\n","\n","preds_all = preds_19*0.06470878 + preds_20*0.0131939 + preds_22*0.06180668 +preds_23*0.05055884 + preds_24*0.02008916 + preds_25*0.06263664 + preds_27*0.08175019 + preds_28*0.03084266 + preds_31*0.03858474 + preds_41*0.02707047 + preds_42*0.08370543 + preds_21*0.07534494 + preds_43*0.08425437 + preds_44*0.07985377 + preds_45*0.08337871 + preds_46*0.01404711 + preds_34*0.02728774 + preds_39*0.00701513 + preds_40*0.03316138 + preds_47*0.02549253 + preds_48*0.03521683\n","\n","\n","preds1 = (preds_25+preds_28) / 2  #0.8071\n","preds2 = (preds_22+preds_23+preds_24+preds_31+preds1+preds_41) / 6  #0.8228\n","preds3 = (preds_19+preds_20+preds_27+preds_42) / 4  #0.8240\n","\n","preds4 = preds_21*.35+preds_43*.35+preds_46*.3   #0.8213\n","preds5 = (preds_45+preds_44) / 2\n","\n","preds6 = (preds_40+preds_47+preds_48) / 3  #0.8213  #0.8215\n","preds7 = preds_34*.5+preds_39*.5  #0.8207\n","\n","preds_com = preds2*0.04754912 + preds3*0.04911001 + preds4*0.37500948 + preds5*0.37216546 + preds6*0.01848971 + preds7*0.13767623\n","\n","\n","preds_805 = preds_19*0.03209519 + preds_20*0.00845168 + preds_22*0.12410198 + preds_23*0.00022835 + preds_24*0.05227489 + preds_27*0.10028456 + preds_31*0.00259968 + preds_42*0.01994933 + preds_21*0.11993072 + preds_43*0.0957319 + preds_44*0.09343536 + preds_45*0.11866233 + preds_34*0.05481453 + preds_39*0.05538527 + preds_40*0.10995686 + preds_47*0.0027024 + preds_48*0.00939497\n","\n","preds_810 = preds_19*0.03682987 + preds_20*0.0061083 + preds_27*0.11077566 + preds_42*0.10054404 + preds_44*0.16015766 + preds_45*0.03514027 + preds_34*0.12992343 + preds_39*0.15352078 + preds_40*0.12774139 + preds_48*0.13925859\n","\n","score1 = get_score(labels, preds_all)\n","score2 = get_score(labels, preds_com)\n","score3 = get_score(labels, preds_805)\n","score4 = get_score(labels, preds_810)\n","LOGGER.info(f'CV all Score: {score1:<.4f}')\n","LOGGER.info(f'CV combine Score: {score2:<.4f}')\n","LOGGER.info(f'CV oof>.805 Score: {score3:<.4f}')\n","LOGGER.info(f'CV oof>.810 Score: {score4:<.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oXzizdz8LE4T","executionInfo":{"status":"ok","timestamp":1663814905248,"user_tz":-540,"elapsed":418,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"50158017-3351-4a01-9255-3176389f490b"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["CV all Score: 0.8320\n","INFO:__main__:CV all Score: 0.8320\n","CV combine Score: 0.8311\n","INFO:__main__:CV combine Score: 0.8311\n","CV oof>.805 Score: 0.8310\n","INFO:__main__:CV oof>.805 Score: 0.8310\n","CV oof>.810 Score: 0.8315\n","INFO:__main__:CV oof>.810 Score: 0.8315\n"]}]},{"cell_type":"code","source":["best_score_all = 0\n","best_thresh_all = 0.5\n","y_pred_all = preds_all\n","y_true = labels\n","for thresh in np.arange(0.2, 0.801, 0.01):\n","    thresh = np.round(thresh, 2)\n","    score = f1_score(y_true, (y_pred_all>thresh).astype(int))\n","    #print(\"F1 score at threshold {0} is {1}\".format(thresh, score))\n","    if score > best_score_all:\n","        best_score_all = score\n","        best_thresh_all = thresh\n","print(\"All Pred best F1 score at threshold {0} is {1}\".format(best_thresh_all, f1_score(y_true, (y_pred_all>best_thresh_all).astype(int))))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zKBb-vgIeSlL","executionInfo":{"status":"ok","timestamp":1663814905917,"user_tz":-540,"elapsed":671,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"1797f4e5-4610-4d08-f9f3-14091d18a837"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["All Pred best F1 score at threshold 0.5 is 0.8319967923015238\n"]}]},{"cell_type":"code","source":["best_score_com = 0\n","best_thresh_com = 0.5\n","y_pred_com = preds_com\n","y_true = labels\n","for thresh in np.arange(0.2, 0.801, 0.01):\n","    thresh = np.round(thresh, 2)\n","    score = f1_score(y_true, (y_pred_com>thresh).astype(int))\n","    #print(\"F1 score at threshold {0} is {1}\".format(thresh, score))\n","    if score > best_score_com:\n","        best_score_com = score\n","        best_thresh_com = thresh\n","print(\"Pred Combine best F1 score at threshold {0} is {1}\".format(best_thresh_com, f1_score(y_true, (y_pred_com>best_thresh_com).astype(int))))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9u3yyIozelGT","executionInfo":{"status":"ok","timestamp":1663814906523,"user_tz":-540,"elapsed":610,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"a0c4eb9c-d549-40bf-8a68-b6d9032f2553"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Pred Combine best F1 score at threshold 0.5 is 0.831077694235589\n"]}]},{"cell_type":"code","source":["best_score_805 = 0\n","best_thresh_805 = 0.5\n","y_pred_805 = preds_805\n","y_true = labels\n","for thresh in np.arange(0.2, 0.801, 0.01):\n","    thresh = np.round(thresh, 2)\n","    score = f1_score(y_true, (y_pred_805>thresh).astype(int))\n","    #print(\"F1 score at threshold {0} is {1}\".format(thresh, score))\n","    if score > best_score_805:\n","        best_score_805 = score\n","        best_thresh_805 = thresh\n","print(\"oof>0.805 Pred best F1 score at threshold {0} is {1}\".format(best_thresh_805, f1_score(y_true, (y_pred_805>best_thresh_805).astype(int))))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7D01lUCsel5y","executionInfo":{"status":"ok","timestamp":1663814906523,"user_tz":-540,"elapsed":12,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"fdf121b2-8a04-4eeb-c806-cb06076fe42c"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["oof>0.805 Pred best F1 score at threshold 0.5 is 0.8310099287935011\n"]}]},{"cell_type":"code","source":["best_score_810 = 0\n","best_thresh_810 = 0.5\n","y_pred_810 = preds_810\n","y_true = labels\n","for thresh in np.arange(0.2, 0.801, 0.01):\n","    thresh = np.round(thresh, 2)\n","    score = f1_score(y_true, (y_pred_810>thresh).astype(int))\n","    #print(\"F1 score at threshold {0} is {1}\".format(thresh, score))\n","    if score > best_score_810:\n","        best_score_810 = score\n","        best_thresh_810 = thresh\n","print(\"oof>0.805 Pred best F1 score at threshold {0} is {1}\".format(best_thresh_810, f1_score(y_true, (y_pred_810>best_thresh_810).astype(int))))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4RUe3FVJeoEE","executionInfo":{"status":"ok","timestamp":1663814906993,"user_tz":-540,"elapsed":471,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"9b4bb9bf-4b2f-4adb-ce01-cfc1d813548d"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["oof>0.805 Pred best F1 score at threshold 0.5 is 0.8315239244069159\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"AEKGIwXQfRWo","executionInfo":{"status":"ok","timestamp":1663814906993,"user_tz":-540,"elapsed":3,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["#best score: 0.8319967923015238\n","#best weight: [0.06470878 0.0131939  0.06180668 0.05055884 0.02008916 0.06263664\n","# 0.08175019 0.03084266 0.03858474 0.02707047 0.08370543 0.07534494\n","# 0.08425437 0.07985377 0.08337871 0.01404711 0.02728774 0.00701513\n","# 0.03316138 0.02549253 0.03521683]\n","\n","#best score: 0.831077694235589\n","#best weight: [0.04754912 0.04911001 0.37500948 0.37216546 0.01848971 0.13767623]\n","\n","# oof > 0.805\n","#best score: 0.8310099287935011\n","#best weight: [0.03209519 0.00845168 0.12410198 0.00022835 0.05227489 0.10028456\n","# 0.00259968 0.01994933 0.11993072 0.0957319  0.09343536 0.11866233\n","# 0.05481453 0.05538527 0.10995686 0.0027024  0.00939497]\n","\n","# oof > 0.810\n","#best score: 0.8315239244069159\n","#best weight: [0.03682987 0.0061083  0.11077566 0.10054404 0.16015766 0.03514027\n","# 0.12992343 0.15352078 0.12774139 0.13925859]"],"metadata":{"id":"HBwOU8eOa2k8","executionInfo":{"status":"ok","timestamp":1663814906994,"user_tz":-540,"elapsed":3,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["test = pd.read_csv(os.path.join(INPUT_DIR,'test.csv'))\n","sub = pd.read_csv(os.path.join(INPUT_DIR,'sample_submit.csv'),header=None)\n","sub.columns = ['id','state']"],"metadata":{"id":"62JPhXXvLTVJ","executionInfo":{"status":"ok","timestamp":1663814910716,"user_tz":-540,"elapsed":3724,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def remove_URL(text):\n","    url = re.compile(r'https?://\\S+|www\\.\\S+')\n","    return url.sub('',text)\n","\n","def remove_html(text):\n","    html=re.compile(r\"<[^>]*?>\")\n","    return html.sub('',text)\n","\n","def cleaning(texts):\n","    clean_texts = []\n","    for text in texts:\n","        # htmlタグを削除\n","        text = remove_URL(text)\n","        text = remove_html(text)\n","        #アルファベット以外をスペースに置き換え\n","        #clean_punc = re.sub(r'[^a-zA-Z]', ' ', text)\n","        #改行削除\n","        #text = text.replace(\"\\n\",\"\")\n","        clean_texts.append(text)\n","    return clean_texts\n","\n","def get_goal_values(df):\n","  df[\"goal\"].replace(\"100000+\",\"100000-100000\",inplace=True)\n","  _df = df[\"goal\"].str.split('-').apply(pd.Series).astype(float)\n","  _df.columns = [\"goal_max\",\"goal_min\"]\n","  df[\"goal_max\"] = _df[\"goal_max\"].astype(str)\n","  df[\"goal_min\"] = _df[\"goal_min\"].astype(str)\n","  df[\"goal_median\"] = _df[[\"goal_max\",\"goal_min\"]].median(axis=1)\n","  df[\"goal_median\"] = df[\"goal_median\"].astype(int)\n","  return df\n","\n","if CFG25.clean_content==True:\n","    test['html_content'] = test['html_content'].map(lambda x: str(x))\n","    test['html_content'] = test['html_content'].apply(html.unescape)\n","    p = re.compile(r\"<[^>]*?>|&amp;|[/'’\\\"”]\")\n","    test['html_content'] = test['html_content'].map(lambda x: p.sub(\"\", x))\n","    test['html_content'] = test['html_content'].map(lambda x: x.lstrip())\n","    test['html_content'] = test['html_content'].fillna('missing')\n","\n","test = get_goal_values(test)\n","test['inputs1'] = test.goal_median.astype(str) + ' [SEP] ' + test.duration.astype(str) + ' [SEP] ' + test.country + ' [SEP] ' + test.category1 + ' [SEP] ' + test.category2 + ' [SEP] ' + test.html_content\n","test['inputs2'] = test.goal_median.astype(str) + ' [SEP] ' + test.duration.astype(str) + ' [SEP] ' + test.country + ' [SEP] ' + test.category2 + ' [SEP] ' + test.html_content"],"metadata":{"id":"YkymMaYHLZsI","executionInfo":{"status":"ok","timestamp":1663814912900,"user_tz":-540,"elapsed":2195,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# tokenizer\n","# ====================================================\n","CFG19.tokenizer = AutoTokenizer.from_pretrained(CFG19.path+'tokenizer/')\n","CFG20.tokenizer = AutoTokenizer.from_pretrained(CFG20.path+'tokenizer/')\n","CFG22.tokenizer = AutoTokenizer.from_pretrained(CFG22.path+'tokenizer/')\n","CFG23.tokenizer = AutoTokenizer.from_pretrained(CFG23.path+'tokenizer/')\n","CFG24.tokenizer = AutoTokenizer.from_pretrained(CFG24.path+'tokenizer/')\n","CFG25.tokenizer = AutoTokenizer.from_pretrained(CFG25.path+'tokenizer/')\n","CFG27.tokenizer = AutoTokenizer.from_pretrained(CFG27.path+'tokenizer/')\n","CFG28.tokenizer = AutoTokenizer.from_pretrained(CFG28.path+'tokenizer/')\n","CFG31.tokenizer = AutoTokenizer.from_pretrained(CFG31.path+'tokenizer/')\n","CFG41.tokenizer = AutoTokenizer.from_pretrained(CFG41.path+'tokenizer/')\n","CFG42.tokenizer = AutoTokenizer.from_pretrained(CFG42.path+'tokenizer/')\n","\n","CFG21.tokenizer = AutoTokenizer.from_pretrained(CFG21.path+'tokenizer/')\n","CFG43.tokenizer = AutoTokenizer.from_pretrained(CFG43.path+'tokenizer/')\n","CFG44.tokenizer = AutoTokenizer.from_pretrained(CFG44.path+'tokenizer/')\n","CFG45.tokenizer = AutoTokenizer.from_pretrained(CFG45.path+'tokenizer/')\n","CFG46.tokenizer = AutoTokenizer.from_pretrained(CFG46.path+'tokenizer/')\n","\n","CFG34.tokenizer = AutoTokenizer.from_pretrained(CFG34.path+'tokenizer/')\n","CFG39.tokenizer = AutoTokenizer.from_pretrained(CFG39.path+'tokenizer/')\n","CFG40.tokenizer = AutoTokenizer.from_pretrained(CFG40.path+'tokenizer/')\n","CFG47.tokenizer = AutoTokenizer.from_pretrained(CFG47.path+'tokenizer/')\n","CFG48.tokenizer = AutoTokenizer.from_pretrained(CFG48.path+'tokenizer/')"],"metadata":{"id":"vmSV1K_mL2jm","executionInfo":{"status":"ok","timestamp":1663814941595,"user_tz":-540,"elapsed":28698,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Dataset\n","# ====================================================\n","def prepare_input(cfg, text):\n","    inputs = cfg.tokenizer(text,\n","                           add_special_tokens=True,\n","                           max_length=cfg.max_len,\n","                           padding=\"max_length\",\n","                           return_offsets_mapping=False,\n","                           truncation=True)\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","    return inputs\n","\n","\n","class TestDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        if cfg.target2col:\n","          self.inputs = df['inputs2'].values\n","        else:\n","          self.inputs = df['inputs1'].values\n","\n","    def __len__(self):\n","        return len(self.inputs)\n","\n","    def __getitem__(self, item):\n","        inputs = prepare_input(self.cfg, self.inputs[item])\n","        return inputs"],"metadata":{"id":"-BbCJR03MAsf","executionInfo":{"status":"ok","timestamp":1663814941596,"user_tz":-540,"elapsed":13,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Model\n","# ====================================================\n","class MeanPooling(nn.Module):\n","    def __init__(self):\n","        super(MeanPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        mean_embeddings = sum_embeddings / sum_mask\n","        return mean_embeddings\n","\n","class MaxPooling(nn.Module):\n","    def __init__(self):\n","        super(MaxPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        embeddings = last_hidden_state.clone()\n","        embeddings[input_mask_expanded == 0] = -1e4\n","        max_embeddings, _ = torch.max(embeddings, dim=1)\n","        return max_embeddings\n","    \n","\n","class CustomModel1(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","            self.config.hidden_dropout = 0.\n","            self.config.hidden_dropout_prob = 0.\n","            self.config.attention_dropout = 0.\n","            self.config.attention_probs_dropout_prob = 0.\n","            LOGGER.info(self.config)\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel.from_config(self.config)\n","        if self.cfg.gradient_checkpointing:\n","            self.model.gradient_checkpointing_enable()\n","\n","        # Freezing\n","        if cfg.freezing:\n","            # freezing embeddings and first 2 layers of encoder\n","            freeze((self.model).embeddings)\n","            freeze((self.model).encoder.layer[:2])\n","            cfg.after_freezed_parameters = filter(lambda parameter: parameter.requires_grad, (self.model).parameters())\n","\n","        self.pool = MeanPooling()\n","        self.fc = nn.Linear(self.config.hidden_size, cfg.target_size)\n","        self._init_weights(self.fc)\n","        \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","        \n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs[0]\n","        feature = self.pool(last_hidden_states, inputs['attention_mask'])\n","        return feature\n","\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","        output = self.fc(feature)\n","        return output\n","\n","\n","class CustomModel2(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","            self.config.hidden_dropout = 0.\n","            self.config.hidden_dropout_prob = 0.\n","            self.config.attention_dropout = 0.\n","            self.config.attention_probs_dropout_prob = 0.\n","            LOGGER.info(self.config)\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel.from_config(self.config)\n","        if self.cfg.gradient_checkpointing:\n","            self.model.gradient_checkpointing_enable()\n","\n","        # Freezing\n","        if cfg.freezing:\n","            # freezing embeddings and first 2 layers of encoder\n","            freeze((self.model).embeddings)\n","            freeze((self.model).encoder.layer[:2])\n","            cfg.after_freezed_parameters = filter(lambda parameter: parameter.requires_grad, (self.model).parameters())\n","\n","        self.pool = MeanPooling()\n","        self.fc = nn.Linear(self.config.hidden_size, cfg.target_size)\n","        #self._init_weights(self.fc)\n","        \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","        \n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs[0]\n","        feature = self.pool(last_hidden_states, inputs['attention_mask'])\n","        return feature\n","\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","        output = self.fc(feature)\n","        return output\n","\n","class CustomModel3(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","            self.config.hidden_dropout = 0.\n","            self.config.hidden_dropout_prob = 0.\n","            self.config.attention_dropout = 0.\n","            self.config.attention_probs_dropout_prob = 0.\n","            LOGGER.info(self.config)\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel.from_config(self.config)\n","        if self.cfg.gradient_checkpointing:\n","            self.model.gradient_checkpointing_enable()\n","\n","        # Freezing\n","        if cfg.freezing:\n","            # freezing embeddings and first 2 layers of encoder\n","            freeze((self.model).embeddings)\n","            freeze((self.model).encoder.layer[:2])\n","            cfg.after_freezed_parameters = filter(lambda parameter: parameter.requires_grad, (self.model).parameters())\n","\n","        #self.pool = MeanPooling()\n","        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n","        self.fc = nn.Linear(self.config.hidden_size, cfg.target_size)\n","        self._init_weights(self.fc)\n","        self.attention = nn.Sequential(\n","            nn.Linear(self.config.hidden_size, 512),\n","            nn.Tanh(),\n","            nn.Linear(512, 1),\n","            nn.Softmax(dim=1)\n","        )\n","        self._init_weights(self.attention)\n","        \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","        \n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs[0]\n","        weights = self.attention(last_hidden_states)\n","        feature = torch.sum(weights * last_hidden_states, dim=1)\n","        return feature\n","\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","        output = self.fc(self.fc_dropout(feature))\n","        return output\n","\n","class CustomModel4(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","            self.config.hidden_dropout = 0.\n","            self.config.hidden_dropout_prob = 0.\n","            self.config.attention_dropout = 0.\n","            self.config.attention_probs_dropout_prob = 0.\n","            LOGGER.info(self.config)\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel.from_config(self.config)\n","        if self.cfg.gradient_checkpointing:\n","            self.model.gradient_checkpointing_enable()\n","\n","        # Freezing\n","        if cfg.freezing:\n","            # freezing embeddings and first 2 layers of encoder\n","            freeze((self.model).embeddings)\n","            freeze((self.model).encoder.layer[:2])\n","            cfg.after_freezed_parameters = filter(lambda parameter: parameter.requires_grad, (self.model).parameters())\n","\n","        #self.pool = MeanPooling()\n","        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n","        self.fc = nn.Linear(self.config.hidden_size, cfg.target_size)\n","        #self._init_weights(self.fc)\n","        self.attention = nn.Sequential(\n","            nn.Linear(self.config.hidden_size, 512),\n","            nn.Tanh(),\n","            nn.Linear(512, 1),\n","            nn.Softmax(dim=1)\n","        )\n","        #self._init_weights(self.attention)\n","        \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","        \n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs[0]\n","        weights = self.attention(last_hidden_states)\n","        feature = torch.sum(weights * last_hidden_states, dim=1)\n","        return feature\n","\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","        output = self.fc(self.fc_dropout(feature))\n","        return output"],"metadata":{"id":"5nujVXC2MIRJ","executionInfo":{"status":"ok","timestamp":1663814941596,"user_tz":-540,"elapsed":12,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# inference\n","# ====================================================\n","def inference_fn(test_loader, model, device):\n","    preds = []\n","    model.eval()\n","    model.to(device)\n","    tk0 = tqdm(test_loader, total=len(test_loader))\n","    for inputs in tk0:\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","    predictions = np.concatenate(preds)\n","    return predictions"],"metadata":{"id":"Ab9Z1BxbMMXd","executionInfo":{"status":"ok","timestamp":1663814941597,"user_tz":-540,"elapsed":13,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["test_dataset19 = TestDataset(CFG19, test)\n","test_loader19 = DataLoader(test_dataset19,\n","                         batch_size=CFG19.batch_size,\n","                         shuffle=False,\n","                         num_workers=CFG19.num_workers, pin_memory=True, drop_last=False)\n","predictions_19 = []\n","for fold in CFG19.trn_fold:\n","    model = CustomModel1(CFG19, config_path=CFG19.config_path, pretrained=False)\n","    state = torch.load(CFG19.path+f\"{CFG19.model.replace('/', '-')}_fold{fold}_best.pth\",\n","                       map_location=torch.device('cpu'))\n","    model.load_state_dict(state['model'])\n","    prediction = inference_fn(test_loader19, model, device)\n","    predictions_19.append(prediction)\n","    del model, state, prediction; gc.collect()\n","    torch.cuda.empty_cache()\n","predictions_19 = np.mean(predictions_19, axis=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UZP9ZlwvPblm","executionInfo":{"status":"ok","timestamp":1663815409079,"user_tz":-540,"elapsed":467495,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"1f2059ce-ace3-4252-cc3b-d7d12ffc962d"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 307/307 [01:47<00:00,  2.86it/s]\n","100%|██████████| 307/307 [01:43<00:00,  2.97it/s]\n","100%|██████████| 307/307 [01:43<00:00,  2.98it/s]\n","100%|██████████| 307/307 [01:43<00:00,  2.97it/s]\n"]}]},{"cell_type":"code","source":["test_dataset20 = TestDataset(CFG20, test)\n","test_loader20 = DataLoader(test_dataset20,\n","                         batch_size=CFG20.batch_size,\n","                         shuffle=False,\n","                         num_workers=CFG20.num_workers, pin_memory=True, drop_last=False)\n","predictions_20 = []\n","for fold in CFG20.trn_fold:\n","    model = CustomModel1(CFG20, config_path=CFG20.config_path, pretrained=False)\n","    state = torch.load(CFG20.path+f\"{CFG20.model.replace('/', '-')}_fold{fold}_best.pth\",\n","                       map_location=torch.device('cpu'))\n","    model.load_state_dict(state['model'])\n","    prediction = inference_fn(test_loader20, model, device)\n","    predictions_20.append(prediction)\n","    del model, state, prediction; gc.collect()\n","    torch.cuda.empty_cache()\n","predictions_20 = np.mean(predictions_20, axis=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EyYuKmw6PzPB","executionInfo":{"status":"ok","timestamp":1663816765415,"user_tz":-540,"elapsed":1356349,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"00cacb28-c2ad-4ffd-daef-557b5e0fb3a6"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 307/307 [05:15<00:00,  1.03s/it]\n","100%|██████████| 307/307 [05:14<00:00,  1.02s/it]\n","100%|██████████| 307/307 [05:14<00:00,  1.02s/it]\n","100%|██████████| 307/307 [05:14<00:00,  1.02s/it]\n"]}]},{"cell_type":"code","source":["\"\"\"\n","test_dataset22 = TestDataset(CFG22, test)\n","test_loader22 = DataLoader(test_dataset22,\n","                         batch_size=CFG22.batch_size,\n","                         shuffle=False,\n","                         num_workers=CFG22.num_workers, pin_memory=True, drop_last=False)\n","predictions_22 = []\n","for fold in CFG22.trn_fold:\n","    model = CustomModel2(CFG22, config_path=CFG22.config_path, pretrained=False)\n","    state = torch.load(CFG22.path+f\"{CFG22.model.replace('/', '-')}_fold{fold}_best.pth\",\n","                       map_location=torch.device('cpu'))\n","    model.load_state_dict(state['model'])\n","    prediction = inference_fn(test_loader22, model, device)\n","    predictions_22.append(prediction)\n","    del model, state, prediction; gc.collect()\n","    torch.cuda.empty_cache()\n","predictions_22 = np.mean(predictions_22, axis=0)\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":108},"id":"9SnIKs4aQL_5","executionInfo":{"status":"ok","timestamp":1663816765415,"user_tz":-540,"elapsed":19,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"bcc31a24-d7e4-44f1-b3e8-249df3b8a91a"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\ntest_dataset22 = TestDataset(CFG22, test)\\ntest_loader22 = DataLoader(test_dataset22,\\n                         batch_size=CFG22.batch_size,\\n                         shuffle=False,\\n                         num_workers=CFG22.num_workers, pin_memory=True, drop_last=False)\\npredictions_22 = []\\nfor fold in CFG22.trn_fold:\\n    model = CustomModel2(CFG22, config_path=CFG22.config_path, pretrained=False)\\n    state = torch.load(CFG22.path+f\"{CFG22.model.replace(\\'/\\', \\'-\\')}_fold{fold}_best.pth\",\\n                       map_location=torch.device(\\'cpu\\'))\\n    model.load_state_dict(state[\\'model\\'])\\n    prediction = inference_fn(test_loader22, model, device)\\n    predictions_22.append(prediction)\\n    del model, state, prediction; gc.collect()\\n    torch.cuda.empty_cache()\\npredictions_22 = np.mean(predictions_22, axis=0)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["\"\"\"\n","test_dataset23 = TestDataset(CFG23, test)\n","test_loader23 = DataLoader(test_dataset23,\n","                         batch_size=CFG23.batch_size,\n","                         shuffle=False,\n","                         num_workers=CFG23.num_workers, pin_memory=True, drop_last=False)\n","predictions_23 = []\n","for fold in CFG23.trn_fold:\n","    model = CustomModel1(CFG23, config_path=CFG23.config_path, pretrained=False)\n","    state = torch.load(CFG23.path+f\"{CFG23.model.replace('/', '-')}_fold{fold}_best.pth\",\n","                       map_location=torch.device('cpu'))\n","    model.load_state_dict(state['model'])\n","    prediction = inference_fn(test_loader23, model, device)\n","    predictions_23.append(prediction)\n","    del model, state, prediction; gc.collect()\n","    torch.cuda.empty_cache()\n","predictions_23 = np.mean(predictions_23, axis=0)\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":108},"id":"4c84VlyIQjEP","executionInfo":{"status":"ok","timestamp":1663816765416,"user_tz":-540,"elapsed":10,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"e4f45409-be13-4bba-c5d1-6a763f103134"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\ntest_dataset23 = TestDataset(CFG23, test)\\ntest_loader23 = DataLoader(test_dataset23,\\n                         batch_size=CFG23.batch_size,\\n                         shuffle=False,\\n                         num_workers=CFG23.num_workers, pin_memory=True, drop_last=False)\\npredictions_23 = []\\nfor fold in CFG23.trn_fold:\\n    model = CustomModel1(CFG23, config_path=CFG23.config_path, pretrained=False)\\n    state = torch.load(CFG23.path+f\"{CFG23.model.replace(\\'/\\', \\'-\\')}_fold{fold}_best.pth\",\\n                       map_location=torch.device(\\'cpu\\'))\\n    model.load_state_dict(state[\\'model\\'])\\n    prediction = inference_fn(test_loader23, model, device)\\n    predictions_23.append(prediction)\\n    del model, state, prediction; gc.collect()\\n    torch.cuda.empty_cache()\\npredictions_23 = np.mean(predictions_23, axis=0)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["\"\"\"\n","test_dataset24 = TestDataset(CFG24, test)\n","test_loader24 = DataLoader(test_dataset24,\n","                         batch_size=CFG24.batch_size,\n","                         shuffle=False,\n","                         num_workers=CFG24.num_workers, pin_memory=True, drop_last=False)\n","predictions_24 = []\n","for fold in CFG24.trn_fold:\n","    model = CustomModel1(CFG24, config_path=CFG24.config_path, pretrained=False)\n","    state = torch.load(CFG24.path+f\"{CFG24.model.replace('/', '-')}_fold{fold}_best.pth\",\n","                       map_location=torch.device('cpu'))\n","    model.load_state_dict(state['model'])\n","    prediction = inference_fn(test_loader24, model, device)\n","    predictions_24.append(prediction)\n","    del model, state, prediction; gc.collect()\n","    torch.cuda.empty_cache()\n","predictions_24 = np.mean(predictions_24, axis=0)\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":108},"id":"Eq1rITBzQ6_i","executionInfo":{"status":"ok","timestamp":1663816765416,"user_tz":-540,"elapsed":9,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"acbf0191-75f7-4195-dab2-e2540aa18c0b"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\ntest_dataset24 = TestDataset(CFG24, test)\\ntest_loader24 = DataLoader(test_dataset24,\\n                         batch_size=CFG24.batch_size,\\n                         shuffle=False,\\n                         num_workers=CFG24.num_workers, pin_memory=True, drop_last=False)\\npredictions_24 = []\\nfor fold in CFG24.trn_fold:\\n    model = CustomModel1(CFG24, config_path=CFG24.config_path, pretrained=False)\\n    state = torch.load(CFG24.path+f\"{CFG24.model.replace(\\'/\\', \\'-\\')}_fold{fold}_best.pth\",\\n                       map_location=torch.device(\\'cpu\\'))\\n    model.load_state_dict(state[\\'model\\'])\\n    prediction = inference_fn(test_loader24, model, device)\\n    predictions_24.append(prediction)\\n    del model, state, prediction; gc.collect()\\n    torch.cuda.empty_cache()\\npredictions_24 = np.mean(predictions_24, axis=0)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["\"\"\"\n","test_dataset25 = TestDataset(CFG25, test)\n","test_loader25 = DataLoader(test_dataset25,\n","                         batch_size=CFG25.batch_size,\n","                         shuffle=False,\n","                         num_workers=CFG25.num_workers, pin_memory=True, drop_last=False)\n","predictions_25 = []\n","for fold in CFG25.trn_fold:\n","    model = CustomModel1(CFG25, config_path=CFG25.config_path, pretrained=False)\n","    state = torch.load(CFG25.path+f\"{CFG25.model.replace('/', '-')}_fold{fold}_best.pth\",\n","                       map_location=torch.device('cpu'))\n","    model.load_state_dict(state['model'])\n","    prediction = inference_fn(test_loader25, model, device)\n","    predictions_25.append(prediction)\n","    del model, state, prediction; gc.collect()\n","    torch.cuda.empty_cache()\n","predictions_25 = np.mean(predictions_25, axis=0)\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":108},"id":"F_N7PRV5MPFc","executionInfo":{"status":"ok","timestamp":1663816765416,"user_tz":-540,"elapsed":8,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"5d8d8362-43f8-4965-b2c9-ca62604e69f1"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\ntest_dataset25 = TestDataset(CFG25, test)\\ntest_loader25 = DataLoader(test_dataset25,\\n                         batch_size=CFG25.batch_size,\\n                         shuffle=False,\\n                         num_workers=CFG25.num_workers, pin_memory=True, drop_last=False)\\npredictions_25 = []\\nfor fold in CFG25.trn_fold:\\n    model = CustomModel1(CFG25, config_path=CFG25.config_path, pretrained=False)\\n    state = torch.load(CFG25.path+f\"{CFG25.model.replace(\\'/\\', \\'-\\')}_fold{fold}_best.pth\",\\n                       map_location=torch.device(\\'cpu\\'))\\n    model.load_state_dict(state[\\'model\\'])\\n    prediction = inference_fn(test_loader25, model, device)\\n    predictions_25.append(prediction)\\n    del model, state, prediction; gc.collect()\\n    torch.cuda.empty_cache()\\npredictions_25 = np.mean(predictions_25, axis=0)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["test_dataset27 = TestDataset(CFG27, test)\n","test_loader27 = DataLoader(test_dataset27,\n","                         batch_size=CFG27.batch_size,\n","                         shuffle=False,\n","                         num_workers=CFG27.num_workers, pin_memory=True, drop_last=False)\n","predictions_27 = []\n","for fold in CFG27.trn_fold:\n","    model = CustomModel1(CFG27, config_path=CFG27.config_path, pretrained=False)\n","    state = torch.load(CFG27.path+f\"{CFG27.model.replace('/', '-')}_fold{fold}_best.pth\",\n","                       map_location=torch.device('cpu'))\n","    model.load_state_dict(state['model'])\n","    prediction = inference_fn(test_loader27, model, device)\n","    predictions_27.append(prediction)\n","    del model, state, prediction; gc.collect()\n","    torch.cuda.empty_cache()\n","predictions_27 = np.mean(predictions_27, axis=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cq-4f0Q-RZ0d","executionInfo":{"status":"ok","timestamp":1663819461883,"user_tz":-540,"elapsed":2696475,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"d27c18b7-f8e3-4981-e479-a603955ab6b3"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 307/307 [10:32<00:00,  2.06s/it]\n","100%|██████████| 307/307 [10:32<00:00,  2.06s/it]\n","100%|██████████| 307/307 [10:32<00:00,  2.06s/it]\n","100%|██████████| 307/307 [10:32<00:00,  2.06s/it]\n"]}]},{"cell_type":"code","source":["\"\"\"\n","test_dataset28 = TestDataset(CFG28, test)\n","test_loader28 = DataLoader(test_dataset28,\n","                         batch_size=CFG28.batch_size,\n","                         shuffle=False,\n","                         num_workers=CFG28.num_workers, pin_memory=True, drop_last=False)\n","predictions_28 = []\n","for fold in CFG28.trn_fold:\n","    model = CustomModel1(CFG28, config_path=CFG28.config_path, pretrained=False)\n","    state = torch.load(CFG28.path+f\"{CFG28.model.replace('/', '-')}_fold{fold}_best.pth\",\n","                       map_location=torch.device('cpu'))\n","    model.load_state_dict(state['model'])\n","    prediction = inference_fn(test_loader28, model, device)\n","    predictions_28.append(prediction)\n","    del model, state, prediction; gc.collect()\n","    torch.cuda.empty_cache()\n","predictions_28 = np.mean(predictions_28, axis=0)\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":108},"id":"b2sKc8s-raiO","executionInfo":{"status":"ok","timestamp":1663819461883,"user_tz":-540,"elapsed":17,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"56305c45-cb7d-42d3-b441-29d7d354a92d"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\ntest_dataset28 = TestDataset(CFG28, test)\\ntest_loader28 = DataLoader(test_dataset28,\\n                         batch_size=CFG28.batch_size,\\n                         shuffle=False,\\n                         num_workers=CFG28.num_workers, pin_memory=True, drop_last=False)\\npredictions_28 = []\\nfor fold in CFG28.trn_fold:\\n    model = CustomModel1(CFG28, config_path=CFG28.config_path, pretrained=False)\\n    state = torch.load(CFG28.path+f\"{CFG28.model.replace(\\'/\\', \\'-\\')}_fold{fold}_best.pth\",\\n                       map_location=torch.device(\\'cpu\\'))\\n    model.load_state_dict(state[\\'model\\'])\\n    prediction = inference_fn(test_loader28, model, device)\\n    predictions_28.append(prediction)\\n    del model, state, prediction; gc.collect()\\n    torch.cuda.empty_cache()\\npredictions_28 = np.mean(predictions_28, axis=0)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["\"\"\"\n","test_dataset31 = TestDataset(CFG31, test)\n","test_loader31 = DataLoader(test_dataset31,\n","                         batch_size=CFG31.batch_size,\n","                         shuffle=False,\n","                         num_workers=CFG31.num_workers, pin_memory=True, drop_last=False)\n","predictions_31 = []\n","for fold in CFG31.trn_fold:\n","    model = CustomModel1(CFG31, config_path=CFG31.config_path, pretrained=False)\n","    state = torch.load(CFG31.path+f\"{CFG31.model.replace('/', '-')}_fold{fold}_best.pth\",\n","                       map_location=torch.device('cpu'))\n","    model.load_state_dict(state['model'])\n","    prediction = inference_fn(test_loader31, model, device)\n","    predictions_31.append(prediction)\n","    del model, state, prediction; gc.collect()\n","    torch.cuda.empty_cache()\n","predictions_31 = np.mean(predictions_31, axis=0)\n","\"\"\""],"metadata":{"id":"_ts253dcRx_g","colab":{"base_uri":"https://localhost:8080/","height":108},"executionInfo":{"status":"ok","timestamp":1663819461884,"user_tz":-540,"elapsed":8,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"7d92938f-0a32-4aab-b966-8731b2147beb"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\ntest_dataset31 = TestDataset(CFG31, test)\\ntest_loader31 = DataLoader(test_dataset31,\\n                         batch_size=CFG31.batch_size,\\n                         shuffle=False,\\n                         num_workers=CFG31.num_workers, pin_memory=True, drop_last=False)\\npredictions_31 = []\\nfor fold in CFG31.trn_fold:\\n    model = CustomModel1(CFG31, config_path=CFG31.config_path, pretrained=False)\\n    state = torch.load(CFG31.path+f\"{CFG31.model.replace(\\'/\\', \\'-\\')}_fold{fold}_best.pth\",\\n                       map_location=torch.device(\\'cpu\\'))\\n    model.load_state_dict(state[\\'model\\'])\\n    prediction = inference_fn(test_loader31, model, device)\\n    predictions_31.append(prediction)\\n    del model, state, prediction; gc.collect()\\n    torch.cuda.empty_cache()\\npredictions_31 = np.mean(predictions_31, axis=0)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["\"\"\"\n","test_dataset41 = TestDataset(CFG41, test)\n","test_loader41 = DataLoader(test_dataset41,\n","                         batch_size=CFG41.batch_size,\n","                         shuffle=False,\n","                         num_workers=CFG41.num_workers, pin_memory=True, drop_last=False)\n","predictions_41 = []\n","for fold in CFG41.trn_fold:\n","    model = CustomModel2(CFG41, config_path=CFG41.config_path, pretrained=False)\n","    state = torch.load(CFG41.path+f\"{CFG41.model.replace('/', '-')}_fold{fold}_best.pth\",\n","                       map_location=torch.device('cpu'))\n","    model.load_state_dict(state['model'])\n","    prediction = inference_fn(test_loader41, model, device)\n","    predictions_41.append(prediction)\n","    del model, state, prediction; gc.collect()\n","    torch.cuda.empty_cache()\n","predictions_41 = np.mean(predictions_41, axis=0)\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":108},"id":"STOqrjBzSL2S","executionInfo":{"status":"ok","timestamp":1663819461884,"user_tz":-540,"elapsed":7,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"47fd57a8-f984-457c-f881-b1755a7c44db"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\ntest_dataset41 = TestDataset(CFG41, test)\\ntest_loader41 = DataLoader(test_dataset41,\\n                         batch_size=CFG41.batch_size,\\n                         shuffle=False,\\n                         num_workers=CFG41.num_workers, pin_memory=True, drop_last=False)\\npredictions_41 = []\\nfor fold in CFG41.trn_fold:\\n    model = CustomModel2(CFG41, config_path=CFG41.config_path, pretrained=False)\\n    state = torch.load(CFG41.path+f\"{CFG41.model.replace(\\'/\\', \\'-\\')}_fold{fold}_best.pth\",\\n                       map_location=torch.device(\\'cpu\\'))\\n    model.load_state_dict(state[\\'model\\'])\\n    prediction = inference_fn(test_loader41, model, device)\\n    predictions_41.append(prediction)\\n    del model, state, prediction; gc.collect()\\n    torch.cuda.empty_cache()\\npredictions_41 = np.mean(predictions_41, axis=0)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["test_dataset42 = TestDataset(CFG42, test)\n","test_loader42 = DataLoader(test_dataset42,\n","                         batch_size=CFG42.batch_size,\n","                         shuffle=False,\n","                         num_workers=CFG42.num_workers, pin_memory=True, drop_last=False)\n","predictions_42 = []\n","for fold in CFG42.trn_fold:\n","    model = CustomModel2(CFG42, config_path=CFG42.config_path, pretrained=False)\n","    state = torch.load(CFG42.path+f\"{CFG42.model.replace('/', '-')}_fold{fold}_best.pth\",\n","                       map_location=torch.device('cpu'))\n","    model.load_state_dict(state['model'])\n","    prediction = inference_fn(test_loader42, model, device)\n","    predictions_42.append(prediction)\n","    del model, state, prediction; gc.collect()\n","    torch.cuda.empty_cache()\n","predictions_42 = np.mean(predictions_42, axis=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uE-3dqBXSmKB","executionInfo":{"status":"ok","timestamp":1663820369016,"user_tz":-540,"elapsed":907139,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"cda11d44-1323-46f1-9b58-ab78424b391f"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 307/307 [03:20<00:00,  1.53it/s]\n","100%|██████████| 307/307 [03:20<00:00,  1.53it/s]\n","100%|██████████| 307/307 [03:20<00:00,  1.53it/s]\n","100%|██████████| 307/307 [03:20<00:00,  1.53it/s]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"5-y79h6ZYYRf","executionInfo":{"status":"ok","timestamp":1663820369016,"user_tz":-540,"elapsed":16,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","test_dataset21 = TestDataset(CFG21, test)\n","test_loader21 = DataLoader(test_dataset21,\n","                         batch_size=CFG21.batch_size,\n","                         shuffle=False,\n","                         num_workers=CFG21.num_workers, pin_memory=True, drop_last=False)\n","predictions_21 = []\n","for fold in CFG21.trn_fold:\n","    model = CustomModel3(CFG21, config_path=CFG21.config_path, pretrained=False)\n","    state = torch.load(CFG21.path+f\"{CFG21.model.replace('/', '-')}_fold{fold}_best.pth\",\n","                       map_location=torch.device('cpu'))\n","    model.load_state_dict(state['model'])\n","    prediction = inference_fn(test_loader21, model, device)\n","    predictions_21.append(prediction)\n","    del model, state, prediction; gc.collect()\n","    torch.cuda.empty_cache()\n","predictions_21 = np.mean(predictions_21, axis=0)\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":108},"id":"PXo_3H3zYlZW","executionInfo":{"status":"ok","timestamp":1663820369017,"user_tz":-540,"elapsed":15,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"51cf3146-9d38-43ea-f016-4e2306c16d3e"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\ntest_dataset21 = TestDataset(CFG21, test)\\ntest_loader21 = DataLoader(test_dataset21,\\n                         batch_size=CFG21.batch_size,\\n                         shuffle=False,\\n                         num_workers=CFG21.num_workers, pin_memory=True, drop_last=False)\\npredictions_21 = []\\nfor fold in CFG21.trn_fold:\\n    model = CustomModel3(CFG21, config_path=CFG21.config_path, pretrained=False)\\n    state = torch.load(CFG21.path+f\"{CFG21.model.replace(\\'/\\', \\'-\\')}_fold{fold}_best.pth\",\\n                       map_location=torch.device(\\'cpu\\'))\\n    model.load_state_dict(state[\\'model\\'])\\n    prediction = inference_fn(test_loader21, model, device)\\n    predictions_21.append(prediction)\\n    del model, state, prediction; gc.collect()\\n    torch.cuda.empty_cache()\\npredictions_21 = np.mean(predictions_21, axis=0)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["\"\"\"\n","test_dataset43 = TestDataset(CFG43, test)\n","test_loader43 = DataLoader(test_dataset43,\n","                         batch_size=CFG43.batch_size,\n","                         shuffle=False,\n","                         num_workers=CFG43.num_workers, pin_memory=True, drop_last=False)\n","predictions_43 = []\n","for fold in CFG43.trn_fold:\n","    model = CustomModel3(CFG43, config_path=CFG43.config_path, pretrained=False)\n","    state = torch.load(CFG43.path+f\"{CFG43.model.replace('/', '-')}_fold{fold}_best.pth\",\n","                       map_location=torch.device('cpu'))\n","    model.load_state_dict(state['model'])\n","    prediction = inference_fn(test_loader43, model, device)\n","    predictions_43.append(prediction)\n","    del model, state, prediction; gc.collect()\n","    torch.cuda.empty_cache()\n","predictions_43 = np.mean(predictions_43, axis=0)\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":108},"id":"TfKr-6wrYrxD","executionInfo":{"status":"ok","timestamp":1663820369017,"user_tz":-540,"elapsed":14,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"8bd143a0-fa56-4144-d182-f66f0bc91bad"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\ntest_dataset43 = TestDataset(CFG43, test)\\ntest_loader43 = DataLoader(test_dataset43,\\n                         batch_size=CFG43.batch_size,\\n                         shuffle=False,\\n                         num_workers=CFG43.num_workers, pin_memory=True, drop_last=False)\\npredictions_43 = []\\nfor fold in CFG43.trn_fold:\\n    model = CustomModel3(CFG43, config_path=CFG43.config_path, pretrained=False)\\n    state = torch.load(CFG43.path+f\"{CFG43.model.replace(\\'/\\', \\'-\\')}_fold{fold}_best.pth\",\\n                       map_location=torch.device(\\'cpu\\'))\\n    model.load_state_dict(state[\\'model\\'])\\n    prediction = inference_fn(test_loader43, model, device)\\n    predictions_43.append(prediction)\\n    del model, state, prediction; gc.collect()\\n    torch.cuda.empty_cache()\\npredictions_43 = np.mean(predictions_43, axis=0)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["test_dataset44 = TestDataset(CFG44, test)\n","test_loader44 = DataLoader(test_dataset44,\n","                         batch_size=CFG44.batch_size,\n","                         shuffle=False,\n","                         num_workers=CFG44.num_workers, pin_memory=True, drop_last=False)\n","predictions_44 = []\n","for fold in CFG44.trn_fold:\n","    model = CustomModel3(CFG44, config_path=CFG44.config_path, pretrained=False)\n","    state = torch.load(CFG44.path+f\"{CFG44.model.replace('/', '-')}_fold{fold}_best.pth\",\n","                       map_location=torch.device('cpu'))\n","    model.load_state_dict(state['model'])\n","    prediction = inference_fn(test_loader44, model, device)\n","    predictions_44.append(prediction)\n","    del model, state, prediction; gc.collect()\n","    torch.cuda.empty_cache()\n","predictions_44 = np.mean(predictions_44, axis=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tECog9D4Yvw1","executionInfo":{"status":"ok","timestamp":1663821726132,"user_tz":-540,"elapsed":1357128,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"2e4d538d-ff08-415c-fb05-6b1be87ea9aa"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 307/307 [05:15<00:00,  1.03s/it]\n","100%|██████████| 307/307 [05:15<00:00,  1.03s/it]\n","100%|██████████| 307/307 [05:15<00:00,  1.03s/it]\n","100%|██████████| 307/307 [05:15<00:00,  1.03s/it]\n"]}]},{"cell_type":"code","source":["test_dataset45 = TestDataset(CFG45, test)\n","test_loader45 = DataLoader(test_dataset45,\n","                         batch_size=CFG45.batch_size,\n","                         shuffle=False,\n","                         num_workers=CFG45.num_workers, pin_memory=True, drop_last=False)\n","predictions_45 = []\n","for fold in CFG45.trn_fold:\n","    model = CustomModel4(CFG45, config_path=CFG45.config_path, pretrained=False)\n","    state = torch.load(CFG45.path+f\"{CFG45.model.replace('/', '-')}_fold{fold}_best.pth\",\n","                       map_location=torch.device('cpu'))\n","    model.load_state_dict(state['model'])\n","    prediction = inference_fn(test_loader45, model, device)\n","    predictions_45.append(prediction)\n","    del model, state, prediction; gc.collect()\n","    torch.cuda.empty_cache()\n","predictions_45 = np.mean(predictions_45, axis=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L1CWB6YiY1H0","executionInfo":{"status":"ok","timestamp":1663822627795,"user_tz":-540,"elapsed":901675,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"ccd6f95f-f284-41a0-ba5b-96cc4d121efd"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 307/307 [03:20<00:00,  1.53it/s]\n","100%|██████████| 307/307 [03:20<00:00,  1.53it/s]\n","100%|██████████| 307/307 [03:20<00:00,  1.53it/s]\n","100%|██████████| 307/307 [03:20<00:00,  1.53it/s]\n"]}]},{"cell_type":"code","source":["\"\"\"\n","test_dataset46 = TestDataset(CFG46, test)\n","test_loader46 = DataLoader(test_dataset46,\n","                         batch_size=CFG46.batch_size,\n","                         shuffle=False,\n","                         num_workers=CFG46.num_workers, pin_memory=True, drop_last=False)\n","predictions_46 = []\n","for fold in CFG46.trn_fold:\n","    model = CustomModel3(CFG46, config_path=CFG46.config_path, pretrained=False)\n","    state = torch.load(CFG46.path+f\"{CFG46.model.replace('/', '-')}_fold{fold}_best.pth\",\n","                       map_location=torch.device('cpu'))\n","    model.load_state_dict(state['model'])\n","    prediction = inference_fn(test_loader46, model, device)\n","    predictions_46.append(prediction)\n","    del model, state, prediction; gc.collect()\n","    torch.cuda.empty_cache()\n","predictions_46 = np.mean(predictions_46, axis=0)\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":108},"id":"-dBXLuBQY425","executionInfo":{"status":"ok","timestamp":1663822627795,"user_tz":-540,"elapsed":14,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"8ea00e9b-56bf-4cd0-8f4b-acf274ade344"},"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\ntest_dataset46 = TestDataset(CFG46, test)\\ntest_loader46 = DataLoader(test_dataset46,\\n                         batch_size=CFG46.batch_size,\\n                         shuffle=False,\\n                         num_workers=CFG46.num_workers, pin_memory=True, drop_last=False)\\npredictions_46 = []\\nfor fold in CFG46.trn_fold:\\n    model = CustomModel3(CFG46, config_path=CFG46.config_path, pretrained=False)\\n    state = torch.load(CFG46.path+f\"{CFG46.model.replace(\\'/\\', \\'-\\')}_fold{fold}_best.pth\",\\n                       map_location=torch.device(\\'cpu\\'))\\n    model.load_state_dict(state[\\'model\\'])\\n    prediction = inference_fn(test_loader46, model, device)\\n    predictions_46.append(prediction)\\n    del model, state, prediction; gc.collect()\\n    torch.cuda.empty_cache()\\npredictions_46 = np.mean(predictions_46, axis=0)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":[],"metadata":{"id":"DLn0CgYXZG5e","executionInfo":{"status":"ok","timestamp":1663822627795,"user_tz":-540,"elapsed":4,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["test_dataset34 = TestDataset(CFG34, test)\n","test_loader34 = DataLoader(test_dataset34,\n","                         batch_size=CFG34.batch_size,\n","                         shuffle=False,\n","                         num_workers=CFG34.num_workers, pin_memory=True, drop_last=False)\n","predictions_34 = []\n","for fold in CFG34.trn_fold:\n","    model = CustomModel1(CFG34, config_path=CFG34.config_path, pretrained=False)\n","    state = torch.load(CFG34.path+f\"{CFG34.model.replace('/', '-')}_fold{fold}_best.pth\",\n","                       map_location=torch.device('cpu'))\n","    model.load_state_dict(state['model'])\n","    prediction = inference_fn(test_loader34, model, device)\n","    predictions_34.append(prediction)\n","    del model, state, prediction; gc.collect()\n","    torch.cuda.empty_cache()\n","predictions_34 = np.mean(predictions_34, axis=0)\n","predictions_34 = predictions_34[:,0]\n","predictions_34 = predictions_34.reshape((-1,1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J0qd0t4cZHjQ","executionInfo":{"status":"ok","timestamp":1663823095645,"user_tz":-540,"elapsed":467854,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"67f4e4d7-d711-4630-f7ee-c6fb2c9d7118"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 307/307 [01:43<00:00,  2.97it/s]\n","100%|██████████| 307/307 [01:43<00:00,  2.96it/s]\n","100%|██████████| 307/307 [01:43<00:00,  2.97it/s]\n","100%|██████████| 307/307 [01:43<00:00,  2.96it/s]\n"]}]},{"cell_type":"code","source":["test_dataset39 = TestDataset(CFG39, test)\n","test_loader39 = DataLoader(test_dataset39,\n","                         batch_size=CFG39.batch_size,\n","                         shuffle=False,\n","                         num_workers=CFG39.num_workers, pin_memory=True, drop_last=False)\n","predictions_39 = []\n","for fold in CFG39.trn_fold:\n","    model = CustomModel1(CFG39, config_path=CFG39.config_path, pretrained=False)\n","    state = torch.load(CFG39.path+f\"{CFG39.model.replace('/', '-')}_fold{fold}_best.pth\",\n","                       map_location=torch.device('cpu'))\n","    model.load_state_dict(state['model'])\n","    prediction = inference_fn(test_loader39, model, device)\n","    predictions_39.append(prediction)\n","    del model, state, prediction; gc.collect()\n","    torch.cuda.empty_cache()\n","predictions_39 = np.mean(predictions_39, axis=0)\n","predictions_39 = predictions_39[:,0]\n","predictions_39 = predictions_39.reshape((-1,1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NV7oUzu0ZLwc","executionInfo":{"status":"ok","timestamp":1663824441811,"user_tz":-540,"elapsed":1346177,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"5aa97167-f6a6-49d2-c352-2937df491996"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 307/307 [05:15<00:00,  1.03s/it]\n","100%|██████████| 307/307 [05:15<00:00,  1.03s/it]\n","100%|██████████| 307/307 [05:15<00:00,  1.03s/it]\n","100%|██████████| 307/307 [05:15<00:00,  1.03s/it]\n"]}]},{"cell_type":"code","source":["test_dataset40 = TestDataset(CFG40, test)\n","test_loader40 = DataLoader(test_dataset40,\n","                         batch_size=CFG40.batch_size,\n","                         shuffle=False,\n","                         num_workers=CFG40.num_workers, pin_memory=True, drop_last=False)\n","predictions_40 = []\n","for fold in CFG40.trn_fold:\n","    model = CustomModel1(CFG40, config_path=CFG40.config_path, pretrained=False)\n","    state = torch.load(CFG40.path+f\"{CFG40.model.replace('/', '-')}_fold{fold}_best.pth\",\n","                       map_location=torch.device('cpu'))\n","    model.load_state_dict(state['model'])\n","    prediction = inference_fn(test_loader40, model, device)\n","    predictions_40.append(prediction)\n","    del model, state, prediction; gc.collect()\n","    torch.cuda.empty_cache()\n","predictions_40 = np.mean(predictions_40, axis=0)\n","predictions_40 = predictions_40[:,0]\n","predictions_40 = predictions_40.reshape((-1,1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rmBgI5TwZReR","executionInfo":{"status":"ok","timestamp":1663827122244,"user_tz":-540,"elapsed":2680440,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"e1a102d2-ad40-4a68-86bc-fb18448afe69"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 307/307 [10:32<00:00,  2.06s/it]\n","100%|██████████| 307/307 [10:32<00:00,  2.06s/it]\n","100%|██████████| 307/307 [10:32<00:00,  2.06s/it]\n","100%|██████████| 307/307 [10:32<00:00,  2.06s/it]\n"]}]},{"cell_type":"code","source":["\"\"\"\n","test_dataset47 = TestDataset(CFG47, test)\n","test_loader47 = DataLoader(test_dataset47,\n","                         batch_size=CFG47.batch_size,\n","                         shuffle=False,\n","                         num_workers=CFG47.num_workers, pin_memory=True, drop_last=False)\n","predictions_47 = []\n","for fold in CFG47.trn_fold:\n","    model = CustomModel1(CFG47, config_path=CFG47.config_path, pretrained=False)\n","    state = torch.load(CFG47.path+f\"{CFG47.model.replace('/', '-')}_fold{fold}_best.pth\",\n","                       map_location=torch.device('cpu'))\n","    model.load_state_dict(state['model'])\n","    prediction = inference_fn(test_loader47, model, device)\n","    predictions_47.append(prediction)\n","    del model, state, prediction; gc.collect()\n","    torch.cuda.empty_cache()\n","predictions_47 = np.mean(predictions_47, axis=0)\n","predictions_47 = predictions_47[:,0]\n","predictions_47 = predictions_47.reshape((-1,1))\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":108},"id":"kum-jnLIZVFQ","executionInfo":{"status":"ok","timestamp":1663827122246,"user_tz":-540,"elapsed":16,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"e397cbba-61c8-4c92-eb31-6bca6f98cb38"},"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\ntest_dataset47 = TestDataset(CFG47, test)\\ntest_loader47 = DataLoader(test_dataset47,\\n                         batch_size=CFG47.batch_size,\\n                         shuffle=False,\\n                         num_workers=CFG47.num_workers, pin_memory=True, drop_last=False)\\npredictions_47 = []\\nfor fold in CFG47.trn_fold:\\n    model = CustomModel1(CFG47, config_path=CFG47.config_path, pretrained=False)\\n    state = torch.load(CFG47.path+f\"{CFG47.model.replace(\\'/\\', \\'-\\')}_fold{fold}_best.pth\",\\n                       map_location=torch.device(\\'cpu\\'))\\n    model.load_state_dict(state[\\'model\\'])\\n    prediction = inference_fn(test_loader47, model, device)\\n    predictions_47.append(prediction)\\n    del model, state, prediction; gc.collect()\\n    torch.cuda.empty_cache()\\npredictions_47 = np.mean(predictions_47, axis=0)\\npredictions_47 = predictions_47[:,0]\\npredictions_47 = predictions_47.reshape((-1,1))\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["test_dataset48 = TestDataset(CFG48, test)\n","test_loader48 = DataLoader(test_dataset48,\n","                         batch_size=CFG48.batch_size,\n","                         shuffle=False,\n","                         num_workers=CFG48.num_workers, pin_memory=True, drop_last=False)\n","predictions_48 = []\n","for fold in CFG48.trn_fold:\n","    model = CustomModel2(CFG48, config_path=CFG48.config_path, pretrained=False)\n","    state = torch.load(CFG48.path+f\"{CFG48.model.replace('/', '-')}_fold{fold}_best.pth\",\n","                       map_location=torch.device('cpu'))\n","    model.load_state_dict(state['model'])\n","    prediction = inference_fn(test_loader48, model, device)\n","    predictions_48.append(prediction)\n","    del model, state, prediction; gc.collect()\n","    torch.cuda.empty_cache()\n","predictions_48 = np.mean(predictions_48, axis=0)\n","predictions_48 = predictions_48[:,0]\n","predictions_48 = predictions_48.reshape((-1,1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":417},"id":"vpBzAsReZYvr","executionInfo":{"status":"error","timestamp":1663827944728,"user_tz":-540,"elapsed":15490,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"707d9f04-5e66-4b30-e11b-55aeddb711d8"},"execution_count":43,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-43-1b24971b860d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m                        map_location=torch.device('cpu'))\n\u001b[1;32m     11\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader48\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mpredictions_48\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-21-d84835958662>\u001b[0m in \u001b[0;36minference_fn\u001b[0;34m(test_loader, model, device)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mtk0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtk0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m     def register_backward_hook(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    923\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    924\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 925\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 198.00 MiB (GPU 0; 15.90 GiB total capacity; 14.60 GiB already allocated; 83.75 MiB free; 14.98 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}]},{"cell_type":"code","source":[],"metadata":{"id":"9lXoFbGLjnQw","executionInfo":{"status":"aborted","timestamp":1663827150567,"user_tz":-540,"elapsed":11,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#predictions_all = predictions_19*0.06470878 + predictions_20*0.0131939 + predictions_22*0.06180668 + predictions_23*0.05055884 + predictions_24*0.02008916 + predictions_25*0.06263664 + predictions_27*0.08175019 + predictions_28*0.03084266 + predictions_31*0.03858474 + predictions_41*0.02707047 + predictions_42*0.08370543 + predictions_21*0.07534494 + predictions_43*0.08425437 + predictions_44*0.07985377 + predictions_45*0.08337871 + predictions_46*0.01404711 + predictions_34*0.02728774 + predictions_39*0.00701513 + predictions_40*0.03316138 + predictions_47*0.02549253 + predictions_48*0.03521683\n","\n","#predictions1 = (predictions_25+predictions_28) / 2  #0.8071\n","#predictions2 = (predictions_22+predictions_23+predictions_24+predictions_31+predictions1+predictions_41) / 6  #0.8228\n","#predictions3 = (predictions_19+predictions_20+predictions_27+predictions_42) / 4  #0.8240\n","#predictions4 = predictions_21*.35+predictions_43*.35+predictions_46*.3   #0.8213\n","#predictions5 = (predictions_45+predictions_44) / 2\n","#predictions6 = (predictions_40+predictions_47+predictions_48) / 3  #0.8213  #0.8215\n","#predictions7 = predictions_34*.5+predictions_39*.5  #0.8207\n","#predictions_combine = predictions2*0.04754912 + predictions3*0.04911001 + predictions4*0.37500948 + predictions5*0.37216546 + predictions6*0.01848971 + predictions7*0.13767623\n","\n","#predictions_805 = predictions_19*0.03209519 + predictions_20*0.00845168 + predictions_22*0.12410198 + predictions_23*0.00022835 + predictions_24*0.05227489 + predictions_27*0.10028456 + predictions_31*0.00259968 + predictions_42*0.01994933 + predictions_21*0.11993072 + predictions_43*0.0957319 + predictions_44*0.09343536 + predictions_45*0.11866233 + predictions_34*0.05481453 + predictions_39*0.05538527 + predictions_40*0.10995686 + predictions_47*0.0027024 + predictions_48*0.00939497\n","\n","#predictions_810 = predictions_19*0.03682987 + predictions_20*0.0061083 + predictions_27*0.11077566 + predictions_42*0.10054404 + predictions_44*0.16015766 + predictions_45*0.03514027 + predictions_34*0.12992343 + predictions_39*0.15352078 + predictions_40*0.12774139 + predictions_48*0.13925859\n","predictions_810 = predictions_19*0.05522093 + predictions_20*0.02881109 + predictions_27*0.11618671 + predictions_42*0.08329814 + predictions_44*0.17960194 + predictions_45*0.13047173 + predictions_34*0.11544728 + predictions_39*0.16952728 + predictions_40*0.12143489"],"metadata":{"id":"hF0pFkDWMTRK","executionInfo":{"status":"ok","timestamp":1663828413109,"user_tz":-540,"elapsed":392,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","submit_all = sub.copy()\n","#submit.columns = [\"id\",\"label\"]\n","\n","submit_all['label'] = predictions_all\n","submit_all['state'] = (predictions_all>0.5).astype(int)\n","#submit_all['state_best'] = (predictions_all>best_thresh_all).astype(int)\n","\n","submit_all[[\"id\",\"state\"]].to_csv(os.path.join(OUTPUT_SUB_DIR,\"all_ensemble_submission8320.csv\"),index=False,header=False)\n","#submit_all[[\"id\",\"state_best\"]].to_csv(os.path.join(OUTPUT_SUB_DIR,\"all_ensemble_bestthresh_submission.csv\"),index=False,header=False)\n","display(submit_all)\n","\"\"\""],"metadata":{"id":"B8FxjGWAdN0i","executionInfo":{"status":"aborted","timestamp":1663827150568,"user_tz":-540,"elapsed":12,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#plt.hist(submit_all.label,bins=25,edgecolor='white')\n","#plt.xlabel(\"Pred\")\n","#plt.show()"],"metadata":{"id":"hqIJJMZ_MjXH","executionInfo":{"status":"aborted","timestamp":1663827150568,"user_tz":-540,"elapsed":11,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","#train,testでダブっているデータを参照\n","dup_test_ids = ['test_01704','test_03707','test_04353','test_04453','test_04645','test_06909','test_08232']\n","sub_dup_all= submit_all[submit_all[\"id\"].isin(dup_test_ids)]\n","\n","T = pd.DataFrame([['train_00365','train_01463','train_02156','train_04506','train_06891','train_08302','train_09470'],\n","                [0,1,1,1,1,1,0],\n","                ['test_08232','test_01704','test_06909','test_04453','test_03707','test_04353','test_04645']]).T\n","T.columns =[\"train id\",\"true label\",\"id\"]\n","T = T.sort_values(by=\"id\")\n","T = T.merge(sub_dup_all,how='left',on='id')\n","T\n","\"\"\""],"metadata":{"id":"RU_iV8EwMxnx","executionInfo":{"status":"aborted","timestamp":1663827150568,"user_tz":-540,"elapsed":11,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"r_KcLF6BbBlt","executionInfo":{"status":"aborted","timestamp":1663827150569,"user_tz":-540,"elapsed":12,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","submit_com = sub.copy()\n","#submit.columns = [\"id\",\"label\"]\n","\n","submit_com['label'] = predictions_combine\n","submit_com['state'] = (predictions_combine>0.5).astype(int)\n","#submit_com['state_best'] = (predictions_combine>best_thresh_com).astype(int)\n","\n","submit_com[[\"id\",\"state\"]].to_csv(os.path.join(OUTPUT_SUB_DIR,\"combine_ensemble_submission8311.csv\"),index=False,header=False)\n","#submit_com[[\"id\",\"state_best\"]].to_csv(os.path.join(OUTPUT_SUB_DIR,\"combine_ensemble_bestthresh_submission.csv\"),index=False,header=False)\n","display(submit_com)\n","\"\"\""],"metadata":{"id":"sE1maffQg9Q-","executionInfo":{"status":"aborted","timestamp":1663827150569,"user_tz":-540,"elapsed":12,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#plt.hist(submit_com.label,bins=25,edgecolor='white')\n","#plt.xlabel(\"Pred\")\n","#plt.show()"],"metadata":{"id":"mDhPxVBVhg4f","executionInfo":{"status":"aborted","timestamp":1663827150569,"user_tz":-540,"elapsed":12,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","#train,testでダブっているデータを参照\n","dup_test_ids = ['test_01704','test_03707','test_04353','test_04453','test_04645','test_06909','test_08232']\n","sub_dup_com= submit_com[submit_com[\"id\"].isin(dup_test_ids)]\n","\n","T = pd.DataFrame([['train_00365','train_01463','train_02156','train_04506','train_06891','train_08302','train_09470'],\n","                [0,1,1,1,1,1,0],\n","                ['test_08232','test_01704','test_06909','test_04453','test_03707','test_04353','test_04645']]).T\n","T.columns =[\"train id\",\"true label\",\"id\"]\n","T = T.sort_values(by=\"id\")\n","T = T.merge(sub_dup_com,how='left',on='id')\n","T\n","\"\"\""],"metadata":{"id":"g4FeLAxIhrnG","executionInfo":{"status":"aborted","timestamp":1663827150569,"user_tz":-540,"elapsed":12,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ZihOOkXnh1tO","executionInfo":{"status":"aborted","timestamp":1663827150570,"user_tz":-540,"elapsed":12,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","submit_805 = sub.copy()\n","#submit.columns = [\"id\",\"label\"]\n","\n","submit_805['label'] = predictions_805\n","submit_805['state'] = (predictions_805>0.5).astype(int)\n","#submit_805['state_best'] = (predictions_805>best_thresh_805).astype(int)\n","\n","submit_805[[\"id\",\"state\"]].to_csv(os.path.join(OUTPUT_SUB_DIR,\"more805_ensemble_submission8310.csv\"),index=False,header=False)\n","#submit_805[[\"id\",\"state_best\"]].to_csv(os.path.join(OUTPUT_SUB_DIR,\"more805_ensemble_bestthresh_submission.csv\"),index=False,header=False)\n","display(submit_805)\n","\"\"\""],"metadata":{"id":"Jmfw4RDBh2KX","executionInfo":{"status":"aborted","timestamp":1663827150570,"user_tz":-540,"elapsed":12,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#plt.hist(submit_805.label,bins=25,edgecolor='white')\n","#plt.xlabel(\"Pred\")\n","#plt.show()"],"metadata":{"id":"nzXwWO1eiVIA","executionInfo":{"status":"aborted","timestamp":1663827150570,"user_tz":-540,"elapsed":12,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","#train,testでダブっているデータを参照\n","dup_test_ids = ['test_01704','test_03707','test_04353','test_04453','test_04645','test_06909','test_08232']\n","sub_dup_805= submit_805[submit_805[\"id\"].isin(dup_test_ids)]\n","\n","T = pd.DataFrame([['train_00365','train_01463','train_02156','train_04506','train_06891','train_08302','train_09470'],\n","                [0,1,1,1,1,1,0],\n","                ['test_08232','test_01704','test_06909','test_04453','test_03707','test_04353','test_04645']]).T\n","T.columns =[\"train id\",\"true label\",\"id\"]\n","T = T.sort_values(by=\"id\")\n","T = T.merge(sub_dup_805,how='left',on='id')\n","T\n","\"\"\""],"metadata":{"id":"TchbpGF7iZuJ","executionInfo":{"status":"aborted","timestamp":1663827150570,"user_tz":-540,"elapsed":12,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"VeWIeYCSik48","executionInfo":{"status":"aborted","timestamp":1663827150571,"user_tz":-540,"elapsed":13,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["submit_810 = sub.copy()\n","#submit.columns = [\"id\",\"label\"]\n","\n","submit_810['label'] = predictions_810\n","submit_810['state'] = (predictions_810>0.5).astype(int)\n","#submit_810['state_best'] = (predictions_810>best_thresh_810).astype(int)\n","\n","#submit_810[[\"id\",\"state\"]].to_csv(os.path.join(OUTPUT_SUB_DIR,\"more810_ensemble_submission8315.csv\"),index=False,header=False)\n","submit_810[[\"id\",\"state\"]].to_csv(os.path.join(OUTPUT_SUB_DIR,\"more810_ensemble_submission8311.csv\"),index=False,header=False)\n","#submit_810[[\"id\",\"state_best\"]].to_csv(os.path.join(OUTPUT_SUB_DIR,\"more810_ensemble_bestthresh_submission.csv\"),index=False,header=False)\n","display(submit_810)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"suZbaeN6ilWu","executionInfo":{"status":"ok","timestamp":1663828441617,"user_tz":-540,"elapsed":645,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"450cdc46-5075-4c92-d55a-cadcc4414ca2"},"execution_count":45,"outputs":[{"output_type":"display_data","data":{"text/plain":["              id  state     label\n","0     test_00000      1  0.534758\n","1     test_00001      1  0.996560\n","2     test_00002      1  0.979538\n","3     test_00003      0  0.060338\n","4     test_00004      0  0.018848\n","...          ...    ...       ...\n","9795  test_09795      1  0.722878\n","9796  test_09796      1  0.997049\n","9797  test_09797      0  0.179334\n","9798  test_09798      1  0.865902\n","9799  test_09799      1  0.970739\n","\n","[9800 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-b8b35479-10a3-4b7b-b854-95308aedcef9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>state</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>test_00000</td>\n","      <td>1</td>\n","      <td>0.534758</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>test_00001</td>\n","      <td>1</td>\n","      <td>0.996560</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>test_00002</td>\n","      <td>1</td>\n","      <td>0.979538</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>test_00003</td>\n","      <td>0</td>\n","      <td>0.060338</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>test_00004</td>\n","      <td>0</td>\n","      <td>0.018848</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>9795</th>\n","      <td>test_09795</td>\n","      <td>1</td>\n","      <td>0.722878</td>\n","    </tr>\n","    <tr>\n","      <th>9796</th>\n","      <td>test_09796</td>\n","      <td>1</td>\n","      <td>0.997049</td>\n","    </tr>\n","    <tr>\n","      <th>9797</th>\n","      <td>test_09797</td>\n","      <td>0</td>\n","      <td>0.179334</td>\n","    </tr>\n","    <tr>\n","      <th>9798</th>\n","      <td>test_09798</td>\n","      <td>1</td>\n","      <td>0.865902</td>\n","    </tr>\n","    <tr>\n","      <th>9799</th>\n","      <td>test_09799</td>\n","      <td>1</td>\n","      <td>0.970739</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>9800 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8b35479-10a3-4b7b-b854-95308aedcef9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b8b35479-10a3-4b7b-b854-95308aedcef9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b8b35479-10a3-4b7b-b854-95308aedcef9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["plt.hist(submit_810.label,bins=25,edgecolor='white')\n","plt.xlabel(\"Pred\")\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"id":"LThG3obgi_gy","executionInfo":{"status":"ok","timestamp":1663828448466,"user_tz":-540,"elapsed":691,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"5c80cace-49cd-4f8c-bb65-fded369eeea1"},"execution_count":46,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["#train,testでダブっているデータを参照\n","dup_test_ids = ['test_01704','test_03707','test_04353','test_04453','test_04645','test_06909','test_08232']\n","sub_dup_810= submit_810[submit_810[\"id\"].isin(dup_test_ids)]\n","\n","T = pd.DataFrame([['train_00365','train_01463','train_02156','train_04506','train_06891','train_08302','train_09470'],\n","                [0,1,1,1,1,1,0],\n","                ['test_08232','test_01704','test_06909','test_04453','test_03707','test_04353','test_04645']]).T\n","T.columns =[\"train id\",\"true label\",\"id\"]\n","T = T.sort_values(by=\"id\")\n","T = T.merge(sub_dup_810,how='left',on='id')\n","T"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":269},"id":"ap7btNBfjEfV","executionInfo":{"status":"ok","timestamp":1663828451405,"user_tz":-540,"elapsed":510,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"5c19d417-97ba-414f-846e-474d787150a7"},"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      train id true label          id  state     label\n","0  train_01463          1  test_01704      1  0.995038\n","1  train_06891          1  test_03707      1  0.991033\n","2  train_08302          1  test_04353      1  0.925482\n","3  train_04506          1  test_04453      1  0.997079\n","4  train_09470          0  test_04645      0  0.193316\n","5  train_02156          1  test_06909      1  0.696601\n","6  train_00365          0  test_08232      0  0.189196"],"text/html":["\n","  <div id=\"df-2c2745e3-fff5-4a9b-a080-8bca2bc83f66\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>train id</th>\n","      <th>true label</th>\n","      <th>id</th>\n","      <th>state</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>train_01463</td>\n","      <td>1</td>\n","      <td>test_01704</td>\n","      <td>1</td>\n","      <td>0.995038</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>train_06891</td>\n","      <td>1</td>\n","      <td>test_03707</td>\n","      <td>1</td>\n","      <td>0.991033</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>train_08302</td>\n","      <td>1</td>\n","      <td>test_04353</td>\n","      <td>1</td>\n","      <td>0.925482</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>train_04506</td>\n","      <td>1</td>\n","      <td>test_04453</td>\n","      <td>1</td>\n","      <td>0.997079</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>train_09470</td>\n","      <td>0</td>\n","      <td>test_04645</td>\n","      <td>0</td>\n","      <td>0.193316</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>train_02156</td>\n","      <td>1</td>\n","      <td>test_06909</td>\n","      <td>1</td>\n","      <td>0.696601</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>train_00365</td>\n","      <td>0</td>\n","      <td>test_08232</td>\n","      <td>0</td>\n","      <td>0.189196</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c2745e3-fff5-4a9b-a080-8bca2bc83f66')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2c2745e3-fff5-4a9b-a080-8bca2bc83f66 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2c2745e3-fff5-4a9b-a080-8bca2bc83f66');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":[],"metadata":{"id":"KqU_Ymy_we7S","executionInfo":{"status":"aborted","timestamp":1663827150572,"user_tz":-540,"elapsed":13,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","#0.8319903303787268\n","predictions_805_2 = predictions_19*0.08771571 + predictions_20*0.05629589 + predictions_22*0.01652287 + predictions_23*0.02771205 + predictions_24*0.01048438 + predictions_27*0.11410127 + predictions_31*0.04871708 + predictions_42*0.11278922 + predictions_21*0.04335175 + predictions_43*0.10829126 + predictions_44*0.10222701 + predictions_45*0.03187614 + predictions_34*0.07385553 + predictions_39*0.10005615 + predictions_47*0.0199686 + predictions_48*0.04603509\n","\n","submit_805_2 = sub.copy()\n","#submit.columns = [\"id\",\"label\"]\n","\n","submit_805_2['label'] = predictions_805_2\n","submit_805_2['state'] = (predictions_805_2>0.5).astype(int)\n","\n","submit_805_2[[\"id\",\"state\"]].to_csv(os.path.join(OUTPUT_SUB_DIR,\"more805_2_ensemble_submission8319.csv\"),index=False,header=False)\n","display(submit_805_2)\n","\"\"\""],"metadata":{"id":"2VoE3mjtwfgY","executionInfo":{"status":"aborted","timestamp":1663827150572,"user_tz":-540,"elapsed":13,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#plt.hist(submit_805_2.label,bins=25,edgecolor='white')\n","#plt.xlabel(\"Pred\")\n","#plt.show()"],"metadata":{"id":"cj_CVCCHybMA","executionInfo":{"status":"aborted","timestamp":1663827150572,"user_tz":-540,"elapsed":13,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","#train,testでダブっているデータを参照\n","dup_test_ids = ['test_01704','test_03707','test_04353','test_04453','test_04645','test_06909','test_08232']\n","sub_dup_805_2= submit_805_2[submit_805_2[\"id\"].isin(dup_test_ids)]\n","\n","T = pd.DataFrame([['train_00365','train_01463','train_02156','train_04506','train_06891','train_08302','train_09470'],\n","                [0,1,1,1,1,1,0],\n","                ['test_08232','test_01704','test_06909','test_04453','test_03707','test_04353','test_04645']]).T\n","T.columns =[\"train id\",\"true label\",\"id\"]\n","T = T.sort_values(by=\"id\")\n","T = T.merge(sub_dup_805_2,how='left',on='id')\n","T\n","\"\"\""],"metadata":{"id":"fJENi9-iyiS8","executionInfo":{"status":"aborted","timestamp":1663827150573,"user_tz":-540,"elapsed":14,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"SeO34dXBBshv","executionInfo":{"status":"aborted","timestamp":1663827150573,"user_tz":-540,"elapsed":14,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":null,"outputs":[]}]}