{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyMYGCAbYAUrvwItQDeEGRQU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"471846a7f3ee41efa63791a88d377489":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_03c6ace151804e1a934dcc898f801c5e","IPY_MODEL_d3cefada82bb446bb514396aef58788e","IPY_MODEL_e3f396e54990457787111b111b3e3a9a"],"layout":"IPY_MODEL_7baa5ce8d40e427ba595a4c8bf5f1c75"}},"03c6ace151804e1a934dcc898f801c5e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc9d3a249b574d9996290b34610e67b6","placeholder":"​","style":"IPY_MODEL_caa05c2aac644faebde28ec100a759d5","value":"Downloading: 100%"}},"d3cefada82bb446bb514396aef58788e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e58fda875a044d0694d05e920329f62c","max":181,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8253e8227b414b10991d62cf174b82d9","value":181}},"e3f396e54990457787111b111b3e3a9a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_077a7d086c4e4079827a5e5cd62433ea","placeholder":"​","style":"IPY_MODEL_2e9e2dbbb0b24e61a752ffbe383ce831","value":" 181/181 [00:00&lt;00:00, 3.57kB/s]"}},"7baa5ce8d40e427ba595a4c8bf5f1c75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc9d3a249b574d9996290b34610e67b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"caa05c2aac644faebde28ec100a759d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e58fda875a044d0694d05e920329f62c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8253e8227b414b10991d62cf174b82d9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"077a7d086c4e4079827a5e5cd62433ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e9e2dbbb0b24e61a752ffbe383ce831":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"747742163a1e4464a200b2914b1efcf4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_af62412538774e1fa0c23c3096c0ceda","IPY_MODEL_a0c1566028894c7b823fc779d011636f","IPY_MODEL_3764a31bb71d44d6b99fba8a5e776b94"],"layout":"IPY_MODEL_40ab6e1108d94a96959cf24630bc964c"}},"af62412538774e1fa0c23c3096c0ceda":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_55cac5136a7a413b9b82d46a5751dbfa","placeholder":"​","style":"IPY_MODEL_3f91c5ec38de43808f25027c05478f06","value":"Downloading: 100%"}},"a0c1566028894c7b823fc779d011636f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_afae0ebe3d2e4e76a6029dae3175848b","max":406,"min":0,"orientation":"horizontal","style":"IPY_MODEL_56e8aad6fec845618c1b9baf878c90f7","value":406}},"3764a31bb71d44d6b99fba8a5e776b94":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f4cbf45cf9e424397f0f38414a9ae0d","placeholder":"​","style":"IPY_MODEL_ab60bd4f7f6e4b139cf8f0cc03cd1f8c","value":" 406/406 [00:00&lt;00:00, 8.19kB/s]"}},"40ab6e1108d94a96959cf24630bc964c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55cac5136a7a413b9b82d46a5751dbfa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f91c5ec38de43808f25027c05478f06":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"afae0ebe3d2e4e76a6029dae3175848b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56e8aad6fec845618c1b9baf878c90f7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7f4cbf45cf9e424397f0f38414a9ae0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab60bd4f7f6e4b139cf8f0cc03cd1f8c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b904983244af4071b56948db65d6b2b8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_62a5da5eb75d4b1f80261015974352cc","IPY_MODEL_c1ff5268b5bc4ff2b2b6bf3569f08f8e","IPY_MODEL_5d76359a451c49a48827c1fa12cc6200"],"layout":"IPY_MODEL_8b4501910be449709c13a6596a7a7c9a"}},"62a5da5eb75d4b1f80261015974352cc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8f1fe084e1842e2846dc272df4096b7","placeholder":"​","style":"IPY_MODEL_b837f667828a4c09a9d340bc4ddd741d","value":"Downloading: 100%"}},"c1ff5268b5bc4ff2b2b6bf3569f08f8e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ffdf081537844a986d75b7776398ef3","max":3162999,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7376614e2394425c904bb5aa3c240a30","value":3162999}},"5d76359a451c49a48827c1fa12cc6200":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ee120ff106c147a09ad2327f1ffffc9c","placeholder":"​","style":"IPY_MODEL_4f5bacb152d847dfb1ed3526664d7896","value":" 3.16M/3.16M [00:01&lt;00:00, 3.28MB/s]"}},"8b4501910be449709c13a6596a7a7c9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8f1fe084e1842e2846dc272df4096b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b837f667828a4c09a9d340bc4ddd741d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4ffdf081537844a986d75b7776398ef3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7376614e2394425c904bb5aa3c240a30":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ee120ff106c147a09ad2327f1ffffc9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f5bacb152d847dfb1ed3526664d7896":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f8c1f396a764695892cf5361504c247":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8affd2c03b474767886899967e427507","IPY_MODEL_a501412cd4e844c09e874f2e3db79e9d","IPY_MODEL_7a922e55e84b474ead481337e2e5f738"],"layout":"IPY_MODEL_9f6d0168c92d4b8d8594a96f46d49203"}},"8affd2c03b474767886899967e427507":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_217c45cfeaaa4d12b8cc9d7e16bd141c","placeholder":"​","style":"IPY_MODEL_9ff348ff4333401f9f2025f9436349aa","value":"Downloading: 100%"}},"a501412cd4e844c09e874f2e3db79e9d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_33c5db3e96e44d778584ef833fe9e848","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_82fc4177eb4a481f8fa9b6af8aa614b3","value":112}},"7a922e55e84b474ead481337e2e5f738":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_942059d7b05c4b88ba2f7017016da80c","placeholder":"​","style":"IPY_MODEL_d73d07f103784ef1a6fa4e737fb13e81","value":" 112/112 [00:00&lt;00:00, 2.51kB/s]"}},"9f6d0168c92d4b8d8594a96f46d49203":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"217c45cfeaaa4d12b8cc9d7e16bd141c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ff348ff4333401f9f2025f9436349aa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"33c5db3e96e44d778584ef833fe9e848":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82fc4177eb4a481f8fa9b6af8aa614b3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"942059d7b05c4b88ba2f7017016da80c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d73d07f103784ef1a6fa4e737fb13e81":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"15c103491a284e7cb216ffa3f25debc8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ac2229296d7f4c058cfa45b6f3aa3d9c","IPY_MODEL_3656c2ed3a174e94be696f7d4c9452ff","IPY_MODEL_677f1e9c5679446d87993b31c2880b3a"],"layout":"IPY_MODEL_80dd1b55893c471698a7028cae891d3a"}},"ac2229296d7f4c058cfa45b6f3aa3d9c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c85ec4cf7c5c4a73b540d4d43868abcf","placeholder":"​","style":"IPY_MODEL_5c25406609694aaa819beed1ebf3ebf8","value":"Downloading: 100%"}},"3656c2ed3a174e94be696f7d4c9452ff":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d320b729b6b4b989326331e531466ad","max":2028800502,"min":0,"orientation":"horizontal","style":"IPY_MODEL_47da4faf98d94e5ea352628813c75e42","value":2028800502}},"677f1e9c5679446d87993b31c2880b3a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_78b48302291c493188b64b2a419a53a2","placeholder":"​","style":"IPY_MODEL_7b5bdd65e40d427ca697f075d80ffa1e","value":" 2.03G/2.03G [01:37&lt;00:00, 19.8MB/s]"}},"80dd1b55893c471698a7028cae891d3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c85ec4cf7c5c4a73b540d4d43868abcf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c25406609694aaa819beed1ebf3ebf8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5d320b729b6b4b989326331e531466ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47da4faf98d94e5ea352628813c75e42":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"78b48302291c493188b64b2a419a53a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b5bdd65e40d427ca697f075d80ffa1e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UtHPx5o75TKH","executionInfo":{"status":"ok","timestamp":1663491434560,"user_tz":-540,"elapsed":2442,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"06800364-7f5d-427a-f652-9c696b35ef5a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","source":["!pip install transformers\n","!pip install datasets\n","!pip install sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ign_5QW05bpr","executionInfo":{"status":"ok","timestamp":1663491448694,"user_tz":-540,"elapsed":14137,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"fb33c378-08d5-41b4-adab-b21b418bff0b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.22.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.9.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.4.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.12.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.8.2)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.9.1)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.2.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.97)\n"]}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NHtchefz5goV","executionInfo":{"status":"ok","timestamp":1663491449343,"user_tz":-540,"elapsed":655,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"c2af71dd-1a72-4bdc-ba53-ac23cfab749e"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Sep 18 08:57:28 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   44C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["import os\n","import gc\n","import math\n","import time\n","import random\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.simplefilter('ignore')\n","from tqdm import tqdm\n","import re\n","import html\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim import Adam, SGD, AdamW, RAdam\n","from torch.optim import lr_scheduler\n","from torch.utils.data import DataLoader, Dataset\n","\n","from sklearn.model_selection import StratifiedKFold,StratifiedGroupKFold,GroupKFold\n","from sklearn.metrics import log_loss,f1_score\n","\n","from transformers import AutoModel, AutoConfig, AutoTokenizer, AdamW, DataCollatorWithPadding\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"_O7dPzvG5lLe","executionInfo":{"status":"ok","timestamp":1663491453018,"user_tz":-540,"elapsed":3676,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# CFG\n","# ====================================================\n","class CFG:\n","    debug=False\n","    debug2 = False\n","    apex=True\n","    print_freq=100\n","    num_workers=4\n","    # model=\"microsoft/deberta-v3-base\" o\n","    # model='microsoft/deberta-base'  △\n","    # model='roberta-base'  x\n","    # model='roberta-large'  x\n","    # model='roberta-large-mnli'\n","    # model='google/bigbird-roberta-base'\n","    # model='google/bigbird-roberta-large'\n","    # model='xlnet-large-cased'  △\n","    # model='albert-xxlarge-v2'\n","    # model=\"microsoft/deberta-large\" o\n","    # model=\"microsoft/deberta-v3-large\"  o\n","    # model='microsoft/deberta-v2-xlarge'\n","    # model='microsoft/deberta-v2-xxlarge'\n","    # model='microsoft/deberta-xlarge' o\n","    # model='funnel-transformer/large' o\n","    # model='funnel-transformer/medium'\n","    # model='albert-base-v2'\n","    # model='albert-large-v2'  x\n","    # model='google/electra-large-discriminator'  x\n","    # model='google/electra-base-discriminator'  x\n","    # model=\"facebook/bart-large-mnli\"\n","    # model=\"facebook/bart-large\"  o\n","    # model=\"facebook/bart-base\"\n","    # model = \"distilbert-base-uncased\" x\n","    # model = \"allenai/longformer-large-4096\" x\n","    # model = \"allenai/longformer-base-4096\"\n","    # model = \"uw-madison/yoso-4096\"  x\n","    # model = \"xlm-roberta-large\"\n","    # model = \"xlm-roberta-base\"\n","    model = \"google/muril-large-cased\" #x\n","    # model = \"google/rembert\" x\n","    scheduler='cosine' # ['linear', 'cosine']\n","    batch_scheduler=True\n","    num_cycles=0.5\n","    num_warmup_steps=0\n","    epochs=4\n","    encoder_lr=2e-5\n","    decoder_lr=2e-5\n","    min_lr=1e-6\n","    eps=1e-6\n","    betas=(0.9, 0.999)\n","    batch_size=16\n","    fc_dropout=0.2\n","    target_size=1\n","    max_len=256\n","    weight_decay=0.01\n","    gradient_accumulation_steps=1\n","    max_grad_norm=1000\n","    seed=42\n","    n_fold=10\n","    trn_fold=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n","    train=True\n","    nth_awp_start_epoch=1\n","    gradient_checkpointing = True\n","    freezing = True\n","    clean_content = True\n","\n","if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.trn_fold = [0, 1]\n","\n","if CFG.debug2:\n","    CFG.epochs = 3\n","    CFG.trn_fold = [0]"],"metadata":{"id":"4b5Y6si363K7","executionInfo":{"status":"ok","timestamp":1663491453018,"user_tz":-540,"elapsed":8,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["DIR = '/content/drive/MyDrive/Competitions/Signate/MUFJ'\n","INPUT_DIR = os.path.join(DIR,'input')\n","OUTPUT_DIR = os.path.join(DIR,'output')\n","OUTPUT_SUB_DIR = os.path.join(OUTPUT_DIR,'submission')\n","#OUTPUT_MODEL_DIR = os.path.join(OUTPUT_DIR,'model')\n","OUTPUT_MODEL_DIR = DIR + '/output/model/EXP36/'\n","if not os.path.exists(OUTPUT_MODEL_DIR):\n","    os.makedirs(OUTPUT_MODEL_DIR)"],"metadata":{"id":"Lo7k9Uzp93_J","executionInfo":{"status":"ok","timestamp":1663491455538,"user_tz":-540,"elapsed":2526,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def get_score(labels, outputs):\n","    thresh = 0.5\n","    y_pred = outputs\n","    y_true = labels\n","    return f1_score(y_true, (y_pred>thresh).astype(int))\n","\n","\n","def get_logger(filename=OUTPUT_MODEL_DIR+'train'):\n","    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","def seed_everything(seed=CFG.seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(seed=CFG.seed)"],"metadata":{"id":"7yfBWz8D99ZZ","executionInfo":{"status":"ok","timestamp":1663491455538,"user_tz":-540,"elapsed":6,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def freeze(module):\n","    \"\"\"\n","    Freezes module's parameters.\n","    \"\"\"\n","    \n","    for parameter in module.parameters():\n","        parameter.requires_grad = False\n","        \n","def get_freezed_parameters(module):\n","    \"\"\"\n","    Returns names of freezed parameters of the given module.\n","    \"\"\"\n","    \n","    freezed_parameters = []\n","    for name, parameter in module.named_parameters():\n","        if not parameter.requires_grad:\n","            freezed_parameters.append(name)\n","            \n","    return freezed_parameters\n","\n","def set_embedding_parameters_bits(embeddings_path, optim_bits=32):\n","    \"\"\"\n","    https://github.com/huggingface/transformers/issues/14819#issuecomment-1003427930\n","    \"\"\"\n","    \n","    embedding_types = (\"word\", \"position\", \"token_type\")\n","    for embedding_type in embedding_types:\n","        attr_name = f\"{embedding_type}_embeddings\"\n","        \n","        if hasattr(embeddings_path, attr_name): \n","            bnb.optim.GlobalOptimManager.get_instance().register_module_override(\n","                getattr(embeddings_path, attr_name), 'weight', {'optim_bits': optim_bits}\n","            )"],"metadata":{"id":"7Msw-Z4V-Q5q","executionInfo":{"status":"ok","timestamp":1663491455538,"user_tz":-540,"elapsed":4,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv(os.path.join(INPUT_DIR,'train.csv'))\n","test = pd.read_csv(os.path.join(INPUT_DIR,'test.csv'))\n","sub = pd.read_csv(os.path.join(INPUT_DIR,'sample_submit.csv'),header=None)\n","sub.columns = ['id','state']"],"metadata":{"id":"Q988lRbI-AzX","executionInfo":{"status":"ok","timestamp":1663491458545,"user_tz":-540,"elapsed":3010,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["English_Country = ['US','CA','GB','AU','NZ']\n","train = df.loc[~df['country'].isin(English_Country)]\n","train = train.reset_index(drop=True)\n","df.shape, train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DIEv9PGTwXEL","executionInfo":{"status":"ok","timestamp":1663491458545,"user_tz":-540,"elapsed":5,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"5398ef61-83e3-4bdf-b039-fb37159bca46"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((9791, 8), (1109, 8))"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["def remove_URL(text):\n","    url = re.compile(r'https?://\\S+|www\\.\\S+')\n","    return url.sub('',text)\n","\n","def remove_html(text):\n","    html=re.compile(r\"<[^>]*?>\")\n","    return html.sub('',text)\n","\n","def cleaning(texts):\n","    clean_texts = []\n","    for text in texts:\n","        # htmlタグを削除\n","        text = remove_URL(text)\n","        text = remove_html(text)\n","        #アルファベット以外をスペースに置き換え\n","        #clean_punc = re.sub(r'[^a-zA-Z]', ' ', text)\n","        #改行削除\n","        #text = text.replace(\"\\n\",\"\")\n","        clean_texts.append(text)\n","    return clean_texts\n","\n","def get_goal_values(df):\n","  df[\"goal\"].replace(\"100000+\",\"100000-100000\",inplace=True)\n","  _df = df[\"goal\"].str.split('-').apply(pd.Series).astype(float)\n","  _df.columns = [\"goal_max\",\"goal_min\"]\n","  df[\"goal_max\"] = _df[\"goal_max\"].astype(str)\n","  df[\"goal_min\"] = _df[\"goal_min\"].astype(str)\n","  df[\"goal_median\"] = _df[[\"goal_max\",\"goal_min\"]].median(axis=1)\n","  df[\"goal_median\"] = df[\"goal_median\"].astype(int)\n","  return df\n","\n","if CFG.clean_content==True:\n","    train['html_content'] = train['html_content'].map(lambda x: str(x))\n","    train['html_content'] = train['html_content'].apply(html.unescape)\n","    p = re.compile(r\"<[^>]*?>|&amp;|[/'’\\\"”]\")\n","    train['html_content'] = train['html_content'].map(lambda x: p.sub(\"\", x))\n","    train['html_content'] = train['html_content'].map(lambda x: x.lstrip())\n","    train['html_content'] = train['html_content'].fillna('missing')\n","\n","train = get_goal_values(train)\n","train['inputs'] = train.goal_median.astype(str) + ' [SEP] ' + train.duration.astype(str) + ' [SEP] ' + train.country + ' [SEP] ' + train.category1 + ' [SEP] ' + train.category2 + ' [SEP] ' + train.html_content"],"metadata":{"id":"VZDywrmo-G71","executionInfo":{"status":"ok","timestamp":1663491459088,"user_tz":-540,"elapsed":546,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":641},"id":"haCa8vqHj4_Q","executionInfo":{"status":"ok","timestamp":1663491459089,"user_tz":-540,"elapsed":6,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"66b523a6-3d5c-47c1-cc98-7450cd0aff6f"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["               id         goal country  duration     category1  \\\n","0     train_00010       1-1000      FR        15    technology   \n","1     train_00027    5001-6000      IT        40  film & video   \n","2     train_00038    2001-3000      DE        32         games   \n","3     train_00064  22001-23000      DE        30          food   \n","4     train_00066    3001-4000      DE        29           art   \n","...           ...          ...     ...       ...           ...   \n","1104  train_09754    2001-3000      SG        30         music   \n","1105  train_09771  75001-76000      IT        48  film & video   \n","1106  train_09774    2001-3000      MX        32  film & video   \n","1107  train_09779  56001-57000      FR        60    technology   \n","1108  train_09790    1001-2000      ES        30           art   \n","\n","            category2                                       html_content  \\\n","0     diy electronics  Excellent  board for Internet of Things (IoT) ...   \n","1              shorts  INTRO[EN] Every day we are bombarded by tragic...   \n","2       playing cards  Front\\n\\n\\n\\n\\n\\nTuck Back\\n\\n\\n\\n\\n\\nComposit...   \n","3              drinks  Fresh T - ice tea with new flavors and combina...   \n","4       installations  It will be a tasty interactive experience! The...   \n","...               ...                                                ...   \n","1104              pop  Im a singer-songwriter based in Singapore, and...   \n","1105          fantasy  Dear lords and ladiesI am Herold the South Tyr...   \n","1106      documentary  SINOPSIS: Miles de migrantes centroamericanos ...   \n","1107             apps  I.\\tCERTISIO ? \\nThe mobile application ‘andro...   \n","1108   conceptual art  Artyoutube Art inspired in YoutubeMany popular...   \n","\n","      state goal_max goal_min  goal_median  \\\n","0         1      1.0   1000.0          500   \n","1         1   5001.0   6000.0         5500   \n","2         1   2001.0   3000.0         2500   \n","3         0  22001.0  23000.0        22500   \n","4         1   3001.0   4000.0         3500   \n","...     ...      ...      ...          ...   \n","1104      1   2001.0   3000.0         2500   \n","1105      0  75001.0  76000.0        75500   \n","1106      1   2001.0   3000.0         2500   \n","1107      0  56001.0  57000.0        56500   \n","1108      0   1001.0   2000.0         1500   \n","\n","                                                 inputs  \n","0     500 [SEP] 15 [SEP] FR [SEP] technology [SEP] d...  \n","1     5500 [SEP] 40 [SEP] IT [SEP] film & video [SEP...  \n","2     2500 [SEP] 32 [SEP] DE [SEP] games [SEP] playi...  \n","3     22500 [SEP] 30 [SEP] DE [SEP] food [SEP] drink...  \n","4     3500 [SEP] 29 [SEP] DE [SEP] art [SEP] install...  \n","...                                                 ...  \n","1104  2500 [SEP] 30 [SEP] SG [SEP] music [SEP] pop [...  \n","1105  75500 [SEP] 48 [SEP] IT [SEP] film & video [SE...  \n","1106  2500 [SEP] 32 [SEP] MX [SEP] film & video [SEP...  \n","1107  56500 [SEP] 60 [SEP] FR [SEP] technology [SEP]...  \n","1108  1500 [SEP] 30 [SEP] ES [SEP] art [SEP] concept...  \n","\n","[1109 rows x 12 columns]"],"text/html":["\n","  <div id=\"df-5cf06f61-2fba-4077-975c-ff07da6b15c2\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>goal</th>\n","      <th>country</th>\n","      <th>duration</th>\n","      <th>category1</th>\n","      <th>category2</th>\n","      <th>html_content</th>\n","      <th>state</th>\n","      <th>goal_max</th>\n","      <th>goal_min</th>\n","      <th>goal_median</th>\n","      <th>inputs</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>train_00010</td>\n","      <td>1-1000</td>\n","      <td>FR</td>\n","      <td>15</td>\n","      <td>technology</td>\n","      <td>diy electronics</td>\n","      <td>Excellent  board for Internet of Things (IoT) ...</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>1000.0</td>\n","      <td>500</td>\n","      <td>500 [SEP] 15 [SEP] FR [SEP] technology [SEP] d...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>train_00027</td>\n","      <td>5001-6000</td>\n","      <td>IT</td>\n","      <td>40</td>\n","      <td>film &amp; video</td>\n","      <td>shorts</td>\n","      <td>INTRO[EN] Every day we are bombarded by tragic...</td>\n","      <td>1</td>\n","      <td>5001.0</td>\n","      <td>6000.0</td>\n","      <td>5500</td>\n","      <td>5500 [SEP] 40 [SEP] IT [SEP] film &amp; video [SEP...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>train_00038</td>\n","      <td>2001-3000</td>\n","      <td>DE</td>\n","      <td>32</td>\n","      <td>games</td>\n","      <td>playing cards</td>\n","      <td>Front\\n\\n\\n\\n\\n\\nTuck Back\\n\\n\\n\\n\\n\\nComposit...</td>\n","      <td>1</td>\n","      <td>2001.0</td>\n","      <td>3000.0</td>\n","      <td>2500</td>\n","      <td>2500 [SEP] 32 [SEP] DE [SEP] games [SEP] playi...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>train_00064</td>\n","      <td>22001-23000</td>\n","      <td>DE</td>\n","      <td>30</td>\n","      <td>food</td>\n","      <td>drinks</td>\n","      <td>Fresh T - ice tea with new flavors and combina...</td>\n","      <td>0</td>\n","      <td>22001.0</td>\n","      <td>23000.0</td>\n","      <td>22500</td>\n","      <td>22500 [SEP] 30 [SEP] DE [SEP] food [SEP] drink...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>train_00066</td>\n","      <td>3001-4000</td>\n","      <td>DE</td>\n","      <td>29</td>\n","      <td>art</td>\n","      <td>installations</td>\n","      <td>It will be a tasty interactive experience! The...</td>\n","      <td>1</td>\n","      <td>3001.0</td>\n","      <td>4000.0</td>\n","      <td>3500</td>\n","      <td>3500 [SEP] 29 [SEP] DE [SEP] art [SEP] install...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1104</th>\n","      <td>train_09754</td>\n","      <td>2001-3000</td>\n","      <td>SG</td>\n","      <td>30</td>\n","      <td>music</td>\n","      <td>pop</td>\n","      <td>Im a singer-songwriter based in Singapore, and...</td>\n","      <td>1</td>\n","      <td>2001.0</td>\n","      <td>3000.0</td>\n","      <td>2500</td>\n","      <td>2500 [SEP] 30 [SEP] SG [SEP] music [SEP] pop [...</td>\n","    </tr>\n","    <tr>\n","      <th>1105</th>\n","      <td>train_09771</td>\n","      <td>75001-76000</td>\n","      <td>IT</td>\n","      <td>48</td>\n","      <td>film &amp; video</td>\n","      <td>fantasy</td>\n","      <td>Dear lords and ladiesI am Herold the South Tyr...</td>\n","      <td>0</td>\n","      <td>75001.0</td>\n","      <td>76000.0</td>\n","      <td>75500</td>\n","      <td>75500 [SEP] 48 [SEP] IT [SEP] film &amp; video [SE...</td>\n","    </tr>\n","    <tr>\n","      <th>1106</th>\n","      <td>train_09774</td>\n","      <td>2001-3000</td>\n","      <td>MX</td>\n","      <td>32</td>\n","      <td>film &amp; video</td>\n","      <td>documentary</td>\n","      <td>SINOPSIS: Miles de migrantes centroamericanos ...</td>\n","      <td>1</td>\n","      <td>2001.0</td>\n","      <td>3000.0</td>\n","      <td>2500</td>\n","      <td>2500 [SEP] 32 [SEP] MX [SEP] film &amp; video [SEP...</td>\n","    </tr>\n","    <tr>\n","      <th>1107</th>\n","      <td>train_09779</td>\n","      <td>56001-57000</td>\n","      <td>FR</td>\n","      <td>60</td>\n","      <td>technology</td>\n","      <td>apps</td>\n","      <td>I.\\tCERTISIO ? \\nThe mobile application ‘andro...</td>\n","      <td>0</td>\n","      <td>56001.0</td>\n","      <td>57000.0</td>\n","      <td>56500</td>\n","      <td>56500 [SEP] 60 [SEP] FR [SEP] technology [SEP]...</td>\n","    </tr>\n","    <tr>\n","      <th>1108</th>\n","      <td>train_09790</td>\n","      <td>1001-2000</td>\n","      <td>ES</td>\n","      <td>30</td>\n","      <td>art</td>\n","      <td>conceptual art</td>\n","      <td>Artyoutube Art inspired in YoutubeMany popular...</td>\n","      <td>0</td>\n","      <td>1001.0</td>\n","      <td>2000.0</td>\n","      <td>1500</td>\n","      <td>1500 [SEP] 30 [SEP] ES [SEP] art [SEP] concept...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1109 rows × 12 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5cf06f61-2fba-4077-975c-ff07da6b15c2')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5cf06f61-2fba-4077-975c-ff07da6b15c2 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5cf06f61-2fba-4077-975c-ff07da6b15c2');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["skf = StratifiedKFold(n_splits=CFG.n_fold,shuffle=True,random_state=CFG.seed)\n","for fold, ( _, val_) in enumerate(skf.split(train, train.state)):\n","    train.loc[val_ , \"kfold\"] = int(fold)\n","    \n","train[\"kfold\"] = train[\"kfold\"].astype(int)\n","\n","if CFG.debug:\n","    display(train.groupby('kfold').size())\n","    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n","    display(train.groupby('kfold').size())"],"metadata":{"id":"FR5JQ4UF-cjJ","executionInfo":{"status":"ok","timestamp":1663491459089,"user_tz":-540,"elapsed":4,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# tokenizer\n","# ====================================================\n","tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n","tokenizer.save_pretrained(OUTPUT_MODEL_DIR+'tokenizer/')\n","CFG.tokenizer = tokenizer"],"metadata":{"id":"fz40KlX9-l-9","executionInfo":{"status":"ok","timestamp":1663491472174,"user_tz":-540,"elapsed":13089,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["471846a7f3ee41efa63791a88d377489","03c6ace151804e1a934dcc898f801c5e","d3cefada82bb446bb514396aef58788e","e3f396e54990457787111b111b3e3a9a","7baa5ce8d40e427ba595a4c8bf5f1c75","dc9d3a249b574d9996290b34610e67b6","caa05c2aac644faebde28ec100a759d5","e58fda875a044d0694d05e920329f62c","8253e8227b414b10991d62cf174b82d9","077a7d086c4e4079827a5e5cd62433ea","2e9e2dbbb0b24e61a752ffbe383ce831","747742163a1e4464a200b2914b1efcf4","af62412538774e1fa0c23c3096c0ceda","a0c1566028894c7b823fc779d011636f","3764a31bb71d44d6b99fba8a5e776b94","40ab6e1108d94a96959cf24630bc964c","55cac5136a7a413b9b82d46a5751dbfa","3f91c5ec38de43808f25027c05478f06","afae0ebe3d2e4e76a6029dae3175848b","56e8aad6fec845618c1b9baf878c90f7","7f4cbf45cf9e424397f0f38414a9ae0d","ab60bd4f7f6e4b139cf8f0cc03cd1f8c","b904983244af4071b56948db65d6b2b8","62a5da5eb75d4b1f80261015974352cc","c1ff5268b5bc4ff2b2b6bf3569f08f8e","5d76359a451c49a48827c1fa12cc6200","8b4501910be449709c13a6596a7a7c9a","b8f1fe084e1842e2846dc272df4096b7","b837f667828a4c09a9d340bc4ddd741d","4ffdf081537844a986d75b7776398ef3","7376614e2394425c904bb5aa3c240a30","ee120ff106c147a09ad2327f1ffffc9c","4f5bacb152d847dfb1ed3526664d7896","9f8c1f396a764695892cf5361504c247","8affd2c03b474767886899967e427507","a501412cd4e844c09e874f2e3db79e9d","7a922e55e84b474ead481337e2e5f738","9f6d0168c92d4b8d8594a96f46d49203","217c45cfeaaa4d12b8cc9d7e16bd141c","9ff348ff4333401f9f2025f9436349aa","33c5db3e96e44d778584ef833fe9e848","82fc4177eb4a481f8fa9b6af8aa614b3","942059d7b05c4b88ba2f7017016da80c","d73d07f103784ef1a6fa4e737fb13e81"]},"outputId":"20d59841-caf0-4d32-a46c-3bf9f247d3fa"},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/181 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"471846a7f3ee41efa63791a88d377489"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/406 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"747742163a1e4464a200b2914b1efcf4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/3.16M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b904983244af4071b56948db65d6b2b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f8c1f396a764695892cf5361504c247"}},"metadata":{}}]},{"cell_type":"code","source":["# ====================================================\n","# Define max_len\n","# ====================================================\n","#lengths = []\n","#tk0 = tqdm(train['inputs'].fillna(\"\").values, total=len(train))\n","#for text in tk0:\n","#    length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n","#    lengths.append(length)\n","#CFG.max_len = max(lengths) + 6 # cls & sep & sep\n","#LOGGER.info(f\"max_len: {CFG.max_len}\")"],"metadata":{"id":"DWuZSetq_jYN","executionInfo":{"status":"ok","timestamp":1663491472174,"user_tz":-540,"elapsed":8,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Dataset\n","# ====================================================\n","def prepare_input(cfg, text):\n","    inputs = cfg.tokenizer(text,\n","                           add_special_tokens=True,\n","                           max_length=cfg.max_len,\n","                           padding=\"max_length\",\n","                           return_offsets_mapping=False,\n","                           truncation=True)\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","    return inputs\n","\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.inputs = df['inputs'].values\n","        self.labels = df['state'].values\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, item):\n","        inputs = prepare_input(self.cfg, self.inputs[item])\n","        label = torch.tensor(self.labels[item], dtype=torch.float)\n","        return inputs, label\n","\n","#collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)"],"metadata":{"id":"krrca9D6-sja","executionInfo":{"status":"ok","timestamp":1663491472175,"user_tz":-540,"elapsed":7,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Model\n","# ====================================================\n","class MeanPooling(nn.Module):\n","    def __init__(self):\n","        super(MeanPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        mean_embeddings = sum_embeddings / sum_mask\n","        return mean_embeddings\n","\n","class MaxPooling(nn.Module):\n","    def __init__(self):\n","        super(MaxPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        embeddings = last_hidden_state.clone()\n","        embeddings[input_mask_expanded == 0] = -1e4\n","        max_embeddings, _ = torch.max(embeddings, dim=1)\n","        return max_embeddings\n","    \n","\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","            self.config.hidden_dropout = 0.\n","            self.config.hidden_dropout_prob = 0.\n","            self.config.attention_dropout = 0.\n","            self.config.attention_probs_dropout_prob = 0.\n","            LOGGER.info(self.config)\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel(self.config)\n","        if self.cfg.gradient_checkpointing:\n","            self.model.gradient_checkpointing_enable()\n","\n","        # Freezing\n","        if cfg.freezing:\n","            # freezing embeddings and first 2 layers of encoder\n","            freeze((self.model).embeddings)\n","            freeze((self.model).encoder.layer[:2])\n","            cfg.after_freezed_parameters = filter(lambda parameter: parameter.requires_grad, (self.model).parameters())\n","\n","        self.pool = MeanPooling()\n","        self.fc = nn.Linear(self.config.hidden_size, cfg.target_size)\n","        self._init_weights(self.fc)\n","        \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","        \n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs[0]\n","        feature = self.pool(last_hidden_states, inputs['attention_mask'])\n","        return feature\n","\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","        output = self.fc(feature)\n","        return output"],"metadata":{"id":"5c5Z1XB3_HrT","executionInfo":{"status":"ok","timestamp":1663491472175,"user_tz":-540,"elapsed":7,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["class AWP:\n","    def __init__(\n","        self,\n","        model,\n","        optimizer,\n","        criterion,\n","        adv_param=\"weight\",\n","        adv_lr=1e-4,\n","        adv_eps=1e-2,\n","        start_epoch=0,\n","        adv_step=1,\n","        device=\"cpu\",\n","    ):\n","        self.model = model\n","        self.optimizer = optimizer\n","        self.criterion = criterion\n","        self.adv_param = adv_param\n","        self.adv_lr = adv_lr\n","        self.adv_eps = adv_eps\n","        self.start_epoch = start_epoch\n","        self.adv_step = adv_step\n","        self.backup = {}\n","        self.backup_eps = {}\n","        self.device = device\n","\n","    def attack_backward(self, inputs, label):\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            self.save()\n","            self.attack_step() # モデルを近傍の悪い方へ改変\n","            y_preds = self.model(inputs)\n","            adv_loss = self.criterion(\n","                y_preds.view(-1, 1), label.view(-1, 1))\n","            mask = (label.view(-1, 1) != -1)\n","            adv_loss = torch.masked_select(adv_loss, mask).mean()\n","            self.optimizer.zero_grad()\n","        return adv_loss\n","        \n","        \n","\n","    def attack_step(self):\n","        e = 1e-6\n","        for name, param in self.model.named_parameters():\n","            if param.requires_grad and param.grad is not None and self.adv_param in name:\n","                norm1 = torch.norm(param.grad)\n","                norm2 = torch.norm(param.data.detach())\n","                if norm1 != 0 and not torch.isnan(norm1):\n","                    r_at = self.adv_lr * param.grad / (norm1 + e) * (norm2 + e)\n","                    param.data.add_(r_at)\n","                    param.data = torch.min(\n","                        torch.max(param.data, self.backup_eps[name][0]), self.backup_eps[name][1]\n","                    )\n","                # param.data.clamp_(*self.backup_eps[name])\n","\n","    def save(self):\n","        for name, param in self.model.named_parameters():\n","            if param.requires_grad and param.grad is not None and self.adv_param in name:\n","                if name not in self.backup:\n","                    self.backup[name] = param.data.clone()\n","                    grad_eps = self.adv_eps * param.abs().detach()\n","                    self.backup_eps[name] = (\n","                        self.backup[name] - grad_eps,\n","                        self.backup[name] + grad_eps,\n","                    )\n","\n","    def restore(self,):\n","        for name, param in self.model.named_parameters():\n","            if name in self.backup:\n","                param.data = self.backup[name]\n","        self.backup = {}\n","        self.backup_eps = {}"],"metadata":{"id":"SvURRSnUJn6A","executionInfo":{"status":"ok","timestamp":1663491472175,"user_tz":-540,"elapsed":6,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Helper functions\n","# ====================================================\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","\n","def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n","    #if not epoch < CFG.nth_awp_start_epoch:\n","    #    LOGGER.info(f'AWP training with epoch {epoch+1}')\n","    model.train()\n","    #awp = AWP(model=model,\n","    #          optimizer=optimizer,\n","    #          criterion=criterion,\n","    #          adv_eps=0.01, \n","    #          device=device)\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    global_step = 0\n","    #tot_loss = 0\n","    for step, (inputs, labels) in enumerate(train_loader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            y_preds = model(inputs)\n","        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","        #if CFG.nth_awp_start_epoch <= epoch:\n","        #      loss = awp.attack_backward(inputs, labels)\n","        #      scaler.scale(loss).backward()\n","        #      awp.restore()\n","        #tot_loss += loss.item()\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","            global_step += 1\n","            if CFG.batch_scheduler:\n","                scheduler.step()\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  'Grad: {grad_norm:.4f}  '\n","                  'LR: {lr:.8f}  '\n","                  .format(epoch+1, step, len(train_loader), \n","                          remain=timeSince(start, float(step+1)/len(train_loader)),\n","                          loss=losses,\n","                          grad_norm=grad_norm,\n","                          lr=scheduler.get_lr()[0]))\n","\n","    return losses.avg\n","    #model.train()\n","    #return tot_loss/(step+1)\n","\n","\n","def valid_fn(valid_loader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    preds = []\n","    start = end = time.time()\n","    for step, (inputs, labels) in enumerate(valid_loader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n","            print('EVAL: [{0}/{1}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  .format(step, len(valid_loader),\n","                          loss=losses,\n","                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n","    predictions = np.concatenate(preds)\n","    predictions = np.concatenate(predictions)\n","    return losses.avg, predictions\n","\n","\n","def inference_fn(test_loader, model, device):\n","    preds = []\n","    model.eval()\n","    model.to(device)\n","    tk0 = tqdm(test_loader, total=len(test_loader))\n","    for inputs in tk0:\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","    predictions = np.concatenate(preds)\n","    return predictions"],"metadata":{"id":"DTVWyY33BVR1","executionInfo":{"status":"ok","timestamp":1663491472175,"user_tz":-540,"elapsed":6,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# train loop\n","# ====================================================\n","def train_loop(folds, fold):\n","    \n","    LOGGER.info(f\"========== fold: {fold} training ==========\")\n","\n","    # ====================================================\n","    # loader\n","    # ====================================================\n","    train_folds = folds[folds['kfold'] != fold].reset_index(drop=True)\n","    valid_folds = folds[folds['kfold'] == fold].reset_index(drop=True)\n","    valid_labels = valid_folds['state'].values\n","    \n","    train_dataset = TrainDataset(CFG, train_folds)\n","    valid_dataset = TrainDataset(CFG, valid_folds)\n","\n","\n","    train_loader = DataLoader(train_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=True,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset,\n","                              batch_size=CFG.batch_size*2,\n","                              shuffle=False,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","\n","    # ====================================================\n","    # model & optimizer\n","    # ====================================================\n","    model = CustomModel(CFG, config_path=None, pretrained=True)\n","    torch.save(model.config, OUTPUT_MODEL_DIR+'config.pth')\n","    model.to(device)\n","    \n","    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n","        param_optimizer = list(model.named_parameters())\n","        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","        optimizer_parameters = [\n","            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': weight_decay},\n","            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': 0.0},\n","            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n","             'lr': decoder_lr, 'weight_decay': 0.0}\n","        ]\n","        return optimizer_parameters\n","\n","    optimizer_parameters = get_optimizer_params(model,\n","                                                encoder_lr=CFG.encoder_lr, \n","                                                decoder_lr=CFG.decoder_lr,\n","                                                weight_decay=CFG.weight_decay)\n","    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n","    \n","    # ====================================================\n","    # scheduler\n","    # ====================================================\n","    def get_scheduler(cfg, optimizer, num_train_steps):\n","        if cfg.scheduler == 'linear':\n","            scheduler = get_linear_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n","            )\n","        elif cfg.scheduler == 'cosine':\n","            scheduler = get_cosine_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","            )\n","        return scheduler\n","    \n","    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n","    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n","\n","    # ====================================================\n","    # loop\n","    # ====================================================\n","    criterion = nn.BCEWithLogitsLoss(reduction=\"mean\")\n","    \n","    best_score = 0\n","\n","    for epoch in range(CFG.epochs):\n","\n","        start_time = time.time()\n","\n","        # train\n","        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n","\n","        # eval\n","        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n","        \n","        # scoring\n","        score = get_score(valid_labels, predictions)\n","\n","        elapsed = time.time() - start_time\n","\n","        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n","        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n","\n","        \n","        if best_score < score:\n","            best_score = score\n","            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","            torch.save({'model': model.state_dict(),\n","                        'predictions': predictions},\n","                        OUTPUT_MODEL_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n","\n","    predictions = torch.load(OUTPUT_MODEL_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", \n","                             map_location=torch.device('cpu'))['predictions']\n","    valid_folds['pred'] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    \n","    return valid_folds"],"metadata":{"id":"teu8DfxeCm1h","executionInfo":{"status":"ok","timestamp":1663491472176,"user_tz":-540,"elapsed":7,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["if __name__ == '__main__':\n","    \n","    def get_result(oof_df):\n","        labels = oof_df['state'].values\n","        preds = oof_df['pred'].values\n","        score = get_score(labels, preds)\n","        LOGGER.info(f'Score: {score:<.4f}')\n","    \n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for fold in range(CFG.n_fold):\n","            if fold in CFG.trn_fold:\n","                _oof_df = train_loop(train, fold)\n","                oof_df = pd.concat([oof_df, _oof_df])\n","                LOGGER.info(f\"========== fold: {fold} result ==========\")\n","                get_result(_oof_df)\n","        oof_df = oof_df.reset_index(drop=True)\n","        LOGGER.info(f\"========== CV ==========\")\n","        get_result(oof_df)\n","        oof_df.to_pickle(OUTPUT_MODEL_DIR+'oof_df.pkl')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["15c103491a284e7cb216ffa3f25debc8","ac2229296d7f4c058cfa45b6f3aa3d9c","3656c2ed3a174e94be696f7d4c9452ff","677f1e9c5679446d87993b31c2880b3a","80dd1b55893c471698a7028cae891d3a","c85ec4cf7c5c4a73b540d4d43868abcf","5c25406609694aaa819beed1ebf3ebf8","5d320b729b6b4b989326331e531466ad","47da4faf98d94e5ea352628813c75e42","78b48302291c493188b64b2a419a53a2","7b5bdd65e40d427ca697f075d80ffa1e"]},"id":"6Fnuz2nICrxj","outputId":"dc3de5be-46b2-47b7-8dc5-c9f2dd0cd56d","executionInfo":{"status":"error","timestamp":1663492080215,"user_tz":-540,"elapsed":608045,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["========== fold: 0 training ==========\n","INFO:__main__:========== fold: 0 training ==========\n","BertConfig {\n","  \"_name_or_path\": \"google/muril-large-cased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"classifier_dropout\": null,\n","  \"embedding_size\": 1024,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.22.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 197285\n","}\n","\n","INFO:__main__:BertConfig {\n","  \"_name_or_path\": \"google/muril-large-cased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"classifier_dropout\": null,\n","  \"embedding_size\": 1024,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.22.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 197285\n","}\n","\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/2.03G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15c103491a284e7cb216ffa3f25debc8"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at google/muril-large-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/62] Elapsed 0m 5s (remain 5m 46s) Loss: 0.6668(0.6668) Grad: 47066.2109  LR: 0.00002000  \n","Epoch: [1][61/62] Elapsed 0m 31s (remain 0m 0s) Loss: 0.6778(0.7427) Grad: 5057.8706  LR: 0.00001709  \n","EVAL: [0/4] Elapsed 0m 1s (remain 0m 5s) Loss: 0.7141(0.7141) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.7427  avg_val_loss: 0.7155  time: 36s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.7427  avg_val_loss: 0.7155  time: 36s\n","Epoch 1 - Score: 0.5802\n","INFO:__main__:Epoch 1 - Score: 0.5802\n","Epoch 1 - Save Best Score: 0.5802 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.5802 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [3/4] Elapsed 0m 3s (remain 0m 0s) Loss: 0.7173(0.7155) \n","Epoch: [2][0/62] Elapsed 0m 1s (remain 1m 9s) Loss: 0.7347(0.7347) Grad: inf  LR: 0.00001700  \n","Epoch: [2][61/62] Elapsed 0m 27s (remain 0m 0s) Loss: 0.7531(0.7281) Grad: 22703.6074  LR: 0.00001006  \n","EVAL: [0/4] Elapsed 0m 2s (remain 0m 6s) Loss: 0.7091(0.7091) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.7281  avg_val_loss: 0.7080  time: 32s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.7281  avg_val_loss: 0.7080  time: 32s\n","Epoch 2 - Score: 0.5179\n","INFO:__main__:Epoch 2 - Score: 0.5179\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [3/4] Elapsed 0m 4s (remain 0m 0s) Loss: 0.6963(0.7080) \n","Epoch: [3][0/62] Elapsed 0m 1s (remain 1m 9s) Loss: 0.6997(0.6997) Grad: inf  LR: 0.00000994  \n","Epoch: [3][61/62] Elapsed 0m 27s (remain 0m 0s) Loss: 0.7502(0.7212) Grad: 32633.3613  LR: 0.00000300  \n","EVAL: [0/4] Elapsed 0m 1s (remain 0m 5s) Loss: 0.7072(0.7072) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.7212  avg_val_loss: 0.7049  time: 31s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.7212  avg_val_loss: 0.7049  time: 31s\n","Epoch 3 - Score: 0.5047\n","INFO:__main__:Epoch 3 - Score: 0.5047\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [3/4] Elapsed 0m 3s (remain 0m 0s) Loss: 0.6876(0.7049) \n","Epoch: [4][0/62] Elapsed 0m 1s (remain 1m 7s) Loss: 0.7229(0.7229) Grad: inf  LR: 0.00000291  \n","Epoch: [4][61/62] Elapsed 0m 27s (remain 0m 0s) Loss: 0.7117(0.7193) Grad: 5972.5869  LR: 0.00000000  \n","EVAL: [0/4] Elapsed 0m 1s (remain 0m 5s) Loss: 0.7070(0.7070) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.7193  avg_val_loss: 0.7045  time: 31s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.7193  avg_val_loss: 0.7045  time: 31s\n","Epoch 4 - Score: 0.4762\n","INFO:__main__:Epoch 4 - Score: 0.4762\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [3/4] Elapsed 0m 3s (remain 0m 0s) Loss: 0.6865(0.7045) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 0 result ==========\n","INFO:__main__:========== fold: 0 result ==========\n","Score: 0.5802\n","INFO:__main__:Score: 0.5802\n","========== fold: 1 training ==========\n","INFO:__main__:========== fold: 1 training ==========\n","BertConfig {\n","  \"_name_or_path\": \"google/muril-large-cased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"classifier_dropout\": null,\n","  \"embedding_size\": 1024,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.22.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 197285\n","}\n","\n","INFO:__main__:BertConfig {\n","  \"_name_or_path\": \"google/muril-large-cased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"classifier_dropout\": null,\n","  \"embedding_size\": 1024,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.22.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 197285\n","}\n","\n","Some weights of the model checkpoint at google/muril-large-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/62] Elapsed 0m 0s (remain 0m 55s) Loss: 0.7092(0.7092) Grad: inf  LR: 0.00002000  \n","Epoch: [1][61/62] Elapsed 0m 26s (remain 0m 0s) Loss: 0.7491(0.7395) Grad: 11527.7061  LR: 0.00001709  \n","EVAL: [0/4] Elapsed 0m 1s (remain 0m 3s) Loss: 0.7257(0.7257) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.7395  avg_val_loss: 0.7172  time: 30s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.7395  avg_val_loss: 0.7172  time: 30s\n","Epoch 1 - Score: 0.2703\n","INFO:__main__:Epoch 1 - Score: 0.2703\n","Epoch 1 - Save Best Score: 0.2703 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.2703 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [3/4] Elapsed 0m 3s (remain 0m 0s) Loss: 0.7167(0.7172) \n","Epoch: [2][0/62] Elapsed 0m 0s (remain 0m 57s) Loss: 0.7131(0.7131) Grad: 104666.3672  LR: 0.00001700  \n","Epoch: [2][61/62] Elapsed 0m 27s (remain 0m 0s) Loss: 0.7532(0.7328) Grad: 32505.1953  LR: 0.00001006  \n","EVAL: [0/4] Elapsed 0m 1s (remain 0m 4s) Loss: 0.7238(0.7238) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.7328  avg_val_loss: 0.7148  time: 31s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.7328  avg_val_loss: 0.7148  time: 31s\n","Epoch 2 - Score: 0.2535\n","INFO:__main__:Epoch 2 - Score: 0.2535\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [3/4] Elapsed 0m 3s (remain 0m 0s) Loss: 0.7141(0.7148) \n","Epoch: [3][0/62] Elapsed 0m 0s (remain 0m 59s) Loss: 0.6964(0.6964) Grad: 93608.1328  LR: 0.00000994  \n","Epoch: [3][61/62] Elapsed 0m 27s (remain 0m 0s) Loss: 0.6571(0.7310) Grad: 5818.8750  LR: 0.00000300  \n","EVAL: [0/4] Elapsed 0m 1s (remain 0m 4s) Loss: 0.7230(0.7230) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.7310  avg_val_loss: 0.7138  time: 31s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.7310  avg_val_loss: 0.7138  time: 31s\n","Epoch 3 - Score: 0.2319\n","INFO:__main__:Epoch 3 - Score: 0.2319\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [3/4] Elapsed 0m 3s (remain 0m 0s) Loss: 0.7130(0.7138) \n","Epoch: [4][0/62] Elapsed 0m 0s (remain 0m 53s) Loss: 0.6442(0.6442) Grad: inf  LR: 0.00000291  \n","Epoch: [4][61/62] Elapsed 0m 26s (remain 0m 0s) Loss: 0.6934(0.7288) Grad: 8848.3506  LR: 0.00000000  \n","EVAL: [0/4] Elapsed 0m 1s (remain 0m 3s) Loss: 0.7229(0.7229) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.7288  avg_val_loss: 0.7136  time: 30s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.7288  avg_val_loss: 0.7136  time: 30s\n","Epoch 4 - Score: 0.2319\n","INFO:__main__:Epoch 4 - Score: 0.2319\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [3/4] Elapsed 0m 3s (remain 0m 0s) Loss: 0.7128(0.7136) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 1 result ==========\n","INFO:__main__:========== fold: 1 result ==========\n","Score: 0.2703\n","INFO:__main__:Score: 0.2703\n","========== fold: 2 training ==========\n","INFO:__main__:========== fold: 2 training ==========\n","BertConfig {\n","  \"_name_or_path\": \"google/muril-large-cased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"classifier_dropout\": null,\n","  \"embedding_size\": 1024,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.22.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 197285\n","}\n","\n","INFO:__main__:BertConfig {\n","  \"_name_or_path\": \"google/muril-large-cased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"classifier_dropout\": null,\n","  \"embedding_size\": 1024,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.22.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 197285\n","}\n","\n","Some weights of the model checkpoint at google/muril-large-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/62] Elapsed 0m 0s (remain 0m 56s) Loss: 0.8735(0.8735) Grad: inf  LR: 0.00002000  \n","Epoch: [1][61/62] Elapsed 0m 26s (remain 0m 0s) Loss: 1.0055(0.7911) Grad: 40517.4453  LR: 0.00001709  \n","EVAL: [0/4] Elapsed 0m 1s (remain 0m 4s) Loss: 0.7710(0.7710) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.7911  avg_val_loss: 0.7609  time: 31s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.7911  avg_val_loss: 0.7609  time: 31s\n","Epoch 1 - Score: 0.5323\n","INFO:__main__:Epoch 1 - Score: 0.5323\n","Epoch 1 - Save Best Score: 0.5323 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.5323 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [3/4] Elapsed 0m 3s (remain 0m 0s) Loss: 0.7071(0.7609) \n","Epoch: [2][0/62] Elapsed 0m 0s (remain 0m 52s) Loss: 0.8371(0.8371) Grad: inf  LR: 0.00001700  \n","Epoch: [2][61/62] Elapsed 0m 26s (remain 0m 0s) Loss: 0.7334(0.7751) Grad: 9835.3740  LR: 0.00001006  \n","EVAL: [0/4] Elapsed 0m 1s (remain 0m 4s) Loss: 0.7538(0.7538) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.7751  avg_val_loss: 0.7523  time: 31s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.7751  avg_val_loss: 0.7523  time: 31s\n","Epoch 2 - Score: 0.5043\n","INFO:__main__:Epoch 2 - Score: 0.5043\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [3/4] Elapsed 0m 3s (remain 0m 0s) Loss: 0.7026(0.7523) \n","Epoch: [3][0/62] Elapsed 0m 0s (remain 0m 54s) Loss: 0.8731(0.8731) Grad: inf  LR: 0.00000994  \n","Epoch: [3][61/62] Elapsed 0m 26s (remain 0m 0s) Loss: 0.8529(0.7677) Grad: 23871.6934  LR: 0.00000300  \n","EVAL: [0/4] Elapsed 0m 1s (remain 0m 3s) Loss: 0.7458(0.7458) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.7677  avg_val_loss: 0.7484  time: 30s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.7677  avg_val_loss: 0.7484  time: 30s\n","Epoch 3 - Score: 0.4865\n","INFO:__main__:Epoch 3 - Score: 0.4865\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [3/4] Elapsed 0m 3s (remain 0m 0s) Loss: 0.7007(0.7484) \n","Epoch: [4][0/62] Elapsed 0m 0s (remain 0m 56s) Loss: 0.6434(0.6434) Grad: 38362.9414  LR: 0.00000291  \n","Epoch: [4][61/62] Elapsed 0m 26s (remain 0m 0s) Loss: 0.7071(0.7631) Grad: 4687.2754  LR: 0.00000000  \n","EVAL: [0/4] Elapsed 0m 1s (remain 0m 4s) Loss: 0.7446(0.7446) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.7631  avg_val_loss: 0.7478  time: 30s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.7631  avg_val_loss: 0.7478  time: 30s\n","Epoch 4 - Score: 0.4865\n","INFO:__main__:Epoch 4 - Score: 0.4865\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [3/4] Elapsed 0m 3s (remain 0m 0s) Loss: 0.7004(0.7478) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 2 result ==========\n","INFO:__main__:========== fold: 2 result ==========\n","Score: 0.5323\n","INFO:__main__:Score: 0.5323\n","========== fold: 3 training ==========\n","INFO:__main__:========== fold: 3 training ==========\n","BertConfig {\n","  \"_name_or_path\": \"google/muril-large-cased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"classifier_dropout\": null,\n","  \"embedding_size\": 1024,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.22.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 197285\n","}\n","\n","INFO:__main__:BertConfig {\n","  \"_name_or_path\": \"google/muril-large-cased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"classifier_dropout\": null,\n","  \"embedding_size\": 1024,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.22.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 197285\n","}\n","\n","Some weights of the model checkpoint at google/muril-large-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/62] Elapsed 0m 0s (remain 0m 55s) Loss: 0.7474(0.7474) Grad: inf  LR: 0.00002000  \n","Epoch: [1][61/62] Elapsed 0m 26s (remain 0m 0s) Loss: 0.6548(0.6795) Grad: 10735.1816  LR: 0.00001709  \n","EVAL: [0/4] Elapsed 0m 1s (remain 0m 4s) Loss: 0.7213(0.7213) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6795  avg_val_loss: 0.7000  time: 31s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6795  avg_val_loss: 0.7000  time: 31s\n","Epoch 1 - Score: 0.3288\n","INFO:__main__:Epoch 1 - Score: 0.3288\n","Epoch 1 - Save Best Score: 0.3288 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.3288 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [3/4] Elapsed 0m 3s (remain 0m 0s) Loss: 0.6743(0.7000) \n","Epoch: [2][0/62] Elapsed 0m 0s (remain 0m 57s) Loss: 0.6769(0.6769) Grad: 76873.4922  LR: 0.00001700  \n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-5e69f1aaf4df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrn_fold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                 \u001b[0m_oof_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                 \u001b[0moof_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moof_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_oof_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"========== fold: {fold} result ==========\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-20-339bd5b5a131>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(folds, fold)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# eval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-92ad4d26792a>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mgrad_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["A = pd.read_pickle(OUTPUT_MODEL_DIR+'oof_df.pkl')\n","A.head()"],"metadata":{"id":"0cHG0TUuknq7","executionInfo":{"status":"aborted","timestamp":1663492080216,"user_tz":-540,"elapsed":6,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3vgWEX03TZjr","executionInfo":{"status":"aborted","timestamp":1663492080216,"user_tz":-540,"elapsed":6,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":null,"outputs":[]}]}