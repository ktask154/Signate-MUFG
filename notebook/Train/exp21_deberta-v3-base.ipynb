{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyM4zR6iCRgwQqbY1QtbJTdf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UtHPx5o75TKH","executionInfo":{"status":"ok","timestamp":1663219941984,"user_tz":-540,"elapsed":2936,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"eabedfc3-40ac-42cb-97bc-b142352862e0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","source":["!pip install transformers\n","!pip install datasets\n","!pip install sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ign_5QW05bpr","executionInfo":{"status":"ok","timestamp":1663219956316,"user_tz":-540,"elapsed":14335,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"f1dbedd5-eee6-4cde-c2ae-54dab13ee719"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.22.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.9.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.4.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.8.2)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.9.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.12.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.2.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.97)\n"]}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NHtchefz5goV","executionInfo":{"status":"ok","timestamp":1663219956317,"user_tz":-540,"elapsed":8,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"6151605d-9a20-4f2b-b27a-8a856051d70e"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Sep 15 05:32:36 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   62C    P0    42W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["import os\n","import gc\n","import math\n","import time\n","import random\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.simplefilter('ignore')\n","from tqdm import tqdm\n","import re\n","import html\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim import Adam, SGD, AdamW, RAdam\n","from torch.optim import lr_scheduler\n","from torch.utils.data import DataLoader, Dataset\n","\n","from sklearn.model_selection import StratifiedKFold,StratifiedGroupKFold,GroupKFold\n","from sklearn.metrics import log_loss,f1_score\n","\n","from transformers import AutoModel, AutoConfig, AutoTokenizer, AdamW, DataCollatorWithPadding\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"_O7dPzvG5lLe","executionInfo":{"status":"ok","timestamp":1663219961728,"user_tz":-540,"elapsed":4749,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# CFG\n","# ====================================================\n","class CFG:\n","    debug=False\n","    debug2 = False\n","    apex=True\n","    print_freq=100\n","    num_workers=4\n","    model=\"microsoft/deberta-v3-base\"\n","    # model='microsoft/deberta-base'\n","    # model='roberta-base'\n","    # model='roberta-large'\n","    # model='roberta-large-mnli'\n","    # model='xlnet-large-cased'\n","    # model='albert-xxlarge-v2'\n","    # model=\"microsoft/deberta-large\"\n","    # model=\"microsoft/deberta-v3-large\"\n","    # model='microsoft/deberta-v2-xlarge'\n","    # model='funnel-transformer/large'\n","    # model='funnel-transformer/medium'\n","    # model='albert-base-v2'\n","    # model='albert-large-v2'\n","    # model='google/electra-large-discriminator'\n","    # model='google/electra-base-discriminator'\n","    # model=\"facebook/bart-large-mnli\"\n","    # model=\"facebook/bart-large\"\n","    # model=\"facebook/bart-base\"\n","    scheduler='cosine' # ['linear', 'cosine']\n","    batch_scheduler=True\n","    num_cycles=0.5\n","    num_warmup_steps=0\n","    epochs=4\n","    encoder_lr=2e-5\n","    decoder_lr=2e-5\n","    min_lr=1e-6\n","    eps=1e-6\n","    betas=(0.9, 0.999)\n","    batch_size=16\n","    fc_dropout=0.2\n","    target_size=1\n","    max_len=256\n","    weight_decay=0.01\n","    gradient_accumulation_steps=1\n","    max_grad_norm=1000\n","    seed=42\n","    n_fold=4\n","    trn_fold=[0, 1, 2, 3]\n","    train=True\n","    nth_awp_start_epoch=1\n","    gradient_checkpointing = True\n","    freezing = True\n","    clean_content = True\n","\n","if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.trn_fold = [0, 1]\n","\n","if CFG.debug2:\n","    CFG.epochs = 3\n","    CFG.trn_fold = [0]"],"metadata":{"id":"4b5Y6si363K7","executionInfo":{"status":"ok","timestamp":1663219961728,"user_tz":-540,"elapsed":6,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["DIR = '/content/drive/MyDrive/Competitions/Signate/MUFJ'\n","INPUT_DIR = os.path.join(DIR,'input')\n","OUTPUT_DIR = os.path.join(DIR,'output')\n","OUTPUT_SUB_DIR = os.path.join(OUTPUT_DIR,'submission')\n","#OUTPUT_MODEL_DIR = os.path.join(OUTPUT_DIR,'model')\n","OUTPUT_MODEL_DIR = DIR + '/output/model/EXP21/'\n","if not os.path.exists(OUTPUT_MODEL_DIR):\n","    os.makedirs(OUTPUT_MODEL_DIR)"],"metadata":{"id":"Lo7k9Uzp93_J","executionInfo":{"status":"ok","timestamp":1663219961729,"user_tz":-540,"elapsed":6,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def get_score(labels, outputs):\n","    thresh = 0.5\n","    y_pred = outputs\n","    y_true = labels\n","    return f1_score(y_true, (y_pred>thresh).astype(int))\n","\n","\n","def get_logger(filename=OUTPUT_MODEL_DIR+'train'):\n","    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","def seed_everything(seed=CFG.seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(seed=CFG.seed)\n","\n","def seed_worker(worker_id):\n","    worker_seed = torch.initial_seed() % 2**32\n","    np.random.seed(worker_seed)\n","    random.seed(worker_seed)\n","\n","g = torch.Generator()\n","g.manual_seed(CFG.seed)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7yfBWz8D99ZZ","executionInfo":{"status":"ok","timestamp":1663219961729,"user_tz":-540,"elapsed":6,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"075fab57-db20-4ca8-ddfb-94a9fcf8ac7f"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7ff00f150ed0>"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["def freeze(module):\n","    \"\"\"\n","    Freezes module's parameters.\n","    \"\"\"\n","    \n","    for parameter in module.parameters():\n","        parameter.requires_grad = False\n","        \n","def get_freezed_parameters(module):\n","    \"\"\"\n","    Returns names of freezed parameters of the given module.\n","    \"\"\"\n","    \n","    freezed_parameters = []\n","    for name, parameter in module.named_parameters():\n","        if not parameter.requires_grad:\n","            freezed_parameters.append(name)\n","            \n","    return freezed_parameters\n","\n","def set_embedding_parameters_bits(embeddings_path, optim_bits=32):\n","    \"\"\"\n","    https://github.com/huggingface/transformers/issues/14819#issuecomment-1003427930\n","    \"\"\"\n","    \n","    embedding_types = (\"word\", \"position\", \"token_type\")\n","    for embedding_type in embedding_types:\n","        attr_name = f\"{embedding_type}_embeddings\"\n","        \n","        if hasattr(embeddings_path, attr_name): \n","            bnb.optim.GlobalOptimManager.get_instance().register_module_override(\n","                getattr(embeddings_path, attr_name), 'weight', {'optim_bits': optim_bits}\n","            )"],"metadata":{"id":"7Msw-Z4V-Q5q","executionInfo":{"status":"ok","timestamp":1663219961729,"user_tz":-540,"elapsed":4,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["train = pd.read_csv(os.path.join(INPUT_DIR,'train.csv'))\n","test = pd.read_csv(os.path.join(INPUT_DIR,'test.csv'))\n","sub = pd.read_csv(os.path.join(INPUT_DIR,'sample_submit.csv'),header=None)\n","sub.columns = ['id','state']"],"metadata":{"id":"Q988lRbI-AzX","executionInfo":{"status":"ok","timestamp":1663219962827,"user_tz":-540,"elapsed":1102,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def remove_URL(text):\n","    url = re.compile(r'https?://\\S+|www\\.\\S+')\n","    return url.sub('',text)\n","\n","def remove_html(text):\n","    html=re.compile(r\"<[^>]*?>\")\n","    return html.sub('',text)\n","\n","def cleaning(texts):\n","    clean_texts = []\n","    for text in texts:\n","        # htmlタグを削除\n","        text = remove_URL(text)\n","        text = remove_html(text)\n","        #アルファベット以外をスペースに置き換え\n","        #clean_punc = re.sub(r'[^a-zA-Z]', ' ', text)\n","        #改行削除\n","        #text = text.replace(\"\\n\",\"\")\n","        clean_texts.append(text)\n","    return clean_texts\n","\n","def get_goal_values(df):\n","  df[\"goal\"].replace(\"100000+\",\"100000-100000\",inplace=True)\n","  _df = df[\"goal\"].str.split('-').apply(pd.Series).astype(float)\n","  _df.columns = [\"goal_max\",\"goal_min\"]\n","  df[\"goal_max\"] = _df[\"goal_max\"].astype(str)\n","  df[\"goal_min\"] = _df[\"goal_min\"].astype(str)\n","  df[\"goal_median\"] = _df[[\"goal_max\",\"goal_min\"]].median(axis=1)\n","  df[\"goal_median\"] = df[\"goal_median\"].astype(int)\n","  return df\n","\n","if CFG.clean_content==True:\n","    train['html_content'] = train['html_content'].map(lambda x: str(x))\n","    train['html_content'] = train['html_content'].apply(html.unescape)\n","    p = re.compile(r\"<[^>]*?>|&amp;|[/'’\\\"”]\")\n","    train['html_content'] = train['html_content'].map(lambda x: p.sub(\"\", x))\n","    train['html_content'] = train['html_content'].map(lambda x: x.lstrip())\n","    train['html_content'] = train['html_content'].fillna('missing')\n","\n","train = get_goal_values(train)\n","train['inputs'] = train.goal_median.astype(str) + ' [SEP] ' + train.duration.astype(str) + ' [SEP] ' + train.country + ' [SEP] ' + train.category1 + ' [SEP] ' + train.category2 + ' [SEP] ' + train.html_content"],"metadata":{"id":"VZDywrmo-G71","executionInfo":{"status":"ok","timestamp":1663219966669,"user_tz":-540,"elapsed":3844,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":641},"id":"haCa8vqHj4_Q","executionInfo":{"status":"ok","timestamp":1663219966670,"user_tz":-540,"elapsed":10,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"3c207116-0406-4e96-f495-978f2ebd44ea"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["               id           goal country  duration     category1  \\\n","0     train_00000    20001-21000      US        45           art   \n","1     train_00001    19001-20000      US        59          food   \n","2     train_00002      2001-3000      US        38           art   \n","3     train_00003      1001-2000      US        30           art   \n","4     train_00004      1001-2000      US        29  film & video   \n","...           ...            ...     ...       ...           ...   \n","9786  train_09786         1-1000      US        15         music   \n","9787  train_09787      3001-4000      CA        30       fashion   \n","9788  train_09788  100000-100000      GB        30    technology   \n","9789  train_09789    79001-80000      US        35    technology   \n","9790  train_09790      1001-2000      ES        30           art   \n","\n","             category2                                       html_content  \\\n","0          mixed media  http:dummy.comIn its first year, The Shillitos...   \n","1          restaurants  Cultural Pretzel Sports Bar is a place where p...   \n","2      performance art  I want to perform this piece guerilla style, o...   \n","3          mixed media  Canyon de Chelley, Dine (Navajo) Reservation, ...   \n","4            webseries  The story of the show, both on and off screen,...   \n","...                ...                                                ...   \n","9786  electronic music  So the story behind this is that Ive been maki...   \n","9787     ready-to-wear  THE HIGH CLOTHINGMy vision is to create high q...   \n","9788          software  We dont think anybody looks forward to filling...   \n","9789           gadgets  What is Droplet?\\nDroplet is a wireless button...   \n","9790    conceptual art  Artyoutube Art inspired in YoutubeMany popular...   \n","\n","      state  goal_max  goal_min  goal_median  \\\n","0         1   20001.0   21000.0        20500   \n","1         0   19001.0   20000.0        19500   \n","2         0    2001.0    3000.0         2500   \n","3         1    1001.0    2000.0         1500   \n","4         1    1001.0    2000.0         1500   \n","...     ...       ...       ...          ...   \n","9786      0       1.0    1000.0          500   \n","9787      0    3001.0    4000.0         3500   \n","9788      0  100000.0  100000.0       100000   \n","9789      1   79001.0   80000.0        79500   \n","9790      0    1001.0    2000.0         1500   \n","\n","                                                 inputs  \n","0     20500 [SEP] 45 [SEP] US [SEP] art [SEP] mixed ...  \n","1     19500 [SEP] 59 [SEP] US [SEP] food [SEP] resta...  \n","2     2500 [SEP] 38 [SEP] US [SEP] art [SEP] perform...  \n","3     1500 [SEP] 30 [SEP] US [SEP] art [SEP] mixed m...  \n","4     1500 [SEP] 29 [SEP] US [SEP] film & video [SEP...  \n","...                                                 ...  \n","9786  500 [SEP] 15 [SEP] US [SEP] music [SEP] electr...  \n","9787  3500 [SEP] 30 [SEP] CA [SEP] fashion [SEP] rea...  \n","9788  100000 [SEP] 30 [SEP] GB [SEP] technology [SEP...  \n","9789  79500 [SEP] 35 [SEP] US [SEP] technology [SEP]...  \n","9790  1500 [SEP] 30 [SEP] ES [SEP] art [SEP] concept...  \n","\n","[9791 rows x 12 columns]"],"text/html":["\n","  <div id=\"df-5a8659cb-d68c-42dc-84e9-5780898ccc56\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>goal</th>\n","      <th>country</th>\n","      <th>duration</th>\n","      <th>category1</th>\n","      <th>category2</th>\n","      <th>html_content</th>\n","      <th>state</th>\n","      <th>goal_max</th>\n","      <th>goal_min</th>\n","      <th>goal_median</th>\n","      <th>inputs</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>train_00000</td>\n","      <td>20001-21000</td>\n","      <td>US</td>\n","      <td>45</td>\n","      <td>art</td>\n","      <td>mixed media</td>\n","      <td>http:dummy.comIn its first year, The Shillitos...</td>\n","      <td>1</td>\n","      <td>20001.0</td>\n","      <td>21000.0</td>\n","      <td>20500</td>\n","      <td>20500 [SEP] 45 [SEP] US [SEP] art [SEP] mixed ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>train_00001</td>\n","      <td>19001-20000</td>\n","      <td>US</td>\n","      <td>59</td>\n","      <td>food</td>\n","      <td>restaurants</td>\n","      <td>Cultural Pretzel Sports Bar is a place where p...</td>\n","      <td>0</td>\n","      <td>19001.0</td>\n","      <td>20000.0</td>\n","      <td>19500</td>\n","      <td>19500 [SEP] 59 [SEP] US [SEP] food [SEP] resta...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>train_00002</td>\n","      <td>2001-3000</td>\n","      <td>US</td>\n","      <td>38</td>\n","      <td>art</td>\n","      <td>performance art</td>\n","      <td>I want to perform this piece guerilla style, o...</td>\n","      <td>0</td>\n","      <td>2001.0</td>\n","      <td>3000.0</td>\n","      <td>2500</td>\n","      <td>2500 [SEP] 38 [SEP] US [SEP] art [SEP] perform...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>train_00003</td>\n","      <td>1001-2000</td>\n","      <td>US</td>\n","      <td>30</td>\n","      <td>art</td>\n","      <td>mixed media</td>\n","      <td>Canyon de Chelley, Dine (Navajo) Reservation, ...</td>\n","      <td>1</td>\n","      <td>1001.0</td>\n","      <td>2000.0</td>\n","      <td>1500</td>\n","      <td>1500 [SEP] 30 [SEP] US [SEP] art [SEP] mixed m...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>train_00004</td>\n","      <td>1001-2000</td>\n","      <td>US</td>\n","      <td>29</td>\n","      <td>film &amp; video</td>\n","      <td>webseries</td>\n","      <td>The story of the show, both on and off screen,...</td>\n","      <td>1</td>\n","      <td>1001.0</td>\n","      <td>2000.0</td>\n","      <td>1500</td>\n","      <td>1500 [SEP] 29 [SEP] US [SEP] film &amp; video [SEP...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>9786</th>\n","      <td>train_09786</td>\n","      <td>1-1000</td>\n","      <td>US</td>\n","      <td>15</td>\n","      <td>music</td>\n","      <td>electronic music</td>\n","      <td>So the story behind this is that Ive been maki...</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>1000.0</td>\n","      <td>500</td>\n","      <td>500 [SEP] 15 [SEP] US [SEP] music [SEP] electr...</td>\n","    </tr>\n","    <tr>\n","      <th>9787</th>\n","      <td>train_09787</td>\n","      <td>3001-4000</td>\n","      <td>CA</td>\n","      <td>30</td>\n","      <td>fashion</td>\n","      <td>ready-to-wear</td>\n","      <td>THE HIGH CLOTHINGMy vision is to create high q...</td>\n","      <td>0</td>\n","      <td>3001.0</td>\n","      <td>4000.0</td>\n","      <td>3500</td>\n","      <td>3500 [SEP] 30 [SEP] CA [SEP] fashion [SEP] rea...</td>\n","    </tr>\n","    <tr>\n","      <th>9788</th>\n","      <td>train_09788</td>\n","      <td>100000-100000</td>\n","      <td>GB</td>\n","      <td>30</td>\n","      <td>technology</td>\n","      <td>software</td>\n","      <td>We dont think anybody looks forward to filling...</td>\n","      <td>0</td>\n","      <td>100000.0</td>\n","      <td>100000.0</td>\n","      <td>100000</td>\n","      <td>100000 [SEP] 30 [SEP] GB [SEP] technology [SEP...</td>\n","    </tr>\n","    <tr>\n","      <th>9789</th>\n","      <td>train_09789</td>\n","      <td>79001-80000</td>\n","      <td>US</td>\n","      <td>35</td>\n","      <td>technology</td>\n","      <td>gadgets</td>\n","      <td>What is Droplet?\\nDroplet is a wireless button...</td>\n","      <td>1</td>\n","      <td>79001.0</td>\n","      <td>80000.0</td>\n","      <td>79500</td>\n","      <td>79500 [SEP] 35 [SEP] US [SEP] technology [SEP]...</td>\n","    </tr>\n","    <tr>\n","      <th>9790</th>\n","      <td>train_09790</td>\n","      <td>1001-2000</td>\n","      <td>ES</td>\n","      <td>30</td>\n","      <td>art</td>\n","      <td>conceptual art</td>\n","      <td>Artyoutube Art inspired in YoutubeMany popular...</td>\n","      <td>0</td>\n","      <td>1001.0</td>\n","      <td>2000.0</td>\n","      <td>1500</td>\n","      <td>1500 [SEP] 30 [SEP] ES [SEP] art [SEP] concept...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>9791 rows × 12 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a8659cb-d68c-42dc-84e9-5780898ccc56')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5a8659cb-d68c-42dc-84e9-5780898ccc56 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5a8659cb-d68c-42dc-84e9-5780898ccc56');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["skf = StratifiedKFold(n_splits=CFG.n_fold,shuffle=True,random_state=CFG.seed)\n","for fold, ( _, val_) in enumerate(skf.split(train, train.state)):\n","    train.loc[val_ , \"kfold\"] = int(fold)\n","    \n","train[\"kfold\"] = train[\"kfold\"].astype(int)\n","\n","if CFG.debug:\n","    display(train.groupby('kfold').size())\n","    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n","    display(train.groupby('kfold').size())"],"metadata":{"id":"FR5JQ4UF-cjJ","executionInfo":{"status":"ok","timestamp":1663219966670,"user_tz":-540,"elapsed":6,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# tokenizer\n","# ====================================================\n","tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n","tokenizer.save_pretrained(OUTPUT_MODEL_DIR+'tokenizer/')\n","CFG.tokenizer = tokenizer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fz40KlX9-l-9","executionInfo":{"status":"ok","timestamp":1663219968925,"user_tz":-540,"elapsed":2261,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"159e5526-c6c5-4fc9-e683-673077f29e0f"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"code","source":["# ====================================================\n","# Define max_len\n","# ====================================================\n","#lengths = []\n","#tk0 = tqdm(train['inputs'].fillna(\"\").values, total=len(train))\n","#for text in tk0:\n","#    length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n","#    lengths.append(length)\n","#CFG.max_len = max(lengths) + 6 # cls & sep & sep\n","#LOGGER.info(f\"max_len: {CFG.max_len}\")"],"metadata":{"id":"DWuZSetq_jYN","executionInfo":{"status":"ok","timestamp":1663219968925,"user_tz":-540,"elapsed":11,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Dataset\n","# ====================================================\n","def prepare_input(cfg, text):\n","    inputs = cfg.tokenizer(text,\n","                           add_special_tokens=True,\n","                           max_length=cfg.max_len,\n","                           padding=\"max_length\",\n","                           return_offsets_mapping=False,\n","                           truncation=True)\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","    return inputs\n","\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.inputs = df['inputs'].values\n","        self.labels = df['state'].values\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, item):\n","        inputs = prepare_input(self.cfg, self.inputs[item])\n","        label = torch.tensor(self.labels[item], dtype=torch.float)\n","        return inputs, label\n","\n","#collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)"],"metadata":{"id":"krrca9D6-sja","executionInfo":{"status":"ok","timestamp":1663219968926,"user_tz":-540,"elapsed":10,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Model\n","# ====================================================\n","class MeanPooling(nn.Module):\n","    def __init__(self):\n","        super(MeanPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        mean_embeddings = sum_embeddings / sum_mask\n","        return mean_embeddings\n","\n","class MaxPooling(nn.Module):\n","    def __init__(self):\n","        super(MaxPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        embeddings = last_hidden_state.clone()\n","        embeddings[input_mask_expanded == 0] = -1e4\n","        max_embeddings, _ = torch.max(embeddings, dim=1)\n","        return max_embeddings\n","    \n","\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","            self.config.hidden_dropout = 0.\n","            self.config.hidden_dropout_prob = 0.\n","            self.config.attention_dropout = 0.\n","            self.config.attention_probs_dropout_prob = 0.\n","            LOGGER.info(self.config)\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel.from_config(self.config)\n","        if self.cfg.gradient_checkpointing:\n","            self.model.gradient_checkpointing_enable()\n","\n","        # Freezing\n","        if cfg.freezing:\n","            # freezing embeddings and first 2 layers of encoder\n","            freeze((self.model).embeddings)\n","            freeze((self.model).encoder.layer[:2])\n","            cfg.after_freezed_parameters = filter(lambda parameter: parameter.requires_grad, (self.model).parameters())\n","\n","        #self.pool = MeanPooling()\n","        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n","        self.fc = nn.Linear(self.config.hidden_size, cfg.target_size)\n","        self._init_weights(self.fc)\n","        self.attention = nn.Sequential(\n","            nn.Linear(self.config.hidden_size, 512),\n","            nn.Tanh(),\n","            nn.Linear(512, 1),\n","            nn.Softmax(dim=1)\n","        )\n","        self._init_weights(self.attention)\n","        \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","        \n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs[0]\n","        weights = self.attention(last_hidden_states)\n","        feature = torch.sum(weights * last_hidden_states, dim=1)\n","        return feature\n","\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","        output = self.fc(self.fc_dropout(feature))\n","        return output"],"metadata":{"id":"5c5Z1XB3_HrT","executionInfo":{"status":"ok","timestamp":1663219968926,"user_tz":-540,"elapsed":9,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["class AWP:\n","    def __init__(\n","        self,\n","        model,\n","        optimizer,\n","        criterion,\n","        adv_param=\"weight\",\n","        adv_lr=1e-4,\n","        adv_eps=1e-2,\n","        start_epoch=0,\n","        adv_step=1,\n","        device=\"cpu\",\n","    ):\n","        self.model = model\n","        self.optimizer = optimizer\n","        self.criterion = criterion\n","        self.adv_param = adv_param\n","        self.adv_lr = adv_lr\n","        self.adv_eps = adv_eps\n","        self.start_epoch = start_epoch\n","        self.adv_step = adv_step\n","        self.backup = {}\n","        self.backup_eps = {}\n","        self.device = device\n","\n","    def attack_backward(self, inputs, label):\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            self.save()\n","            self.attack_step() # モデルを近傍の悪い方へ改変\n","            y_preds = self.model(inputs)\n","            adv_loss = self.criterion(\n","                y_preds.view(-1, 1), label.view(-1, 1))\n","            mask = (label.view(-1, 1) != -1)\n","            adv_loss = torch.masked_select(adv_loss, mask).mean()\n","            self.optimizer.zero_grad()\n","        return adv_loss\n","        \n","        \n","\n","    def attack_step(self):\n","        e = 1e-6\n","        for name, param in self.model.named_parameters():\n","            if param.requires_grad and param.grad is not None and self.adv_param in name:\n","                norm1 = torch.norm(param.grad)\n","                norm2 = torch.norm(param.data.detach())\n","                if norm1 != 0 and not torch.isnan(norm1):\n","                    r_at = self.adv_lr * param.grad / (norm1 + e) * (norm2 + e)\n","                    param.data.add_(r_at)\n","                    param.data = torch.min(\n","                        torch.max(param.data, self.backup_eps[name][0]), self.backup_eps[name][1]\n","                    )\n","                # param.data.clamp_(*self.backup_eps[name])\n","\n","    def save(self):\n","        for name, param in self.model.named_parameters():\n","            if param.requires_grad and param.grad is not None and self.adv_param in name:\n","                if name not in self.backup:\n","                    self.backup[name] = param.data.clone()\n","                    grad_eps = self.adv_eps * param.abs().detach()\n","                    self.backup_eps[name] = (\n","                        self.backup[name] - grad_eps,\n","                        self.backup[name] + grad_eps,\n","                    )\n","\n","    def restore(self,):\n","        for name, param in self.model.named_parameters():\n","            if name in self.backup:\n","                param.data = self.backup[name]\n","        self.backup = {}\n","        self.backup_eps = {}"],"metadata":{"id":"SvURRSnUJn6A","executionInfo":{"status":"ok","timestamp":1663219968927,"user_tz":-540,"elapsed":9,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Helper functions\n","# ====================================================\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","\n","def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n","    #if not epoch < CFG.nth_awp_start_epoch:\n","    #    LOGGER.info(f'AWP training with epoch {epoch+1}')\n","    model.train()\n","    #awp = AWP(model=model,\n","    #          optimizer=optimizer,\n","    #          criterion=criterion,\n","    #          adv_eps=0.01, \n","    #          device=device)\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    global_step = 0\n","    #tot_loss = 0\n","    for step, (inputs, labels) in enumerate(train_loader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            y_preds = model(inputs)\n","        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","        #if CFG.nth_awp_start_epoch <= epoch:\n","        #      loss = awp.attack_backward(inputs, labels)\n","        #      scaler.scale(loss).backward()\n","        #      awp.restore()\n","        #tot_loss += loss.item()\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","            global_step += 1\n","            if CFG.batch_scheduler:\n","                scheduler.step()\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  'Grad: {grad_norm:.4f}  '\n","                  'LR: {lr:.8f}  '\n","                  .format(epoch+1, step, len(train_loader), \n","                          remain=timeSince(start, float(step+1)/len(train_loader)),\n","                          loss=losses,\n","                          grad_norm=grad_norm,\n","                          lr=scheduler.get_lr()[0]))\n","\n","    return losses.avg\n","    #model.train()\n","    #return tot_loss/(step+1)\n","\n","\n","def valid_fn(valid_loader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    preds = []\n","    start = end = time.time()\n","    for step, (inputs, labels) in enumerate(valid_loader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n","            print('EVAL: [{0}/{1}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  .format(step, len(valid_loader),\n","                          loss=losses,\n","                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n","    predictions = np.concatenate(preds)\n","    predictions = np.concatenate(predictions)\n","    return losses.avg, predictions\n","\n","\n","def inference_fn(test_loader, model, device):\n","    preds = []\n","    model.eval()\n","    model.to(device)\n","    tk0 = tqdm(test_loader, total=len(test_loader))\n","    for inputs in tk0:\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","    predictions = np.concatenate(preds)\n","    return predictions"],"metadata":{"id":"DTVWyY33BVR1","executionInfo":{"status":"ok","timestamp":1663219968927,"user_tz":-540,"elapsed":8,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# train loop\n","# ====================================================\n","def train_loop(folds, fold):\n","    \n","    LOGGER.info(f\"========== fold: {fold} training ==========\")\n","\n","    # ====================================================\n","    # loader\n","    # ====================================================\n","    train_folds = folds[folds['kfold'] != fold].reset_index(drop=True)\n","    valid_folds = folds[folds['kfold'] == fold].reset_index(drop=True)\n","    valid_labels = valid_folds['state'].values\n","    \n","    train_dataset = TrainDataset(CFG, train_folds)\n","    valid_dataset = TrainDataset(CFG, valid_folds)\n","\n","\n","    train_loader = DataLoader(train_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=True,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset,\n","                              batch_size=CFG.batch_size*2,\n","                              shuffle=False,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","\n","    # ====================================================\n","    # model & optimizer\n","    # ====================================================\n","    model = CustomModel(CFG, config_path=None, pretrained=True)\n","    torch.save(model.config, OUTPUT_MODEL_DIR+'config.pth')\n","    model.to(device)\n","    \n","    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n","        param_optimizer = list(model.named_parameters())\n","        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","        optimizer_parameters = [\n","            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': weight_decay},\n","            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': 0.0},\n","            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n","             'lr': decoder_lr, 'weight_decay': 0.0}\n","        ]\n","        return optimizer_parameters\n","\n","    optimizer_parameters = get_optimizer_params(model,\n","                                                encoder_lr=CFG.encoder_lr, \n","                                                decoder_lr=CFG.decoder_lr,\n","                                                weight_decay=CFG.weight_decay)\n","    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n","    \n","    # ====================================================\n","    # scheduler\n","    # ====================================================\n","    def get_scheduler(cfg, optimizer, num_train_steps):\n","        if cfg.scheduler == 'linear':\n","            scheduler = get_linear_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n","            )\n","        elif cfg.scheduler == 'cosine':\n","            scheduler = get_cosine_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","            )\n","        return scheduler\n","    \n","    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n","    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n","\n","    # ====================================================\n","    # loop\n","    # ====================================================\n","    criterion = nn.BCEWithLogitsLoss(reduction=\"mean\")\n","    \n","    best_score = 0.\n","\n","    for epoch in range(CFG.epochs):\n","\n","        start_time = time.time()\n","\n","        # train\n","        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n","\n","        # eval\n","        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n","        \n","        # scoring\n","        score = get_score(valid_labels, predictions)\n","\n","        elapsed = time.time() - start_time\n","\n","        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n","        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n","\n","        \n","        if best_score < score:\n","            best_score = score\n","            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","            torch.save({'model': model.state_dict(),\n","                        'predictions': predictions},\n","                        OUTPUT_MODEL_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n","\n","    predictions = torch.load(OUTPUT_MODEL_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", \n","                             map_location=torch.device('cpu'))['predictions']\n","    valid_folds['pred'] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    \n","    return valid_folds"],"metadata":{"id":"teu8DfxeCm1h","executionInfo":{"status":"ok","timestamp":1663219968927,"user_tz":-540,"elapsed":7,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["if __name__ == '__main__':\n","    \n","    def get_result(oof_df):\n","        labels = oof_df['state'].values\n","        preds = oof_df['pred'].values\n","        score = get_score(labels, preds)\n","        LOGGER.info(f'Score: {score:<.4f}')\n","    \n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for fold in range(CFG.n_fold):\n","            if fold in CFG.trn_fold:\n","                _oof_df = train_loop(train, fold)\n","                oof_df = pd.concat([oof_df, _oof_df])\n","                LOGGER.info(f\"========== fold: {fold} result ==========\")\n","                get_result(_oof_df)\n","        oof_df = oof_df.reset_index(drop=True)\n","        LOGGER.info(f\"========== CV ==========\")\n","        get_result(oof_df)\n","        oof_df.to_pickle(OUTPUT_MODEL_DIR+'oof_df.pkl')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Fnuz2nICrxj","outputId":"a1ddaca6-fa68-43c4-b5b2-3eaa7b823ce9","executionInfo":{"status":"ok","timestamp":1663225324022,"user_tz":-540,"elapsed":5355102,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":20,"outputs":[{"output_type":"stream","name":"stderr","text":["========== fold: 0 training ==========\n","INFO:__main__:========== fold: 0 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.22.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.22.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/458] Elapsed 0m 2s (remain 19m 8s) Loss: 0.6573(0.6573) Grad: 169677.0469  LR: 0.00002000  \n","Epoch: [1][100/458] Elapsed 1m 9s (remain 4m 4s) Loss: 0.6308(0.6440) Grad: 40969.8047  LR: 0.00001985  \n","Epoch: [1][200/458] Elapsed 2m 15s (remain 2m 53s) Loss: 0.3900(0.6167) Grad: 23699.0684  LR: 0.00001941  \n","Epoch: [1][300/458] Elapsed 3m 22s (remain 1m 45s) Loss: 0.5316(0.5896) Grad: 96095.6250  LR: 0.00001870  \n","Epoch: [1][400/458] Elapsed 4m 28s (remain 0m 38s) Loss: 0.5468(0.5749) Grad: 31599.9746  LR: 0.00001773  \n","Epoch: [1][457/458] Elapsed 5m 6s (remain 0m 0s) Loss: 0.6925(0.5656) Grad: 101732.7656  LR: 0.00001708  \n","EVAL: [0/77] Elapsed 0m 0s (remain 1m 11s) Loss: 0.4907(0.4907) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.5656  avg_val_loss: 0.5984  time: 333s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.5656  avg_val_loss: 0.5984  time: 333s\n","Epoch 1 - Score: 0.7608\n","INFO:__main__:Epoch 1 - Score: 0.7608\n","Epoch 1 - Save Best Score: 0.7608 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7608 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 0m 26s (remain 0m 0s) Loss: 0.6720(0.5984) \n","Epoch: [2][0/458] Elapsed 0m 1s (remain 9m 7s) Loss: 0.4288(0.4288) Grad: 396539.3438  LR: 0.00001707  \n","Epoch: [2][100/458] Elapsed 1m 8s (remain 4m 0s) Loss: 0.3709(0.4361) Grad: 80739.0312  LR: 0.00001576  \n","Epoch: [2][200/458] Elapsed 2m 14s (remain 2m 52s) Loss: 0.3444(0.4156) Grad: 60957.7227  LR: 0.00001428  \n","Epoch: [2][300/458] Elapsed 3m 21s (remain 1m 44s) Loss: 0.2358(0.4072) Grad: 63545.6875  LR: 0.00001268  \n","Epoch: [2][400/458] Elapsed 4m 27s (remain 0m 38s) Loss: 0.4177(0.4073) Grad: 56432.6367  LR: 0.00001100  \n","Epoch: [2][457/458] Elapsed 5m 5s (remain 0m 0s) Loss: 0.6131(0.4063) Grad: 100983.8750  LR: 0.00001003  \n","EVAL: [0/77] Elapsed 0m 0s (remain 1m 11s) Loss: 0.4337(0.4337) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.4063  avg_val_loss: 0.4377  time: 332s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.4063  avg_val_loss: 0.4377  time: 332s\n","Epoch 2 - Score: 0.7911\n","INFO:__main__:Epoch 2 - Score: 0.7911\n","Epoch 2 - Save Best Score: 0.7911 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.7911 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 0m 26s (remain 0m 0s) Loss: 0.5965(0.4377) \n","Epoch: [3][0/458] Elapsed 0m 1s (remain 8m 58s) Loss: 0.4162(0.4162) Grad: inf  LR: 0.00001001  \n","Epoch: [3][100/458] Elapsed 1m 7s (remain 3m 59s) Loss: 0.1596(0.3259) Grad: 44991.8711  LR: 0.00000830  \n","Epoch: [3][200/458] Elapsed 2m 14s (remain 2m 51s) Loss: 0.1919(0.3110) Grad: 78931.9062  LR: 0.00000665  \n","Epoch: [3][300/458] Elapsed 3m 20s (remain 1m 44s) Loss: 0.0792(0.3099) Grad: 24117.0078  LR: 0.00000509  \n","Epoch: [3][400/458] Elapsed 4m 27s (remain 0m 37s) Loss: 0.1384(0.3039) Grad: 59220.4219  LR: 0.00000368  \n","Epoch: [3][457/458] Elapsed 5m 5s (remain 0m 0s) Loss: 0.6416(0.2993) Grad: 69694.6094  LR: 0.00000296  \n","EVAL: [0/77] Elapsed 0m 0s (remain 1m 8s) Loss: 0.3960(0.3960) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.2993  avg_val_loss: 0.4479  time: 331s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.2993  avg_val_loss: 0.4479  time: 331s\n","Epoch 3 - Score: 0.7987\n","INFO:__main__:Epoch 3 - Score: 0.7987\n","Epoch 3 - Save Best Score: 0.7987 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.7987 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 0m 26s (remain 0m 0s) Loss: 0.6474(0.4479) \n","Epoch: [4][0/458] Elapsed 0m 1s (remain 8m 55s) Loss: 0.1651(0.1651) Grad: 323343.6250  LR: 0.00000294  \n","Epoch: [4][100/458] Elapsed 1m 7s (remain 3m 59s) Loss: 0.0766(0.1987) Grad: 93782.8047  LR: 0.00000184  \n","Epoch: [4][200/458] Elapsed 2m 14s (remain 2m 51s) Loss: 0.1534(0.1967) Grad: 73292.6562  LR: 0.00000097  \n","Epoch: [4][300/458] Elapsed 3m 20s (remain 1m 44s) Loss: 0.1084(0.1945) Grad: 99828.2891  LR: 0.00000037  \n","Epoch: [4][400/458] Elapsed 4m 27s (remain 0m 38s) Loss: 0.1605(0.1937) Grad: 100499.7969  LR: 0.00000005  \n","Epoch: [4][457/458] Elapsed 5m 5s (remain 0m 0s) Loss: 0.4019(0.1938) Grad: 125410.1953  LR: 0.00000000  \n","EVAL: [0/77] Elapsed 0m 0s (remain 1m 14s) Loss: 0.4489(0.4489) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.1938  avg_val_loss: 0.4824  time: 332s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.1938  avg_val_loss: 0.4824  time: 332s\n","Epoch 4 - Score: 0.7948\n","INFO:__main__:Epoch 4 - Score: 0.7948\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 0m 26s (remain 0m 0s) Loss: 0.7348(0.4824) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 0 result ==========\n","INFO:__main__:========== fold: 0 result ==========\n","Score: 0.7987\n","INFO:__main__:Score: 0.7987\n","========== fold: 1 training ==========\n","INFO:__main__:========== fold: 1 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.22.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.22.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/458] Elapsed 0m 1s (remain 8m 15s) Loss: 1.0017(1.0017) Grad: inf  LR: 0.00002000  \n","Epoch: [1][100/458] Elapsed 1m 7s (remain 3m 58s) Loss: 0.3922(0.6421) Grad: 33988.6406  LR: 0.00001985  \n","Epoch: [1][200/458] Elapsed 2m 13s (remain 2m 51s) Loss: 0.5850(0.6034) Grad: 83063.1328  LR: 0.00001941  \n","Epoch: [1][300/458] Elapsed 3m 20s (remain 1m 44s) Loss: 0.3123(0.5909) Grad: 40023.3203  LR: 0.00001870  \n","Epoch: [1][400/458] Elapsed 4m 26s (remain 0m 37s) Loss: 0.6796(0.5759) Grad: 102541.1562  LR: 0.00001773  \n","Epoch: [1][457/458] Elapsed 5m 4s (remain 0m 0s) Loss: 0.3997(0.5713) Grad: 21613.6348  LR: 0.00001708  \n","EVAL: [0/77] Elapsed 0m 0s (remain 1m 6s) Loss: 0.4530(0.4530) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.5713  avg_val_loss: 0.4723  time: 331s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.5713  avg_val_loss: 0.4723  time: 331s\n","Epoch 1 - Score: 0.7502\n","INFO:__main__:Epoch 1 - Score: 0.7502\n","Epoch 1 - Save Best Score: 0.7502 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7502 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 0m 26s (remain 0m 0s) Loss: 0.4514(0.4723) \n","Epoch: [2][0/458] Elapsed 0m 1s (remain 8m 16s) Loss: 0.3423(0.3423) Grad: 168927.0625  LR: 0.00001707  \n","Epoch: [2][100/458] Elapsed 1m 7s (remain 3m 58s) Loss: 0.3691(0.4206) Grad: 31367.8828  LR: 0.00001576  \n","Epoch: [2][200/458] Elapsed 2m 13s (remain 2m 51s) Loss: 0.4162(0.4342) Grad: 38044.8125  LR: 0.00001428  \n","Epoch: [2][300/458] Elapsed 3m 20s (remain 1m 44s) Loss: 0.5409(0.4344) Grad: 69104.8359  LR: 0.00001268  \n","Epoch: [2][400/458] Elapsed 4m 26s (remain 0m 37s) Loss: 0.3376(0.4266) Grad: 39911.4648  LR: 0.00001100  \n","Epoch: [2][457/458] Elapsed 5m 4s (remain 0m 0s) Loss: 0.3330(0.4240) Grad: 56903.5977  LR: 0.00001003  \n","EVAL: [0/77] Elapsed 0m 1s (remain 1m 16s) Loss: 0.5066(0.5066) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.4240  avg_val_loss: 0.4677  time: 331s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.4240  avg_val_loss: 0.4677  time: 331s\n","Epoch 2 - Score: 0.8085\n","INFO:__main__:Epoch 2 - Score: 0.8085\n","Epoch 2 - Save Best Score: 0.8085 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.8085 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 0m 26s (remain 0m 0s) Loss: 0.6174(0.4677) \n","Epoch: [3][0/458] Elapsed 0m 1s (remain 8m 54s) Loss: 0.3301(0.3301) Grad: inf  LR: 0.00001001  \n","Epoch: [3][100/458] Elapsed 1m 7s (remain 3m 59s) Loss: 0.1212(0.3059) Grad: 95876.9062  LR: 0.00000830  \n","Epoch: [3][200/458] Elapsed 2m 13s (remain 2m 51s) Loss: 0.3672(0.3037) Grad: 183662.3750  LR: 0.00000665  \n","Epoch: [3][300/458] Elapsed 3m 20s (remain 1m 44s) Loss: 0.2966(0.2931) Grad: 160161.1875  LR: 0.00000509  \n","Epoch: [3][400/458] Elapsed 4m 26s (remain 0m 37s) Loss: 0.3152(0.2790) Grad: 197982.4219  LR: 0.00000368  \n","Epoch: [3][457/458] Elapsed 5m 4s (remain 0m 0s) Loss: 0.5343(0.2766) Grad: 347487.8438  LR: 0.00000296  \n","EVAL: [0/77] Elapsed 0m 0s (remain 1m 13s) Loss: 0.5352(0.5352) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.2766  avg_val_loss: 0.4537  time: 331s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.2766  avg_val_loss: 0.4537  time: 331s\n","Epoch 3 - Score: 0.8045\n","INFO:__main__:Epoch 3 - Score: 0.8045\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 0m 26s (remain 0m 0s) Loss: 0.3834(0.4537) \n","Epoch: [4][0/458] Elapsed 0m 1s (remain 8m 29s) Loss: 0.0496(0.0496) Grad: 215977.7812  LR: 0.00000294  \n","Epoch: [4][100/458] Elapsed 1m 7s (remain 3m 59s) Loss: 0.1931(0.2197) Grad: 309369.5625  LR: 0.00000184  \n","Epoch: [4][200/458] Elapsed 2m 14s (remain 2m 51s) Loss: 0.2413(0.2094) Grad: 218032.8281  LR: 0.00000097  \n","Epoch: [4][300/458] Elapsed 3m 20s (remain 1m 44s) Loss: 0.0834(0.2040) Grad: 63619.0156  LR: 0.00000037  \n","Epoch: [4][400/458] Elapsed 4m 27s (remain 0m 38s) Loss: 0.0563(0.2012) Grad: 76167.1016  LR: 0.00000005  \n","Epoch: [4][457/458] Elapsed 5m 5s (remain 0m 0s) Loss: 0.5009(0.1993) Grad: 90341.3906  LR: 0.00000000  \n","EVAL: [0/77] Elapsed 0m 0s (remain 1m 5s) Loss: 0.5710(0.5710) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.1993  avg_val_loss: 0.4713  time: 332s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.1993  avg_val_loss: 0.4713  time: 332s\n","Epoch 4 - Score: 0.8055\n","INFO:__main__:Epoch 4 - Score: 0.8055\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 0m 26s (remain 0m 0s) Loss: 0.4169(0.4713) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 1 result ==========\n","INFO:__main__:========== fold: 1 result ==========\n","Score: 0.8085\n","INFO:__main__:Score: 0.8085\n","========== fold: 2 training ==========\n","INFO:__main__:========== fold: 2 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.22.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.22.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/458] Elapsed 0m 1s (remain 8m 46s) Loss: 0.6499(0.6499) Grad: 195783.0781  LR: 0.00002000  \n","Epoch: [1][100/458] Elapsed 1m 7s (remain 3m 59s) Loss: 0.5673(0.6440) Grad: 33576.0820  LR: 0.00001985  \n","Epoch: [1][200/458] Elapsed 2m 14s (remain 2m 51s) Loss: 0.3423(0.6103) Grad: 10809.3701  LR: 0.00001941  \n","Epoch: [1][300/458] Elapsed 3m 20s (remain 1m 44s) Loss: 0.7294(0.5837) Grad: 42733.2461  LR: 0.00001870  \n","Epoch: [1][400/458] Elapsed 4m 27s (remain 0m 37s) Loss: 0.5022(0.5745) Grad: 25594.4961  LR: 0.00001773  \n","Epoch: [1][457/458] Elapsed 5m 5s (remain 0m 0s) Loss: 0.4886(0.5617) Grad: 23760.6699  LR: 0.00001708  \n","EVAL: [0/77] Elapsed 0m 0s (remain 1m 15s) Loss: 0.6371(0.6371) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.5617  avg_val_loss: 0.5077  time: 332s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.5617  avg_val_loss: 0.5077  time: 332s\n","Epoch 1 - Score: 0.7773\n","INFO:__main__:Epoch 1 - Score: 0.7773\n","Epoch 1 - Save Best Score: 0.7773 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7773 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 0m 26s (remain 0m 0s) Loss: 0.4244(0.5077) \n","Epoch: [2][0/458] Elapsed 0m 1s (remain 8m 55s) Loss: 0.3149(0.3149) Grad: inf  LR: 0.00001707  \n","Epoch: [2][100/458] Elapsed 1m 7s (remain 4m 0s) Loss: 0.2684(0.3836) Grad: 71954.2500  LR: 0.00001576  \n","Epoch: [2][200/458] Elapsed 2m 14s (remain 2m 51s) Loss: 0.4814(0.3949) Grad: 74330.7188  LR: 0.00001428  \n","Epoch: [2][300/458] Elapsed 3m 21s (remain 1m 44s) Loss: 0.3734(0.3918) Grad: 29405.5430  LR: 0.00001268  \n","Epoch: [2][400/458] Elapsed 4m 27s (remain 0m 38s) Loss: 0.3328(0.3839) Grad: 38736.5820  LR: 0.00001100  \n","Epoch: [2][457/458] Elapsed 5m 5s (remain 0m 0s) Loss: 0.3236(0.3840) Grad: 20348.8594  LR: 0.00001003  \n","EVAL: [0/77] Elapsed 0m 0s (remain 1m 11s) Loss: 0.4483(0.4483) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.3840  avg_val_loss: 0.4611  time: 332s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.3840  avg_val_loss: 0.4611  time: 332s\n","Epoch 2 - Score: 0.7764\n","INFO:__main__:Epoch 2 - Score: 0.7764\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 0m 26s (remain 0m 0s) Loss: 0.2037(0.4611) \n","Epoch: [3][0/458] Elapsed 0m 1s (remain 9m 7s) Loss: 0.1639(0.1639) Grad: inf  LR: 0.00001001  \n","Epoch: [3][100/458] Elapsed 1m 7s (remain 3m 59s) Loss: 0.3973(0.2980) Grad: 84281.4609  LR: 0.00000830  \n","Epoch: [3][200/458] Elapsed 2m 14s (remain 2m 51s) Loss: 0.0705(0.2936) Grad: 54911.3398  LR: 0.00000665  \n","Epoch: [3][300/458] Elapsed 3m 20s (remain 1m 44s) Loss: 0.3204(0.2901) Grad: 149446.4531  LR: 0.00000509  \n","Epoch: [3][400/458] Elapsed 4m 27s (remain 0m 38s) Loss: 0.1876(0.2853) Grad: 200413.1875  LR: 0.00000368  \n","Epoch: [3][457/458] Elapsed 5m 5s (remain 0m 0s) Loss: 0.2541(0.2811) Grad: 121664.0938  LR: 0.00000296  \n","EVAL: [0/77] Elapsed 0m 0s (remain 1m 9s) Loss: 0.4765(0.4765) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.2811  avg_val_loss: 0.5008  time: 332s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.2811  avg_val_loss: 0.5008  time: 332s\n","Epoch 3 - Score: 0.8036\n","INFO:__main__:Epoch 3 - Score: 0.8036\n","Epoch 3 - Save Best Score: 0.8036 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.8036 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 0m 26s (remain 0m 0s) Loss: 0.4207(0.5008) \n","Epoch: [4][0/458] Elapsed 0m 1s (remain 9m 9s) Loss: 0.2022(0.2022) Grad: 352247.6875  LR: 0.00000294  \n","Epoch: [4][100/458] Elapsed 1m 7s (remain 3m 59s) Loss: 0.2100(0.2078) Grad: 222714.8281  LR: 0.00000184  \n","Epoch: [4][200/458] Elapsed 2m 14s (remain 2m 51s) Loss: 0.2128(0.2195) Grad: 116179.0391  LR: 0.00000097  \n","Epoch: [4][300/458] Elapsed 3m 20s (remain 1m 44s) Loss: 0.0667(0.2249) Grad: 41725.5234  LR: 0.00000037  \n","Epoch: [4][400/458] Elapsed 4m 27s (remain 0m 38s) Loss: 0.2250(0.2227) Grad: 165062.0625  LR: 0.00000005  \n","Epoch: [4][457/458] Elapsed 5m 5s (remain 0m 0s) Loss: 0.1024(0.2213) Grad: 96645.0781  LR: 0.00000000  \n","EVAL: [0/77] Elapsed 0m 0s (remain 1m 12s) Loss: 0.4485(0.4485) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.2213  avg_val_loss: 0.5020  time: 332s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.2213  avg_val_loss: 0.5020  time: 332s\n","Epoch 4 - Score: 0.7929\n","INFO:__main__:Epoch 4 - Score: 0.7929\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 0m 26s (remain 0m 0s) Loss: 0.3485(0.5020) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 2 result ==========\n","INFO:__main__:========== fold: 2 result ==========\n","Score: 0.8036\n","INFO:__main__:Score: 0.8036\n","========== fold: 3 training ==========\n","INFO:__main__:========== fold: 3 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.22.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.22.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/459] Elapsed 0m 1s (remain 8m 34s) Loss: 0.8723(0.8723) Grad: inf  LR: 0.00002000  \n","Epoch: [1][100/459] Elapsed 1m 7s (remain 3m 59s) Loss: 0.6418(0.6367) Grad: 29832.8789  LR: 0.00001985  \n","Epoch: [1][200/459] Elapsed 2m 13s (remain 2m 51s) Loss: 0.6591(0.5996) Grad: 56452.5938  LR: 0.00001941  \n","Epoch: [1][300/459] Elapsed 3m 20s (remain 1m 45s) Loss: 0.5200(0.5825) Grad: 28776.4941  LR: 0.00001870  \n","Epoch: [1][400/459] Elapsed 4m 26s (remain 0m 38s) Loss: 0.5090(0.5633) Grad: 28020.2480  LR: 0.00001774  \n","Epoch: [1][458/459] Elapsed 5m 5s (remain 0m 0s) Loss: 0.3253(0.5584) Grad: 27315.6230  LR: 0.00001707  \n","EVAL: [0/77] Elapsed 0m 0s (remain 1m 15s) Loss: 0.4348(0.4348) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.5584  avg_val_loss: 0.4515  time: 332s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.5584  avg_val_loss: 0.4515  time: 332s\n","Epoch 1 - Score: 0.7933\n","INFO:__main__:Epoch 1 - Score: 0.7933\n","Epoch 1 - Save Best Score: 0.7933 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7933 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 0m 26s (remain 0m 0s) Loss: 0.4114(0.4515) \n","Epoch: [2][0/459] Elapsed 0m 1s (remain 9m 14s) Loss: 0.4591(0.4591) Grad: 210883.2500  LR: 0.00001706  \n","Epoch: [2][100/459] Elapsed 1m 7s (remain 3m 59s) Loss: 0.4513(0.3827) Grad: 80603.7188  LR: 0.00001575  \n","Epoch: [2][200/459] Elapsed 2m 14s (remain 2m 52s) Loss: 1.1233(0.3986) Grad: 203492.5312  LR: 0.00001427  \n","Epoch: [2][300/459] Elapsed 3m 20s (remain 1m 45s) Loss: 0.2948(0.4023) Grad: 83219.9062  LR: 0.00001267  \n","Epoch: [2][400/459] Elapsed 4m 26s (remain 0m 38s) Loss: 0.6591(0.4080) Grad: 64826.6133  LR: 0.00001099  \n","Epoch: [2][458/459] Elapsed 5m 5s (remain 0m 0s) Loss: 0.2838(0.4048) Grad: 77169.2422  LR: 0.00001000  \n","EVAL: [0/77] Elapsed 0m 0s (remain 1m 12s) Loss: 0.3603(0.3603) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.4048  avg_val_loss: 0.4023  time: 332s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.4048  avg_val_loss: 0.4023  time: 332s\n","Epoch 2 - Score: 0.8111\n","INFO:__main__:Epoch 2 - Score: 0.8111\n","Epoch 2 - Save Best Score: 0.8111 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.8111 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 0m 26s (remain 0m 0s) Loss: 0.3621(0.4023) \n","Epoch: [3][0/459] Elapsed 0m 1s (remain 8m 48s) Loss: 0.2315(0.2315) Grad: 260940.9062  LR: 0.00000998  \n","Epoch: [3][100/459] Elapsed 1m 7s (remain 3m 59s) Loss: 0.2790(0.2860) Grad: 116433.9766  LR: 0.00000828  \n","Epoch: [3][200/459] Elapsed 2m 13s (remain 2m 51s) Loss: 0.2592(0.2720) Grad: 86943.9531  LR: 0.00000663  \n","Epoch: [3][300/459] Elapsed 3m 20s (remain 1m 45s) Loss: 0.4075(0.2659) Grad: 199688.5469  LR: 0.00000507  \n","Epoch: [3][400/459] Elapsed 4m 26s (remain 0m 38s) Loss: 0.2695(0.2657) Grad: 102898.4297  LR: 0.00000366  \n","Epoch: [3][458/459] Elapsed 5m 5s (remain 0m 0s) Loss: 0.1922(0.2644) Grad: 111710.4062  LR: 0.00000293  \n","EVAL: [0/77] Elapsed 0m 0s (remain 1m 10s) Loss: 0.4005(0.4005) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.2644  avg_val_loss: 0.4301  time: 332s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.2644  avg_val_loss: 0.4301  time: 332s\n","Epoch 3 - Score: 0.8205\n","INFO:__main__:Epoch 3 - Score: 0.8205\n","Epoch 3 - Save Best Score: 0.8205 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.8205 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 0m 26s (remain 0m 0s) Loss: 0.3739(0.4301) \n","Epoch: [4][0/459] Elapsed 0m 1s (remain 8m 42s) Loss: 0.2867(0.2867) Grad: 688704.9375  LR: 0.00000292  \n","Epoch: [4][100/459] Elapsed 1m 7s (remain 3m 59s) Loss: 0.1239(0.2032) Grad: 87385.5469  LR: 0.00000182  \n","Epoch: [4][200/459] Elapsed 2m 13s (remain 2m 51s) Loss: 0.1245(0.1948) Grad: 171430.0312  LR: 0.00000096  \n","Epoch: [4][300/459] Elapsed 3m 20s (remain 1m 45s) Loss: 0.1996(0.1902) Grad: 85315.9609  LR: 0.00000036  \n","Epoch: [4][400/459] Elapsed 4m 26s (remain 0m 38s) Loss: 0.1133(0.1865) Grad: 151616.4531  LR: 0.00000005  \n","Epoch: [4][458/459] Elapsed 5m 4s (remain 0m 0s) Loss: 0.3781(0.1903) Grad: 312059.5938  LR: 0.00000000  \n","EVAL: [0/77] Elapsed 0m 0s (remain 1m 9s) Loss: 0.4346(0.4346) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.1903  avg_val_loss: 0.4853  time: 331s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.1903  avg_val_loss: 0.4853  time: 331s\n","Epoch 4 - Score: 0.8120\n","INFO:__main__:Epoch 4 - Score: 0.8120\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 0m 26s (remain 0m 0s) Loss: 0.4331(0.4853) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 3 result ==========\n","INFO:__main__:========== fold: 3 result ==========\n","Score: 0.8205\n","INFO:__main__:Score: 0.8205\n","========== CV ==========\n","INFO:__main__:========== CV ==========\n","Score: 0.8079\n","INFO:__main__:Score: 0.8079\n"]}]},{"cell_type":"code","source":["A = pd.read_pickle(OUTPUT_MODEL_DIR+'oof_df.pkl')\n","A.head()"],"metadata":{"id":"0cHG0TUuknq7","colab":{"base_uri":"https://localhost:8080/","height":337},"executionInfo":{"status":"ok","timestamp":1663225324022,"user_tz":-540,"elapsed":7,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"f97f53ca-bb97-470c-a0cf-f5fd219a873d"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["            id         goal country  duration   category1        category2  \\\n","0  train_00002    2001-3000      US        38         art  performance art   \n","1  train_00006    2001-3000      CA        30       music  classical music   \n","2  train_00016    3001-4000      GB        30  journalism              web   \n","3  train_00017  11001-12000      US        30        food           drinks   \n","4  train_00018  12001-13000      US        28  journalism              web   \n","\n","                                        html_content  state goal_max goal_min  \\\n","0  I want to perform this piece guerilla style, o...      0   2001.0   3000.0   \n","1  The Crimson String Quartet (CSQ) is returning ...      1   2001.0   3000.0   \n","2  I am interested in setting up a small news web...      0   3001.0   4000.0   \n","3  Why Schenk-Atwood?Our neighborhood has just ab...      1  11001.0  12000.0   \n","4  Mega Visions app has been approved on all majo...      1  12001.0  13000.0   \n","\n","   goal_median                                             inputs  kfold  \\\n","0         2500  2500 [SEP] 38 [SEP] US [SEP] art [SEP] perform...      0   \n","1         2500  2500 [SEP] 30 [SEP] CA [SEP] music [SEP] class...      0   \n","2         3500  3500 [SEP] 30 [SEP] GB [SEP] journalism [SEP] ...      0   \n","3        11500  11500 [SEP] 30 [SEP] US [SEP] food [SEP] drink...      0   \n","4        12500  12500 [SEP] 28 [SEP] US [SEP] journalism [SEP]...      0   \n","\n","       pred  \n","0  0.680858  \n","1  0.905334  \n","2  0.004502  \n","3  0.141276  \n","4  0.216301  "],"text/html":["\n","  <div id=\"df-9839b407-d1f5-4723-a6a6-d436b1ff30d6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>goal</th>\n","      <th>country</th>\n","      <th>duration</th>\n","      <th>category1</th>\n","      <th>category2</th>\n","      <th>html_content</th>\n","      <th>state</th>\n","      <th>goal_max</th>\n","      <th>goal_min</th>\n","      <th>goal_median</th>\n","      <th>inputs</th>\n","      <th>kfold</th>\n","      <th>pred</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>train_00002</td>\n","      <td>2001-3000</td>\n","      <td>US</td>\n","      <td>38</td>\n","      <td>art</td>\n","      <td>performance art</td>\n","      <td>I want to perform this piece guerilla style, o...</td>\n","      <td>0</td>\n","      <td>2001.0</td>\n","      <td>3000.0</td>\n","      <td>2500</td>\n","      <td>2500 [SEP] 38 [SEP] US [SEP] art [SEP] perform...</td>\n","      <td>0</td>\n","      <td>0.680858</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>train_00006</td>\n","      <td>2001-3000</td>\n","      <td>CA</td>\n","      <td>30</td>\n","      <td>music</td>\n","      <td>classical music</td>\n","      <td>The Crimson String Quartet (CSQ) is returning ...</td>\n","      <td>1</td>\n","      <td>2001.0</td>\n","      <td>3000.0</td>\n","      <td>2500</td>\n","      <td>2500 [SEP] 30 [SEP] CA [SEP] music [SEP] class...</td>\n","      <td>0</td>\n","      <td>0.905334</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>train_00016</td>\n","      <td>3001-4000</td>\n","      <td>GB</td>\n","      <td>30</td>\n","      <td>journalism</td>\n","      <td>web</td>\n","      <td>I am interested in setting up a small news web...</td>\n","      <td>0</td>\n","      <td>3001.0</td>\n","      <td>4000.0</td>\n","      <td>3500</td>\n","      <td>3500 [SEP] 30 [SEP] GB [SEP] journalism [SEP] ...</td>\n","      <td>0</td>\n","      <td>0.004502</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>train_00017</td>\n","      <td>11001-12000</td>\n","      <td>US</td>\n","      <td>30</td>\n","      <td>food</td>\n","      <td>drinks</td>\n","      <td>Why Schenk-Atwood?Our neighborhood has just ab...</td>\n","      <td>1</td>\n","      <td>11001.0</td>\n","      <td>12000.0</td>\n","      <td>11500</td>\n","      <td>11500 [SEP] 30 [SEP] US [SEP] food [SEP] drink...</td>\n","      <td>0</td>\n","      <td>0.141276</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>train_00018</td>\n","      <td>12001-13000</td>\n","      <td>US</td>\n","      <td>28</td>\n","      <td>journalism</td>\n","      <td>web</td>\n","      <td>Mega Visions app has been approved on all majo...</td>\n","      <td>1</td>\n","      <td>12001.0</td>\n","      <td>13000.0</td>\n","      <td>12500</td>\n","      <td>12500 [SEP] 28 [SEP] US [SEP] journalism [SEP]...</td>\n","      <td>0</td>\n","      <td>0.216301</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9839b407-d1f5-4723-a6a6-d436b1ff30d6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9839b407-d1f5-4723-a6a6-d436b1ff30d6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9839b407-d1f5-4723-a6a6-d436b1ff30d6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":[],"metadata":{"id":"3vgWEX03TZjr","executionInfo":{"status":"ok","timestamp":1663225324023,"user_tz":-540,"elapsed":6,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":21,"outputs":[]}]}