{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMwKYGu/Y4mAxSyJj/TuwUG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"15b91534d76842e78cdb21818f75edab":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6542ddc6876d4fcfb37cbe22dcc4cee6","IPY_MODEL_ca25c68d289b4c3288ee8dd8fd3e1002","IPY_MODEL_43a844878e554441aea09647dbe6d976"],"layout":"IPY_MODEL_2e1240de36e94d3b9c9540d31efd73c0"}},"6542ddc6876d4fcfb37cbe22dcc4cee6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_700ba5f2eaa746f59ffb28c93d38283a","placeholder":"​","style":"IPY_MODEL_d4c647571a0340fbb0cea8a8a5a688ae","value":""}},"ca25c68d289b4c3288ee8dd8fd3e1002":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c1b8a70fc90c4f07a63bdaccfb788cf4","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_661b5e4aa06b425182685719060997ba","value":0}},"43a844878e554441aea09647dbe6d976":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5840c1d628da4438ad33e5d32fd80a73","placeholder":"​","style":"IPY_MODEL_a92561db3e2f4f0ebb37c125471371ca","value":" 0/0 [00:00&lt;?, ?it/s]"}},"2e1240de36e94d3b9c9540d31efd73c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"700ba5f2eaa746f59ffb28c93d38283a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4c647571a0340fbb0cea8a8a5a688ae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1b8a70fc90c4f07a63bdaccfb788cf4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"661b5e4aa06b425182685719060997ba":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5840c1d628da4438ad33e5d32fd80a73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a92561db3e2f4f0ebb37c125471371ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"875ab94fa7ae440e9036317413f326c8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b8b886b24e1a4fab891726d6e5d49771","IPY_MODEL_8cb6a6b6f08b4a76afc5944ef9396499","IPY_MODEL_0bdfa9a3d5594121aa443c623691ce84"],"layout":"IPY_MODEL_ea2570f69f0d4794a5c82fcbe34dc009"}},"b8b886b24e1a4fab891726d6e5d49771":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4614ff9e2b5943bdbe3bcb0158a02411","placeholder":"​","style":"IPY_MODEL_936d7cd8ea074f12a3c18c437559fd4f","value":"Downloading: 100%"}},"8cb6a6b6f08b4a76afc5944ef9396499":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_111b51acdbc04d5487800c487c59837f","max":26,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e57ccabd1cb64179a2d810b893509de8","value":26}},"0bdfa9a3d5594121aa443c623691ce84":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_660d34a8989845aea5cbbe75692313e0","placeholder":"​","style":"IPY_MODEL_0e1fbe95993e49c0a6404407734030f9","value":" 26.0/26.0 [00:00&lt;00:00, 292B/s]"}},"ea2570f69f0d4794a5c82fcbe34dc009":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4614ff9e2b5943bdbe3bcb0158a02411":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"936d7cd8ea074f12a3c18c437559fd4f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"111b51acdbc04d5487800c487c59837f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e57ccabd1cb64179a2d810b893509de8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"660d34a8989845aea5cbbe75692313e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e1fbe95993e49c0a6404407734030f9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0960a43242aa43fdbf43bcd0f5d942b8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c0f0a4b8633845fabdd7069176d452a4","IPY_MODEL_521a2efc73254c60a5acbe2f00ebfe53","IPY_MODEL_bff6df043e5a4841a04cfa489d24e7d1"],"layout":"IPY_MODEL_a32a2a89961e4290b6ac2249851f6350"}},"c0f0a4b8633845fabdd7069176d452a4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_04eb7399e89d4c7bb38be23a35218bdc","placeholder":"​","style":"IPY_MODEL_d30a541792bb4472acd1ff819557bba3","value":"Downloading: 100%"}},"521a2efc73254c60a5acbe2f00ebfe53":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad2601642a91416db3a578480a9b79c4","max":1154,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9bce8cce795d4ee1961572c05912752f","value":1154}},"bff6df043e5a4841a04cfa489d24e7d1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_227fd8ae14ec44ac8e6d0c95ebae1fef","placeholder":"​","style":"IPY_MODEL_26ac5c09d2ed474f93233decd8a61e5c","value":" 1.15k/1.15k [00:00&lt;00:00, 8.28kB/s]"}},"a32a2a89961e4290b6ac2249851f6350":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04eb7399e89d4c7bb38be23a35218bdc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d30a541792bb4472acd1ff819557bba3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ad2601642a91416db3a578480a9b79c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9bce8cce795d4ee1961572c05912752f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"227fd8ae14ec44ac8e6d0c95ebae1fef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26ac5c09d2ed474f93233decd8a61e5c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4dd148d4282d41c0a726b38edd72e9ee":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c7c1c0baa9b847c480a56e78e618d45a","IPY_MODEL_f0a1ed8b64af47388ea1bcd742278bd3","IPY_MODEL_10b920d27eaf428eadf61d31ed628c18"],"layout":"IPY_MODEL_3afe07987d714b9f9ce65b1af13fe825"}},"c7c1c0baa9b847c480a56e78e618d45a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2b3174cc7e24b4dad5b831c73d351a1","placeholder":"​","style":"IPY_MODEL_71cd1a85811e430899bd92d85ff59c88","value":"Downloading: 100%"}},"f0a1ed8b64af47388ea1bcd742278bd3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc3e0c19caa143d38ba79ead60e885b3","max":898822,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d9a81165e19c46ae9b3e6d07c7ad3cbf","value":898822}},"10b920d27eaf428eadf61d31ed628c18":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8da69c24315f457eaad39c33e90403b1","placeholder":"​","style":"IPY_MODEL_36afdb3f89554240947616b40c7bec98","value":" 899k/899k [00:00&lt;00:00, 1.66MB/s]"}},"3afe07987d714b9f9ce65b1af13fe825":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2b3174cc7e24b4dad5b831c73d351a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71cd1a85811e430899bd92d85ff59c88":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc3e0c19caa143d38ba79ead60e885b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9a81165e19c46ae9b3e6d07c7ad3cbf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8da69c24315f457eaad39c33e90403b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36afdb3f89554240947616b40c7bec98":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f7b74d1cfcd4485f8cca50cb0ac19cee":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7b0102e7581946889d97e9a55e1948d9","IPY_MODEL_a65bcf7668864965be7e6dd8610ec0bb","IPY_MODEL_5e7448716057403d8c15fd3110d79d81"],"layout":"IPY_MODEL_2fa0e7bdc8f3472389324e21018febf2"}},"7b0102e7581946889d97e9a55e1948d9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_97f3b7e83d4d45439ef8182b7b1f3481","placeholder":"​","style":"IPY_MODEL_e61f912018b94ae5882c627f74cabf19","value":"Downloading: 100%"}},"a65bcf7668864965be7e6dd8610ec0bb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ff1d5a74178488fa741555dc7d18ebf","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2428ed4befde4457a2a164ebe6f582d2","value":456318}},"5e7448716057403d8c15fd3110d79d81":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0407a947caa64a6a980a927cc176dc04","placeholder":"​","style":"IPY_MODEL_dce0406e4bc8451e8125f9b462205706","value":" 456k/456k [00:00&lt;00:00, 1.42MB/s]"}},"2fa0e7bdc8f3472389324e21018febf2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97f3b7e83d4d45439ef8182b7b1f3481":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e61f912018b94ae5882c627f74cabf19":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4ff1d5a74178488fa741555dc7d18ebf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2428ed4befde4457a2a164ebe6f582d2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0407a947caa64a6a980a927cc176dc04":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dce0406e4bc8451e8125f9b462205706":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d8136903c67546c88719fba78495fe7b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2c1f7c81fde74fa4aa2980b11d46fd0f","IPY_MODEL_6ba6a147936c43008f760bf6163b1ef9","IPY_MODEL_d1c1023ffb3e407fa2e50d06bf0d83de"],"layout":"IPY_MODEL_0144ddb40b4641caaebfaf1f9ff5962c"}},"2c1f7c81fde74fa4aa2980b11d46fd0f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_172a472de6504348938a2a91f7967653","placeholder":"​","style":"IPY_MODEL_bf2716d44c4e49cf8a4f3c9d890d0431","value":"Downloading: 100%"}},"6ba6a147936c43008f760bf6163b1ef9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2fdb2eba28734950b37cbe85791c0321","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9d0f52c1ef6d4b21ad34a9f0008157bb","value":1355863}},"d1c1023ffb3e407fa2e50d06bf0d83de":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_809d3a630e3748d5b1f67f400e305295","placeholder":"​","style":"IPY_MODEL_3ea7075db06f41d39ce26a7e27b28a11","value":" 1.36M/1.36M [00:00&lt;00:00, 3.70MB/s]"}},"0144ddb40b4641caaebfaf1f9ff5962c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"172a472de6504348938a2a91f7967653":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf2716d44c4e49cf8a4f3c9d890d0431":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2fdb2eba28734950b37cbe85791c0321":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d0f52c1ef6d4b21ad34a9f0008157bb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"809d3a630e3748d5b1f67f400e305295":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ea7075db06f41d39ce26a7e27b28a11":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"949091bd49654980afe0d8605ee9d56a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7746338d8a60461a89a8b204484b5526","IPY_MODEL_5fa4796545824f0ebe94fe6933e0ce9a","IPY_MODEL_8dec3a1683fc4ba5b47c0855821d3429"],"layout":"IPY_MODEL_46ecc005ac05479e804dba5a0fe2fad6"}},"7746338d8a60461a89a8b204484b5526":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a42a041d59d847f59e35c67a61a3e790","placeholder":"​","style":"IPY_MODEL_71a462f06181462b8a0163ae94363f90","value":"Downloading: 100%"}},"5fa4796545824f0ebe94fe6933e0ce9a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0fe9968265ea469c835e3b7d1dfdc0c6","max":1629486723,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0c93bdc795b845e6bfafae3e77da679e","value":1629486723}},"8dec3a1683fc4ba5b47c0855821d3429":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0374024e70294dad98dbb4fbadd3bfd7","placeholder":"​","style":"IPY_MODEL_c5c370a98610469b8e158773285b2035","value":" 1.63G/1.63G [00:31&lt;00:00, 58.9MB/s]"}},"46ecc005ac05479e804dba5a0fe2fad6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a42a041d59d847f59e35c67a61a3e790":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71a462f06181462b8a0163ae94363f90":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0fe9968265ea469c835e3b7d1dfdc0c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c93bdc795b845e6bfafae3e77da679e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0374024e70294dad98dbb4fbadd3bfd7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5c370a98610469b8e158773285b2035":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UtHPx5o75TKH","executionInfo":{"status":"ok","timestamp":1663570522275,"user_tz":-540,"elapsed":19337,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"a5342b2f-206f-4bb5-8d89-9d3fd9b73ae9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","source":["!pip install transformers\n","!pip install datasets\n","!pip install sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ign_5QW05bpr","executionInfo":{"status":"ok","timestamp":1663570539890,"user_tz":-540,"elapsed":17618,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"8e9aa25e-a1c5-4ac9-f72b-266ae6f24dad"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.22.1-py3-none-any.whl (4.9 MB)\n","\u001b[K     |████████████████████████████████| 4.9 MB 6.7 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.9.0\n","  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n","\u001b[K     |████████████████████████████████| 120 kB 72.0 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 55.6 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.22.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n","\u001b[K     |████████████████████████████████| 365 kB 7.3 MB/s \n","\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.12.0)\n","Collecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 63.6 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.9.1)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.8.2)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n","\u001b[K     |████████████████████████████████| 115 kB 68.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n","Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 35.8 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.2.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: urllib3, xxhash, responses, multiprocess, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed datasets-2.4.0 multiprocess-0.70.13 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 7.5 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n"]}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NHtchefz5goV","executionInfo":{"status":"ok","timestamp":1663570539890,"user_tz":-540,"elapsed":7,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"117640fd-895e-4885-c6e8-5dc17a33d0f9"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Sep 19 06:55:40 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   37C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["import os\n","import gc\n","import math\n","import time\n","import random\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.simplefilter('ignore')\n","from tqdm import tqdm\n","import re\n","import html\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim import Adam, SGD, AdamW, RAdam\n","from torch.optim import lr_scheduler\n","from torch.utils.data import DataLoader, Dataset\n","\n","from sklearn.model_selection import StratifiedKFold,StratifiedGroupKFold,GroupKFold\n","from sklearn.metrics import log_loss,f1_score\n","\n","from transformers import AutoModel, AutoConfig, AutoTokenizer, AdamW, DataCollatorWithPadding\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"_O7dPzvG5lLe","executionInfo":{"status":"ok","timestamp":1663570545523,"user_tz":-540,"elapsed":5637,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"colab":{"base_uri":"https://localhost:8080/","height":105,"referenced_widgets":["15b91534d76842e78cdb21818f75edab","6542ddc6876d4fcfb37cbe22dcc4cee6","ca25c68d289b4c3288ee8dd8fd3e1002","43a844878e554441aea09647dbe6d976","2e1240de36e94d3b9c9540d31efd73c0","700ba5f2eaa746f59ffb28c93d38283a","d4c647571a0340fbb0cea8a8a5a688ae","c1b8a70fc90c4f07a63bdaccfb788cf4","661b5e4aa06b425182685719060997ba","5840c1d628da4438ad33e5d32fd80a73","a92561db3e2f4f0ebb37c125471371ca"]},"outputId":"a1bef846-92a0-4477-acbf-c8668d64d6b5"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"]},{"output_type":"stream","name":"stdout","text":["Moving 0 files to the new cache system\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15b91534d76842e78cdb21818f75edab"}},"metadata":{}}]},{"cell_type":"code","source":["# ====================================================\n","# CFG\n","# ====================================================\n","class CFG:\n","    debug=False\n","    debug2 = False\n","    apex=True\n","    print_freq=100\n","    num_workers=4\n","    # model=\"microsoft/deberta-v3-base\"\n","    # model='microsoft/deberta-base'\n","    # model='roberta-base'\n","    # model='roberta-large'\n","    # model='roberta-large-mnli'\n","    # model='xlnet-large-cased'\n","    # model='albert-xxlarge-v2'\n","    # model=\"microsoft/deberta-large\"\n","    # model=\"microsoft/deberta-v3-large\"\n","    # model='microsoft/deberta-v2-xlarge'\n","    # model='funnel-transformer/large'\n","    # model='funnel-transformer/medium'\n","    # model='albert-base-v2'\n","    # model='albert-large-v2'\n","    # model='google/electra-large-discriminator'\n","    # model='google/electra-base-discriminator'\n","    model=\"facebook/bart-large-mnli\"\n","    # model=\"facebook/bart-large\"\n","    # model=\"facebook/bart-base\"\n","    scheduler='cosine' # ['linear', 'cosine']\n","    batch_scheduler=True\n","    num_cycles=0.5\n","    num_warmup_steps=0\n","    epochs=4\n","    encoder_lr=2e-5\n","    decoder_lr=2e-5\n","    min_lr=1e-6\n","    eps=1e-6\n","    betas=(0.9, 0.999)\n","    batch_size=16\n","    fc_dropout=0.2\n","    target_size=1\n","    max_len=180\n","    weight_decay=0.01\n","    gradient_accumulation_steps=1\n","    max_grad_norm=1000\n","    seed=42\n","    n_fold=4\n","    trn_fold=[0, 1, 2, 3]\n","    train=True\n","    nth_awp_start_epoch=1\n","    gradient_checkpointing = False\n","    freezing = False\n","    clean_content = True\n","\n","if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.trn_fold = [0, 1]\n","\n","if CFG.debug2:\n","    CFG.epochs = 3\n","    CFG.trn_fold = [0]"],"metadata":{"id":"4b5Y6si363K7","executionInfo":{"status":"ok","timestamp":1663570545523,"user_tz":-540,"elapsed":6,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["DIR = '/content/drive/MyDrive/Competitions/Signate/MUFJ'\n","INPUT_DIR = os.path.join(DIR,'input')\n","OUTPUT_DIR = os.path.join(DIR,'output')\n","OUTPUT_SUB_DIR = os.path.join(OUTPUT_DIR,'submission')\n","#OUTPUT_MODEL_DIR = os.path.join(OUTPUT_DIR,'model')\n","OUTPUT_MODEL_DIR = DIR + '/output/model/EXP45/'\n","if not os.path.exists(OUTPUT_MODEL_DIR):\n","    os.makedirs(OUTPUT_MODEL_DIR)"],"metadata":{"id":"Lo7k9Uzp93_J","executionInfo":{"status":"ok","timestamp":1663570546673,"user_tz":-540,"elapsed":1154,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def get_score(labels, outputs):\n","    thresh = 0.5\n","    y_pred = outputs\n","    y_true = labels\n","    return f1_score(y_true, (y_pred>thresh).astype(int))\n","\n","\n","def get_logger(filename=OUTPUT_MODEL_DIR+'train'):\n","    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","def seed_everything(seed=CFG.seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(seed=CFG.seed)\n","\n","def seed_worker(worker_id):\n","    worker_seed = torch.initial_seed() % 2**32\n","    np.random.seed(worker_seed)\n","    random.seed(worker_seed)\n","\n","g = torch.Generator()\n","g.manual_seed(CFG.seed)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7yfBWz8D99ZZ","executionInfo":{"status":"ok","timestamp":1663570546673,"user_tz":-540,"elapsed":5,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"c49fe4f4-287c-453e-9356-8deb99df1e3d"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7fda6f6b8eb0>"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["def freeze(module):\n","    \"\"\"\n","    Freezes module's parameters.\n","    \"\"\"\n","    \n","    for parameter in module.parameters():\n","        parameter.requires_grad = False\n","        \n","def get_freezed_parameters(module):\n","    \"\"\"\n","    Returns names of freezed parameters of the given module.\n","    \"\"\"\n","    \n","    freezed_parameters = []\n","    for name, parameter in module.named_parameters():\n","        if not parameter.requires_grad:\n","            freezed_parameters.append(name)\n","            \n","    return freezed_parameters\n","\n","def set_embedding_parameters_bits(embeddings_path, optim_bits=32):\n","    \"\"\"\n","    https://github.com/huggingface/transformers/issues/14819#issuecomment-1003427930\n","    \"\"\"\n","    \n","    embedding_types = (\"word\", \"position\", \"token_type\")\n","    for embedding_type in embedding_types:\n","        attr_name = f\"{embedding_type}_embeddings\"\n","        \n","        if hasattr(embeddings_path, attr_name): \n","            bnb.optim.GlobalOptimManager.get_instance().register_module_override(\n","                getattr(embeddings_path, attr_name), 'weight', {'optim_bits': optim_bits}\n","            )"],"metadata":{"id":"7Msw-Z4V-Q5q","executionInfo":{"status":"ok","timestamp":1663570546673,"user_tz":-540,"elapsed":2,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["train = pd.read_csv(os.path.join(INPUT_DIR,'train.csv'))\n","test = pd.read_csv(os.path.join(INPUT_DIR,'test.csv'))\n","sub = pd.read_csv(os.path.join(INPUT_DIR,'sample_submit.csv'),header=None)\n","sub.columns = ['id','state']"],"metadata":{"id":"Q988lRbI-AzX","executionInfo":{"status":"ok","timestamp":1663570549794,"user_tz":-540,"elapsed":3123,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def remove_URL(text):\n","    url = re.compile(r'https?://\\S+|www\\.\\S+')\n","    return url.sub('',text)\n","\n","def remove_html(text):\n","    html=re.compile(r\"<[^>]*?>\")\n","    return html.sub('',text)\n","\n","def cleaning(texts):\n","    clean_texts = []\n","    for text in texts:\n","        # htmlタグを削除\n","        text = remove_URL(text)\n","        text = remove_html(text)\n","        #アルファベット以外をスペースに置き換え\n","        #clean_punc = re.sub(r'[^a-zA-Z]', ' ', text)\n","        #改行削除\n","        #text = text.replace(\"\\n\",\"\")\n","        clean_texts.append(text)\n","    return clean_texts\n","\n","def get_goal_values(df):\n","  df[\"goal\"].replace(\"100000+\",\"100000-100000\",inplace=True)\n","  _df = df[\"goal\"].str.split('-').apply(pd.Series).astype(float)\n","  _df.columns = [\"goal_max\",\"goal_min\"]\n","  df[\"goal_max\"] = _df[\"goal_max\"].astype(str)\n","  df[\"goal_min\"] = _df[\"goal_min\"].astype(str)\n","  df[\"goal_median\"] = _df[[\"goal_max\",\"goal_min\"]].median(axis=1)\n","  df[\"goal_median\"] = df[\"goal_median\"].astype(int)\n","  return df\n","\n","if CFG.clean_content==True:\n","    train['html_content'] = train['html_content'].map(lambda x: str(x))\n","    train['html_content'] = train['html_content'].apply(html.unescape)\n","    p = re.compile(r\"<[^>]*?>|&amp;|[/'’\\\"”]\")\n","    train['html_content'] = train['html_content'].map(lambda x: p.sub(\"\", x))\n","    train['html_content'] = train['html_content'].map(lambda x: x.lstrip())\n","    train['html_content'] = train['html_content'].fillna('missing')\n","\n","train = get_goal_values(train)\n","train['inputs'] = train.goal_median.astype(str) + ' [SEP] ' + train.duration.astype(str) + ' [SEP] ' + train.country + ' [SEP] ' + train.category1 + ' [SEP] ' + train.category2 + ' [SEP] ' + train.html_content"],"metadata":{"id":"VZDywrmo-G71","executionInfo":{"status":"ok","timestamp":1663570553597,"user_tz":-540,"elapsed":3808,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":641},"id":"haCa8vqHj4_Q","executionInfo":{"status":"ok","timestamp":1663570553597,"user_tz":-540,"elapsed":17,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"447a856e-8e08-434f-8279-3c007a75b1fa"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["               id           goal country  duration     category1  \\\n","0     train_00000    20001-21000      US        45           art   \n","1     train_00001    19001-20000      US        59          food   \n","2     train_00002      2001-3000      US        38           art   \n","3     train_00003      1001-2000      US        30           art   \n","4     train_00004      1001-2000      US        29  film & video   \n","...           ...            ...     ...       ...           ...   \n","9786  train_09786         1-1000      US        15         music   \n","9787  train_09787      3001-4000      CA        30       fashion   \n","9788  train_09788  100000-100000      GB        30    technology   \n","9789  train_09789    79001-80000      US        35    technology   \n","9790  train_09790      1001-2000      ES        30           art   \n","\n","             category2                                       html_content  \\\n","0          mixed media  http:dummy.comIn its first year, The Shillitos...   \n","1          restaurants  Cultural Pretzel Sports Bar is a place where p...   \n","2      performance art  I want to perform this piece guerilla style, o...   \n","3          mixed media  Canyon de Chelley, Dine (Navajo) Reservation, ...   \n","4            webseries  The story of the show, both on and off screen,...   \n","...                ...                                                ...   \n","9786  electronic music  So the story behind this is that Ive been maki...   \n","9787     ready-to-wear  THE HIGH CLOTHINGMy vision is to create high q...   \n","9788          software  We dont think anybody looks forward to filling...   \n","9789           gadgets  What is Droplet?\\nDroplet is a wireless button...   \n","9790    conceptual art  Artyoutube Art inspired in YoutubeMany popular...   \n","\n","      state  goal_max  goal_min  goal_median  \\\n","0         1   20001.0   21000.0        20500   \n","1         0   19001.0   20000.0        19500   \n","2         0    2001.0    3000.0         2500   \n","3         1    1001.0    2000.0         1500   \n","4         1    1001.0    2000.0         1500   \n","...     ...       ...       ...          ...   \n","9786      0       1.0    1000.0          500   \n","9787      0    3001.0    4000.0         3500   \n","9788      0  100000.0  100000.0       100000   \n","9789      1   79001.0   80000.0        79500   \n","9790      0    1001.0    2000.0         1500   \n","\n","                                                 inputs  \n","0     20500 [SEP] 45 [SEP] US [SEP] art [SEP] mixed ...  \n","1     19500 [SEP] 59 [SEP] US [SEP] food [SEP] resta...  \n","2     2500 [SEP] 38 [SEP] US [SEP] art [SEP] perform...  \n","3     1500 [SEP] 30 [SEP] US [SEP] art [SEP] mixed m...  \n","4     1500 [SEP] 29 [SEP] US [SEP] film & video [SEP...  \n","...                                                 ...  \n","9786  500 [SEP] 15 [SEP] US [SEP] music [SEP] electr...  \n","9787  3500 [SEP] 30 [SEP] CA [SEP] fashion [SEP] rea...  \n","9788  100000 [SEP] 30 [SEP] GB [SEP] technology [SEP...  \n","9789  79500 [SEP] 35 [SEP] US [SEP] technology [SEP]...  \n","9790  1500 [SEP] 30 [SEP] ES [SEP] art [SEP] concept...  \n","\n","[9791 rows x 12 columns]"],"text/html":["\n","  <div id=\"df-e6492a32-feb0-4d1b-8dee-a4a976404c31\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>goal</th>\n","      <th>country</th>\n","      <th>duration</th>\n","      <th>category1</th>\n","      <th>category2</th>\n","      <th>html_content</th>\n","      <th>state</th>\n","      <th>goal_max</th>\n","      <th>goal_min</th>\n","      <th>goal_median</th>\n","      <th>inputs</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>train_00000</td>\n","      <td>20001-21000</td>\n","      <td>US</td>\n","      <td>45</td>\n","      <td>art</td>\n","      <td>mixed media</td>\n","      <td>http:dummy.comIn its first year, The Shillitos...</td>\n","      <td>1</td>\n","      <td>20001.0</td>\n","      <td>21000.0</td>\n","      <td>20500</td>\n","      <td>20500 [SEP] 45 [SEP] US [SEP] art [SEP] mixed ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>train_00001</td>\n","      <td>19001-20000</td>\n","      <td>US</td>\n","      <td>59</td>\n","      <td>food</td>\n","      <td>restaurants</td>\n","      <td>Cultural Pretzel Sports Bar is a place where p...</td>\n","      <td>0</td>\n","      <td>19001.0</td>\n","      <td>20000.0</td>\n","      <td>19500</td>\n","      <td>19500 [SEP] 59 [SEP] US [SEP] food [SEP] resta...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>train_00002</td>\n","      <td>2001-3000</td>\n","      <td>US</td>\n","      <td>38</td>\n","      <td>art</td>\n","      <td>performance art</td>\n","      <td>I want to perform this piece guerilla style, o...</td>\n","      <td>0</td>\n","      <td>2001.0</td>\n","      <td>3000.0</td>\n","      <td>2500</td>\n","      <td>2500 [SEP] 38 [SEP] US [SEP] art [SEP] perform...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>train_00003</td>\n","      <td>1001-2000</td>\n","      <td>US</td>\n","      <td>30</td>\n","      <td>art</td>\n","      <td>mixed media</td>\n","      <td>Canyon de Chelley, Dine (Navajo) Reservation, ...</td>\n","      <td>1</td>\n","      <td>1001.0</td>\n","      <td>2000.0</td>\n","      <td>1500</td>\n","      <td>1500 [SEP] 30 [SEP] US [SEP] art [SEP] mixed m...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>train_00004</td>\n","      <td>1001-2000</td>\n","      <td>US</td>\n","      <td>29</td>\n","      <td>film &amp; video</td>\n","      <td>webseries</td>\n","      <td>The story of the show, both on and off screen,...</td>\n","      <td>1</td>\n","      <td>1001.0</td>\n","      <td>2000.0</td>\n","      <td>1500</td>\n","      <td>1500 [SEP] 29 [SEP] US [SEP] film &amp; video [SEP...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>9786</th>\n","      <td>train_09786</td>\n","      <td>1-1000</td>\n","      <td>US</td>\n","      <td>15</td>\n","      <td>music</td>\n","      <td>electronic music</td>\n","      <td>So the story behind this is that Ive been maki...</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>1000.0</td>\n","      <td>500</td>\n","      <td>500 [SEP] 15 [SEP] US [SEP] music [SEP] electr...</td>\n","    </tr>\n","    <tr>\n","      <th>9787</th>\n","      <td>train_09787</td>\n","      <td>3001-4000</td>\n","      <td>CA</td>\n","      <td>30</td>\n","      <td>fashion</td>\n","      <td>ready-to-wear</td>\n","      <td>THE HIGH CLOTHINGMy vision is to create high q...</td>\n","      <td>0</td>\n","      <td>3001.0</td>\n","      <td>4000.0</td>\n","      <td>3500</td>\n","      <td>3500 [SEP] 30 [SEP] CA [SEP] fashion [SEP] rea...</td>\n","    </tr>\n","    <tr>\n","      <th>9788</th>\n","      <td>train_09788</td>\n","      <td>100000-100000</td>\n","      <td>GB</td>\n","      <td>30</td>\n","      <td>technology</td>\n","      <td>software</td>\n","      <td>We dont think anybody looks forward to filling...</td>\n","      <td>0</td>\n","      <td>100000.0</td>\n","      <td>100000.0</td>\n","      <td>100000</td>\n","      <td>100000 [SEP] 30 [SEP] GB [SEP] technology [SEP...</td>\n","    </tr>\n","    <tr>\n","      <th>9789</th>\n","      <td>train_09789</td>\n","      <td>79001-80000</td>\n","      <td>US</td>\n","      <td>35</td>\n","      <td>technology</td>\n","      <td>gadgets</td>\n","      <td>What is Droplet?\\nDroplet is a wireless button...</td>\n","      <td>1</td>\n","      <td>79001.0</td>\n","      <td>80000.0</td>\n","      <td>79500</td>\n","      <td>79500 [SEP] 35 [SEP] US [SEP] technology [SEP]...</td>\n","    </tr>\n","    <tr>\n","      <th>9790</th>\n","      <td>train_09790</td>\n","      <td>1001-2000</td>\n","      <td>ES</td>\n","      <td>30</td>\n","      <td>art</td>\n","      <td>conceptual art</td>\n","      <td>Artyoutube Art inspired in YoutubeMany popular...</td>\n","      <td>0</td>\n","      <td>1001.0</td>\n","      <td>2000.0</td>\n","      <td>1500</td>\n","      <td>1500 [SEP] 30 [SEP] ES [SEP] art [SEP] concept...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>9791 rows × 12 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6492a32-feb0-4d1b-8dee-a4a976404c31')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e6492a32-feb0-4d1b-8dee-a4a976404c31 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e6492a32-feb0-4d1b-8dee-a4a976404c31');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["skf = StratifiedKFold(n_splits=CFG.n_fold,shuffle=True,random_state=CFG.seed)\n","for fold, ( _, val_) in enumerate(skf.split(train, train.state)):\n","    train.loc[val_ , \"kfold\"] = int(fold)\n","    \n","train[\"kfold\"] = train[\"kfold\"].astype(int)\n","\n","if CFG.debug:\n","    display(train.groupby('kfold').size())\n","    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n","    display(train.groupby('kfold').size())"],"metadata":{"id":"FR5JQ4UF-cjJ","executionInfo":{"status":"ok","timestamp":1663570553598,"user_tz":-540,"elapsed":6,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# tokenizer\n","# ====================================================\n","tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n","tokenizer.save_pretrained(OUTPUT_MODEL_DIR+'tokenizer/')\n","CFG.tokenizer = tokenizer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":177,"referenced_widgets":["875ab94fa7ae440e9036317413f326c8","b8b886b24e1a4fab891726d6e5d49771","8cb6a6b6f08b4a76afc5944ef9396499","0bdfa9a3d5594121aa443c623691ce84","ea2570f69f0d4794a5c82fcbe34dc009","4614ff9e2b5943bdbe3bcb0158a02411","936d7cd8ea074f12a3c18c437559fd4f","111b51acdbc04d5487800c487c59837f","e57ccabd1cb64179a2d810b893509de8","660d34a8989845aea5cbbe75692313e0","0e1fbe95993e49c0a6404407734030f9","0960a43242aa43fdbf43bcd0f5d942b8","c0f0a4b8633845fabdd7069176d452a4","521a2efc73254c60a5acbe2f00ebfe53","bff6df043e5a4841a04cfa489d24e7d1","a32a2a89961e4290b6ac2249851f6350","04eb7399e89d4c7bb38be23a35218bdc","d30a541792bb4472acd1ff819557bba3","ad2601642a91416db3a578480a9b79c4","9bce8cce795d4ee1961572c05912752f","227fd8ae14ec44ac8e6d0c95ebae1fef","26ac5c09d2ed474f93233decd8a61e5c","4dd148d4282d41c0a726b38edd72e9ee","c7c1c0baa9b847c480a56e78e618d45a","f0a1ed8b64af47388ea1bcd742278bd3","10b920d27eaf428eadf61d31ed628c18","3afe07987d714b9f9ce65b1af13fe825","d2b3174cc7e24b4dad5b831c73d351a1","71cd1a85811e430899bd92d85ff59c88","bc3e0c19caa143d38ba79ead60e885b3","d9a81165e19c46ae9b3e6d07c7ad3cbf","8da69c24315f457eaad39c33e90403b1","36afdb3f89554240947616b40c7bec98","f7b74d1cfcd4485f8cca50cb0ac19cee","7b0102e7581946889d97e9a55e1948d9","a65bcf7668864965be7e6dd8610ec0bb","5e7448716057403d8c15fd3110d79d81","2fa0e7bdc8f3472389324e21018febf2","97f3b7e83d4d45439ef8182b7b1f3481","e61f912018b94ae5882c627f74cabf19","4ff1d5a74178488fa741555dc7d18ebf","2428ed4befde4457a2a164ebe6f582d2","0407a947caa64a6a980a927cc176dc04","dce0406e4bc8451e8125f9b462205706","d8136903c67546c88719fba78495fe7b","2c1f7c81fde74fa4aa2980b11d46fd0f","6ba6a147936c43008f760bf6163b1ef9","d1c1023ffb3e407fa2e50d06bf0d83de","0144ddb40b4641caaebfaf1f9ff5962c","172a472de6504348938a2a91f7967653","bf2716d44c4e49cf8a4f3c9d890d0431","2fdb2eba28734950b37cbe85791c0321","9d0f52c1ef6d4b21ad34a9f0008157bb","809d3a630e3748d5b1f67f400e305295","3ea7075db06f41d39ce26a7e27b28a11"]},"id":"fz40KlX9-l-9","executionInfo":{"status":"ok","timestamp":1663570559128,"user_tz":-540,"elapsed":5534,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"4b231e48-37a9-482f-cd55-226a646caa3b"},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"875ab94fa7ae440e9036317413f326c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0960a43242aa43fdbf43bcd0f5d942b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4dd148d4282d41c0a726b38edd72e9ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7b74d1cfcd4485f8cca50cb0ac19cee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8136903c67546c88719fba78495fe7b"}},"metadata":{}}]},{"cell_type":"code","source":["# ====================================================\n","# Define max_len\n","# ====================================================\n","#lengths = []\n","#tk0 = tqdm(train['inputs'].fillna(\"\").values, total=len(train))\n","#for text in tk0:\n","#    length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n","#    lengths.append(length)\n","#CFG.max_len = max(lengths) + 6 # cls & sep & sep\n","#LOGGER.info(f\"max_len: {CFG.max_len}\")"],"metadata":{"id":"DWuZSetq_jYN","executionInfo":{"status":"ok","timestamp":1663570559128,"user_tz":-540,"elapsed":13,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Dataset\n","# ====================================================\n","def prepare_input(cfg, text):\n","    inputs = cfg.tokenizer(text,\n","                           add_special_tokens=True,\n","                           max_length=cfg.max_len,\n","                           padding=\"max_length\",\n","                           return_offsets_mapping=False,\n","                           truncation=True)\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","    return inputs\n","\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.inputs = df['inputs'].values\n","        self.labels = df['state'].values\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, item):\n","        inputs = prepare_input(self.cfg, self.inputs[item])\n","        label = torch.tensor(self.labels[item], dtype=torch.float)\n","        return inputs, label\n","\n","#collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)"],"metadata":{"id":"krrca9D6-sja","executionInfo":{"status":"ok","timestamp":1663570559611,"user_tz":-540,"elapsed":493,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Model\n","# ====================================================\n","class MeanPooling(nn.Module):\n","    def __init__(self):\n","        super(MeanPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        mean_embeddings = sum_embeddings / sum_mask\n","        return mean_embeddings\n","\n","class MaxPooling(nn.Module):\n","    def __init__(self):\n","        super(MaxPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        embeddings = last_hidden_state.clone()\n","        embeddings[input_mask_expanded == 0] = -1e4\n","        max_embeddings, _ = torch.max(embeddings, dim=1)\n","        return max_embeddings\n","    \n","\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","            self.config.hidden_dropout = 0.\n","            self.config.hidden_dropout_prob = 0.\n","            self.config.attention_dropout = 0.\n","            self.config.attention_probs_dropout_prob = 0.\n","            LOGGER.info(self.config)\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel.from_config(self.config)\n","        if self.cfg.gradient_checkpointing:\n","            self.model.gradient_checkpointing_enable()\n","\n","        # Freezing\n","        if cfg.freezing:\n","            # freezing embeddings and first 2 layers of encoder\n","            freeze((self.model).embeddings)\n","            freeze((self.model).encoder.layer[:2])\n","            cfg.after_freezed_parameters = filter(lambda parameter: parameter.requires_grad, (self.model).parameters())\n","\n","        #self.pool = MeanPooling()\n","        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n","        self.fc = nn.Linear(self.config.hidden_size, cfg.target_size)\n","        #self._init_weights(self.fc)\n","        self.attention = nn.Sequential(\n","            nn.Linear(self.config.hidden_size, 512),\n","            nn.Tanh(),\n","            nn.Linear(512, 1),\n","            nn.Softmax(dim=1)\n","        )\n","        #self._init_weights(self.attention)\n","        \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","        \n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs[0]\n","        weights = self.attention(last_hidden_states)\n","        feature = torch.sum(weights * last_hidden_states, dim=1)\n","        return feature\n","\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","        output = self.fc(self.fc_dropout(feature))\n","        return output"],"metadata":{"id":"5c5Z1XB3_HrT","executionInfo":{"status":"ok","timestamp":1663570559611,"user_tz":-540,"elapsed":11,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["class AWP:\n","    def __init__(\n","        self,\n","        model,\n","        optimizer,\n","        criterion,\n","        adv_param=\"weight\",\n","        adv_lr=1e-4,\n","        adv_eps=1e-2,\n","        start_epoch=0,\n","        adv_step=1,\n","        device=\"cpu\",\n","    ):\n","        self.model = model\n","        self.optimizer = optimizer\n","        self.criterion = criterion\n","        self.adv_param = adv_param\n","        self.adv_lr = adv_lr\n","        self.adv_eps = adv_eps\n","        self.start_epoch = start_epoch\n","        self.adv_step = adv_step\n","        self.backup = {}\n","        self.backup_eps = {}\n","        self.device = device\n","\n","    def attack_backward(self, inputs, label):\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            self.save()\n","            self.attack_step() # モデルを近傍の悪い方へ改変\n","            y_preds = self.model(inputs)\n","            adv_loss = self.criterion(\n","                y_preds.view(-1, 1), label.view(-1, 1))\n","            mask = (label.view(-1, 1) != -1)\n","            adv_loss = torch.masked_select(adv_loss, mask).mean()\n","            self.optimizer.zero_grad()\n","        return adv_loss\n","        \n","        \n","\n","    def attack_step(self):\n","        e = 1e-6\n","        for name, param in self.model.named_parameters():\n","            if param.requires_grad and param.grad is not None and self.adv_param in name:\n","                norm1 = torch.norm(param.grad)\n","                norm2 = torch.norm(param.data.detach())\n","                if norm1 != 0 and not torch.isnan(norm1):\n","                    r_at = self.adv_lr * param.grad / (norm1 + e) * (norm2 + e)\n","                    param.data.add_(r_at)\n","                    param.data = torch.min(\n","                        torch.max(param.data, self.backup_eps[name][0]), self.backup_eps[name][1]\n","                    )\n","                # param.data.clamp_(*self.backup_eps[name])\n","\n","    def save(self):\n","        for name, param in self.model.named_parameters():\n","            if param.requires_grad and param.grad is not None and self.adv_param in name:\n","                if name not in self.backup:\n","                    self.backup[name] = param.data.clone()\n","                    grad_eps = self.adv_eps * param.abs().detach()\n","                    self.backup_eps[name] = (\n","                        self.backup[name] - grad_eps,\n","                        self.backup[name] + grad_eps,\n","                    )\n","\n","    def restore(self,):\n","        for name, param in self.model.named_parameters():\n","            if name in self.backup:\n","                param.data = self.backup[name]\n","        self.backup = {}\n","        self.backup_eps = {}"],"metadata":{"id":"SvURRSnUJn6A","executionInfo":{"status":"ok","timestamp":1663570559612,"user_tz":-540,"elapsed":10,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Helper functions\n","# ====================================================\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","\n","def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n","    #if not epoch < CFG.nth_awp_start_epoch:\n","    #    LOGGER.info(f'AWP training with epoch {epoch+1}')\n","    model.train()\n","    #awp = AWP(model=model,\n","    #          optimizer=optimizer,\n","    #          criterion=criterion,\n","    #          adv_eps=0.01, \n","    #          device=device)\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    global_step = 0\n","    #tot_loss = 0\n","    for step, (inputs, labels) in enumerate(train_loader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            y_preds = model(inputs)\n","        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","        #if CFG.nth_awp_start_epoch <= epoch:\n","        #      loss = awp.attack_backward(inputs, labels)\n","        #      scaler.scale(loss).backward()\n","        #      awp.restore()\n","        #tot_loss += loss.item()\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","            global_step += 1\n","            if CFG.batch_scheduler:\n","                scheduler.step()\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  'Grad: {grad_norm:.4f}  '\n","                  'LR: {lr:.8f}  '\n","                  .format(epoch+1, step, len(train_loader), \n","                          remain=timeSince(start, float(step+1)/len(train_loader)),\n","                          loss=losses,\n","                          grad_norm=grad_norm,\n","                          lr=scheduler.get_lr()[0]))\n","\n","    return losses.avg\n","    #model.train()\n","    #return tot_loss/(step+1)\n","\n","\n","def valid_fn(valid_loader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    preds = []\n","    start = end = time.time()\n","    for step, (inputs, labels) in enumerate(valid_loader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n","            print('EVAL: [{0}/{1}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  .format(step, len(valid_loader),\n","                          loss=losses,\n","                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n","    predictions = np.concatenate(preds)\n","    predictions = np.concatenate(predictions)\n","    return losses.avg, predictions\n","\n","\n","def inference_fn(test_loader, model, device):\n","    preds = []\n","    model.eval()\n","    model.to(device)\n","    tk0 = tqdm(test_loader, total=len(test_loader))\n","    for inputs in tk0:\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","    predictions = np.concatenate(preds)\n","    return predictions"],"metadata":{"id":"DTVWyY33BVR1","executionInfo":{"status":"ok","timestamp":1663570559612,"user_tz":-540,"elapsed":9,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# train loop\n","# ====================================================\n","def train_loop(folds, fold):\n","    \n","    LOGGER.info(f\"========== fold: {fold} training ==========\")\n","\n","    # ====================================================\n","    # loader\n","    # ====================================================\n","    train_folds = folds[folds['kfold'] != fold].reset_index(drop=True)\n","    valid_folds = folds[folds['kfold'] == fold].reset_index(drop=True)\n","    valid_labels = valid_folds['state'].values\n","    \n","    train_dataset = TrainDataset(CFG, train_folds)\n","    valid_dataset = TrainDataset(CFG, valid_folds)\n","\n","\n","    train_loader = DataLoader(train_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=True,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset,\n","                              batch_size=CFG.batch_size*2,\n","                              shuffle=False,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","\n","    # ====================================================\n","    # model & optimizer\n","    # ====================================================\n","    model = CustomModel(CFG, config_path=None, pretrained=True)\n","    torch.save(model.config, OUTPUT_MODEL_DIR+'config.pth')\n","    model.to(device)\n","    \n","    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n","        param_optimizer = list(model.named_parameters())\n","        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","        optimizer_parameters = [\n","            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': weight_decay},\n","            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': 0.0},\n","            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n","             'lr': decoder_lr, 'weight_decay': 0.0}\n","        ]\n","        return optimizer_parameters\n","\n","    optimizer_parameters = get_optimizer_params(model,\n","                                                encoder_lr=CFG.encoder_lr, \n","                                                decoder_lr=CFG.decoder_lr,\n","                                                weight_decay=CFG.weight_decay)\n","    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n","    \n","    # ====================================================\n","    # scheduler\n","    # ====================================================\n","    def get_scheduler(cfg, optimizer, num_train_steps):\n","        if cfg.scheduler == 'linear':\n","            scheduler = get_linear_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n","            )\n","        elif cfg.scheduler == 'cosine':\n","            scheduler = get_cosine_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","            )\n","        return scheduler\n","    \n","    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n","    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n","\n","    # ====================================================\n","    # loop\n","    # ====================================================\n","    criterion = nn.BCEWithLogitsLoss(reduction=\"mean\")\n","    \n","    best_score = 0.\n","\n","    for epoch in range(CFG.epochs):\n","\n","        start_time = time.time()\n","\n","        # train\n","        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n","\n","        # eval\n","        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n","        \n","        # scoring\n","        score = get_score(valid_labels, predictions)\n","\n","        elapsed = time.time() - start_time\n","\n","        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n","        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n","\n","        \n","        if best_score < score:\n","            best_score = score\n","            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","            torch.save({'model': model.state_dict(),\n","                        'predictions': predictions},\n","                        OUTPUT_MODEL_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n","\n","    predictions = torch.load(OUTPUT_MODEL_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", \n","                             map_location=torch.device('cpu'))['predictions']\n","    valid_folds['pred'] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    \n","    return valid_folds"],"metadata":{"id":"teu8DfxeCm1h","executionInfo":{"status":"ok","timestamp":1663570559612,"user_tz":-540,"elapsed":8,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["if __name__ == '__main__':\n","    \n","    def get_result(oof_df):\n","        labels = oof_df['state'].values\n","        preds = oof_df['pred'].values\n","        score = get_score(labels, preds)\n","        LOGGER.info(f'Score: {score:<.4f}')\n","    \n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for fold in range(CFG.n_fold):\n","            if fold in CFG.trn_fold:\n","                _oof_df = train_loop(train, fold)\n","                oof_df = pd.concat([oof_df, _oof_df])\n","                LOGGER.info(f\"========== fold: {fold} result ==========\")\n","                get_result(_oof_df)\n","        oof_df = oof_df.reset_index(drop=True)\n","        LOGGER.info(f\"========== CV ==========\")\n","        get_result(oof_df)\n","        oof_df.to_pickle(OUTPUT_MODEL_DIR+'oof_df.pkl')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["949091bd49654980afe0d8605ee9d56a","7746338d8a60461a89a8b204484b5526","5fa4796545824f0ebe94fe6933e0ce9a","8dec3a1683fc4ba5b47c0855821d3429","46ecc005ac05479e804dba5a0fe2fad6","a42a041d59d847f59e35c67a61a3e790","71a462f06181462b8a0163ae94363f90","0fe9968265ea469c835e3b7d1dfdc0c6","0c93bdc795b845e6bfafae3e77da679e","0374024e70294dad98dbb4fbadd3bfd7","c5c370a98610469b8e158773285b2035"]},"id":"6Fnuz2nICrxj","outputId":"0cb99146-1b8b-407c-8164-4198ed8bcfb7","executionInfo":{"status":"ok","timestamp":1663579851026,"user_tz":-540,"elapsed":9291421,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":20,"outputs":[{"output_type":"stream","name":"stderr","text":["========== fold: 0 training ==========\n","INFO:__main__:========== fold: 0 training ==========\n","BartConfig {\n","  \"_name_or_path\": \"facebook/bart-large-mnli\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForSequenceClassification\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"id2label\": {\n","    \"0\": \"contradiction\",\n","    \"1\": \"neutral\",\n","    \"2\": \"entailment\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"contradiction\": 0,\n","    \"entailment\": 2,\n","    \"neutral\": 1\n","  },\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"bart\",\n","  \"normalize_before\": false,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"output_past\": false,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": false,\n","  \"transformers_version\": \"4.22.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","INFO:__main__:BartConfig {\n","  \"_name_or_path\": \"facebook/bart-large-mnli\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForSequenceClassification\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"id2label\": {\n","    \"0\": \"contradiction\",\n","    \"1\": \"neutral\",\n","    \"2\": \"entailment\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"contradiction\": 0,\n","    \"entailment\": 2,\n","    \"neutral\": 1\n","  },\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"bart\",\n","  \"normalize_before\": false,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"output_past\": false,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": false,\n","  \"transformers_version\": \"4.22.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"949091bd49654980afe0d8605ee9d56a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at facebook/bart-large-mnli were not used when initializing BartModel: ['classification_head.dense.weight', 'classification_head.dense.bias', 'classification_head.out_proj.weight', 'classification_head.out_proj.bias']\n","- This IS expected if you are initializing BartModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BartModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/458] Elapsed 0m 5s (remain 38m 10s) Loss: 0.8660(0.8660) Grad: inf  LR: 0.00002000  \n","Epoch: [1][100/458] Elapsed 1m 58s (remain 7m 0s) Loss: 0.7295(0.6553) Grad: 352889.2812  LR: 0.00001985  \n","Epoch: [1][200/458] Elapsed 3m 52s (remain 4m 57s) Loss: 0.5238(0.6272) Grad: 214720.2188  LR: 0.00001941  \n","Epoch: [1][300/458] Elapsed 5m 46s (remain 3m 0s) Loss: 0.4334(0.5951) Grad: 281218.1562  LR: 0.00001870  \n","Epoch: [1][400/458] Elapsed 7m 40s (remain 1m 5s) Loss: 0.6132(0.5741) Grad: 313088.3438  LR: 0.00001773  \n","Epoch: [1][457/458] Elapsed 8m 45s (remain 0m 0s) Loss: 0.5555(0.5611) Grad: 394228.5000  LR: 0.00001708  \n","EVAL: [0/77] Elapsed 0m 1s (remain 1m 55s) Loss: 0.5957(0.5957) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.5611  avg_val_loss: 0.5344  time: 577s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.5611  avg_val_loss: 0.5344  time: 577s\n","Epoch 1 - Score: 0.6240\n","INFO:__main__:Epoch 1 - Score: 0.6240\n","Epoch 1 - Save Best Score: 0.6240 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.6240 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 0m 50s (remain 0m 0s) Loss: 0.3747(0.5344) \n","Epoch: [2][0/458] Elapsed 0m 1s (remain 13m 39s) Loss: 0.5403(0.5403) Grad: inf  LR: 0.00001707  \n","Epoch: [2][100/458] Elapsed 1m 55s (remain 6m 48s) Loss: 0.4054(0.4179) Grad: 332885.3125  LR: 0.00001576  \n","Epoch: [2][200/458] Elapsed 3m 49s (remain 4m 53s) Loss: 0.1358(0.4131) Grad: 111626.0469  LR: 0.00001428  \n","Epoch: [2][300/458] Elapsed 5m 42s (remain 2m 58s) Loss: 0.4757(0.4132) Grad: 292191.2500  LR: 0.00001268  \n","Epoch: [2][400/458] Elapsed 7m 36s (remain 1m 4s) Loss: 0.3907(0.4125) Grad: 385581.5938  LR: 0.00001100  \n","Epoch: [2][457/458] Elapsed 8m 41s (remain 0m 0s) Loss: 0.4373(0.4051) Grad: 289196.6875  LR: 0.00001003  \n","EVAL: [0/77] Elapsed 0m 1s (remain 2m 8s) Loss: 0.3312(0.3312) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.4051  avg_val_loss: 0.4324  time: 572s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.4051  avg_val_loss: 0.4324  time: 572s\n","Epoch 2 - Score: 0.8098\n","INFO:__main__:Epoch 2 - Score: 0.8098\n","Epoch 2 - Save Best Score: 0.8098 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.8098 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 0m 50s (remain 0m 0s) Loss: 0.2855(0.4324) \n","Epoch: [3][0/458] Elapsed 0m 1s (remain 13m 1s) Loss: 0.1584(0.1584) Grad: 298204.1562  LR: 0.00001001  \n","Epoch: [3][100/458] Elapsed 1m 54s (remain 6m 46s) Loss: 0.4679(0.3039) Grad: 393253.7812  LR: 0.00000830  \n","Epoch: [3][200/458] Elapsed 3m 48s (remain 4m 51s) Loss: 0.2440(0.3022) Grad: 463826.7812  LR: 0.00000665  \n","Epoch: [3][300/458] Elapsed 5m 41s (remain 2m 58s) Loss: 0.3387(0.2998) Grad: 432035.6250  LR: 0.00000509  \n","Epoch: [3][400/458] Elapsed 7m 34s (remain 1m 4s) Loss: 0.2649(0.2987) Grad: 311420.3750  LR: 0.00000368  \n","Epoch: [3][457/458] Elapsed 8m 39s (remain 0m 0s) Loss: 0.0911(0.2957) Grad: 164253.2656  LR: 0.00000296  \n","EVAL: [0/77] Elapsed 0m 1s (remain 1m 32s) Loss: 0.4006(0.4006) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.2957  avg_val_loss: 0.4619  time: 570s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.2957  avg_val_loss: 0.4619  time: 570s\n","Epoch 3 - Score: 0.8013\n","INFO:__main__:Epoch 3 - Score: 0.8013\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 0m 50s (remain 0m 0s) Loss: 0.3500(0.4619) \n","Epoch: [4][0/458] Elapsed 0m 1s (remain 12m 1s) Loss: 0.1083(0.1083) Grad: 408940.3438  LR: 0.00000294  \n","Epoch: [4][100/458] Elapsed 1m 54s (remain 6m 45s) Loss: 0.2343(0.1993) Grad: 388704.0000  LR: 0.00000184  \n","Epoch: [4][200/458] Elapsed 3m 48s (remain 4m 51s) Loss: 0.1019(0.1915) Grad: 251781.3594  LR: 0.00000097  \n","Epoch: [4][300/458] Elapsed 5m 41s (remain 2m 58s) Loss: 0.2173(0.1933) Grad: 169176.8594  LR: 0.00000037  \n","Epoch: [4][400/458] Elapsed 7m 34s (remain 1m 4s) Loss: 0.1987(0.1999) Grad: 368619.4062  LR: 0.00000005  \n","Epoch: [4][457/458] Elapsed 8m 39s (remain 0m 0s) Loss: 0.0366(0.1966) Grad: 79789.5547  LR: 0.00000000  \n","EVAL: [0/77] Elapsed 0m 1s (remain 1m 43s) Loss: 0.4770(0.4770) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.1966  avg_val_loss: 0.5654  time: 570s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.1966  avg_val_loss: 0.5654  time: 570s\n","Epoch 4 - Score: 0.8084\n","INFO:__main__:Epoch 4 - Score: 0.8084\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 0m 50s (remain 0m 0s) Loss: 0.5922(0.5654) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 0 result ==========\n","INFO:__main__:========== fold: 0 result ==========\n","Score: 0.8098\n","INFO:__main__:Score: 0.8098\n","========== fold: 1 training ==========\n","INFO:__main__:========== fold: 1 training ==========\n","BartConfig {\n","  \"_name_or_path\": \"facebook/bart-large-mnli\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForSequenceClassification\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"id2label\": {\n","    \"0\": \"contradiction\",\n","    \"1\": \"neutral\",\n","    \"2\": \"entailment\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"contradiction\": 0,\n","    \"entailment\": 2,\n","    \"neutral\": 1\n","  },\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"bart\",\n","  \"normalize_before\": false,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"output_past\": false,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": false,\n","  \"transformers_version\": \"4.22.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","INFO:__main__:BartConfig {\n","  \"_name_or_path\": \"facebook/bart-large-mnli\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForSequenceClassification\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"id2label\": {\n","    \"0\": \"contradiction\",\n","    \"1\": \"neutral\",\n","    \"2\": \"entailment\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"contradiction\": 0,\n","    \"entailment\": 2,\n","    \"neutral\": 1\n","  },\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"bart\",\n","  \"normalize_before\": false,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"output_past\": false,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": false,\n","  \"transformers_version\": \"4.22.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","Some weights of the model checkpoint at facebook/bart-large-mnli were not used when initializing BartModel: ['classification_head.dense.weight', 'classification_head.dense.bias', 'classification_head.out_proj.weight', 'classification_head.out_proj.bias']\n","- This IS expected if you are initializing BartModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BartModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/458] Elapsed 0m 1s (remain 12m 4s) Loss: 0.7227(0.7227) Grad: 277421.0625  LR: 0.00002000  \n","Epoch: [1][100/458] Elapsed 1m 54s (remain 6m 45s) Loss: 0.6283(0.6714) Grad: 128588.5703  LR: 0.00001985  \n","Epoch: [1][200/458] Elapsed 3m 47s (remain 4m 51s) Loss: 0.5463(0.6259) Grad: 216037.0000  LR: 0.00001941  \n","Epoch: [1][300/458] Elapsed 5m 40s (remain 2m 57s) Loss: 0.3907(0.5912) Grad: 261945.0312  LR: 0.00001870  \n","Epoch: [1][400/458] Elapsed 7m 33s (remain 1m 4s) Loss: 0.8763(0.5702) Grad: 536006.5000  LR: 0.00001773  \n","Epoch: [1][457/458] Elapsed 8m 38s (remain 0m 0s) Loss: 0.2795(0.5571) Grad: 99098.7422  LR: 0.00001708  \n","EVAL: [0/77] Elapsed 0m 0s (remain 1m 14s) Loss: 0.4376(0.4376) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.5571  avg_val_loss: 0.4366  time: 568s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.5571  avg_val_loss: 0.4366  time: 568s\n","Epoch 1 - Score: 0.8034\n","INFO:__main__:Epoch 1 - Score: 0.8034\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 0m 49s (remain 0m 0s) Loss: 0.5473(0.4366) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - Save Best Score: 0.8034 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.8034 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][0/458] Elapsed 0m 1s (remain 10m 31s) Loss: 0.4908(0.4908) Grad: inf  LR: 0.00001707  \n","Epoch: [2][100/458] Elapsed 1m 54s (remain 6m 44s) Loss: 0.3638(0.4475) Grad: 115213.2734  LR: 0.00001576  \n","Epoch: [2][200/458] Elapsed 3m 47s (remain 4m 50s) Loss: 0.4817(0.4353) Grad: 136370.1406  LR: 0.00001428  \n","Epoch: [2][300/458] Elapsed 5m 40s (remain 2m 57s) Loss: 0.3635(0.4447) Grad: 70210.1562  LR: 0.00001268  \n","Epoch: [2][400/458] Elapsed 7m 33s (remain 1m 4s) Loss: 0.7909(0.4438) Grad: 94339.9062  LR: 0.00001100  \n","Epoch: [2][457/458] Elapsed 8m 38s (remain 0m 0s) Loss: 0.4556(0.4380) Grad: 41855.0898  LR: 0.00001003  \n","EVAL: [0/77] Elapsed 0m 0s (remain 1m 15s) Loss: 0.4443(0.4443) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.4380  avg_val_loss: 0.4228  time: 568s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.4380  avg_val_loss: 0.4228  time: 568s\n","Epoch 2 - Score: 0.7634\n","INFO:__main__:Epoch 2 - Score: 0.7634\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 0m 49s (remain 0m 0s) Loss: 0.4109(0.4228) \n","Epoch: [3][0/458] Elapsed 0m 1s (remain 11m 20s) Loss: 0.3522(0.3522) Grad: 230120.5312  LR: 0.00001001  \n","Epoch: [3][100/458] Elapsed 1m 54s (remain 6m 44s) Loss: 0.3008(0.3173) Grad: 314307.4062  LR: 0.00000830  \n","Epoch: [3][200/458] Elapsed 3m 47s (remain 4m 50s) Loss: 0.1614(0.2955) Grad: 64856.0234  LR: 0.00000665  \n","Epoch: [3][300/458] Elapsed 5m 40s (remain 2m 57s) Loss: 0.1245(0.2931) Grad: 84466.5781  LR: 0.00000509  \n","Epoch: [3][400/458] Elapsed 7m 33s (remain 1m 4s) Loss: 0.2919(0.2881) Grad: 143103.1406  LR: 0.00000368  \n","Epoch: [3][457/458] Elapsed 8m 38s (remain 0m 0s) Loss: 0.1523(0.2842) Grad: 110709.7969  LR: 0.00000296  \n","EVAL: [0/77] Elapsed 0m 0s (remain 1m 9s) Loss: 0.5568(0.5568) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.2842  avg_val_loss: 0.4611  time: 568s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.2842  avg_val_loss: 0.4611  time: 568s\n","Epoch 3 - Score: 0.8178\n","INFO:__main__:Epoch 3 - Score: 0.8178\n","Epoch 3 - Save Best Score: 0.8178 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.8178 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 0m 49s (remain 0m 0s) Loss: 0.4793(0.4611) \n","Epoch: [4][0/458] Elapsed 0m 1s (remain 11m 0s) Loss: 0.1351(0.1351) Grad: 283376.0000  LR: 0.00000294  \n","Epoch: [4][100/458] Elapsed 1m 54s (remain 6m 45s) Loss: 0.2507(0.2103) Grad: 256640.7812  LR: 0.00000184  \n","Epoch: [4][200/458] Elapsed 3m 47s (remain 4m 51s) Loss: 0.0786(0.2062) Grad: 261617.0625  LR: 0.00000097  \n","Epoch: [4][300/458] Elapsed 5m 40s (remain 2m 57s) Loss: 0.0508(0.2003) Grad: 75075.9297  LR: 0.00000037  \n","Epoch: [4][400/458] Elapsed 7m 33s (remain 1m 4s) Loss: 0.0724(0.2049) Grad: 93393.9297  LR: 0.00000005  \n","Epoch: [4][457/458] Elapsed 8m 38s (remain 0m 0s) Loss: 0.1022(0.2031) Grad: 383121.3125  LR: 0.00000000  \n","EVAL: [0/77] Elapsed 0m 0s (remain 1m 11s) Loss: 0.6419(0.6419) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.2031  avg_val_loss: 0.5206  time: 568s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.2031  avg_val_loss: 0.5206  time: 568s\n","Epoch 4 - Score: 0.8182\n","INFO:__main__:Epoch 4 - Score: 0.8182\n","Epoch 4 - Save Best Score: 0.8182 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.8182 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 0m 49s (remain 0m 0s) Loss: 0.5304(0.5206) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 1 result ==========\n","INFO:__main__:========== fold: 1 result ==========\n","Score: 0.8182\n","INFO:__main__:Score: 0.8182\n","========== fold: 2 training ==========\n","INFO:__main__:========== fold: 2 training ==========\n","BartConfig {\n","  \"_name_or_path\": \"facebook/bart-large-mnli\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForSequenceClassification\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"id2label\": {\n","    \"0\": \"contradiction\",\n","    \"1\": \"neutral\",\n","    \"2\": \"entailment\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"contradiction\": 0,\n","    \"entailment\": 2,\n","    \"neutral\": 1\n","  },\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"bart\",\n","  \"normalize_before\": false,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"output_past\": false,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": false,\n","  \"transformers_version\": \"4.22.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","INFO:__main__:BartConfig {\n","  \"_name_or_path\": \"facebook/bart-large-mnli\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForSequenceClassification\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"id2label\": {\n","    \"0\": \"contradiction\",\n","    \"1\": \"neutral\",\n","    \"2\": \"entailment\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"contradiction\": 0,\n","    \"entailment\": 2,\n","    \"neutral\": 1\n","  },\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"bart\",\n","  \"normalize_before\": false,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"output_past\": false,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": false,\n","  \"transformers_version\": \"4.22.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","Some weights of the model checkpoint at facebook/bart-large-mnli were not used when initializing BartModel: ['classification_head.dense.weight', 'classification_head.dense.bias', 'classification_head.out_proj.weight', 'classification_head.out_proj.bias']\n","- This IS expected if you are initializing BartModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BartModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/458] Elapsed 0m 1s (remain 15m 9s) Loss: 0.6983(0.6983) Grad: 315915.9688  LR: 0.00002000  \n","Epoch: [1][100/458] Elapsed 1m 54s (remain 6m 46s) Loss: 0.4966(0.6742) Grad: 72276.2812  LR: 0.00001985  \n","Epoch: [1][200/458] Elapsed 3m 48s (remain 4m 51s) Loss: 0.5037(0.6321) Grad: 120007.3203  LR: 0.00001941  \n","Epoch: [1][300/458] Elapsed 5m 41s (remain 2m 57s) Loss: 0.5508(0.6066) Grad: 114996.0391  LR: 0.00001870  \n","Epoch: [1][400/458] Elapsed 7m 34s (remain 1m 4s) Loss: 0.3039(0.5746) Grad: 64527.0352  LR: 0.00001773  \n","Epoch: [1][457/458] Elapsed 8m 38s (remain 0m 0s) Loss: 0.8484(0.5599) Grad: 179411.2500  LR: 0.00001708  \n","EVAL: [0/77] Elapsed 0m 1s (remain 1m 21s) Loss: 0.3426(0.3426) \n","EVAL: [76/77] Elapsed 0m 49s (remain 0m 0s) Loss: 0.1891(0.4521) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.5599  avg_val_loss: 0.4521  time: 569s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.5599  avg_val_loss: 0.4521  time: 569s\n","Epoch 1 - Score: 0.7765\n","INFO:__main__:Epoch 1 - Score: 0.7765\n","Epoch 1 - Save Best Score: 0.7765 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7765 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][0/458] Elapsed 0m 1s (remain 11m 19s) Loss: 0.2981(0.2981) Grad: 396174.5938  LR: 0.00001707  \n","Epoch: [2][100/458] Elapsed 1m 54s (remain 6m 45s) Loss: 0.4108(0.3890) Grad: 236312.8750  LR: 0.00001576  \n","Epoch: [2][200/458] Elapsed 3m 47s (remain 4m 51s) Loss: 0.1995(0.3855) Grad: 148490.2031  LR: 0.00001428  \n","Epoch: [2][300/458] Elapsed 5m 40s (remain 2m 57s) Loss: 0.3548(0.3818) Grad: 132793.0469  LR: 0.00001268  \n","Epoch: [2][400/458] Elapsed 7m 33s (remain 1m 4s) Loss: 0.3317(0.3741) Grad: 189225.1094  LR: 0.00001100  \n","Epoch: [2][457/458] Elapsed 8m 38s (remain 0m 0s) Loss: 0.3041(0.3795) Grad: 93092.1562  LR: 0.00001003  \n","EVAL: [0/77] Elapsed 0m 1s (remain 1m 20s) Loss: 0.4380(0.4380) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.3795  avg_val_loss: 0.4438  time: 568s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.3795  avg_val_loss: 0.4438  time: 568s\n","Epoch 2 - Score: 0.7812\n","INFO:__main__:Epoch 2 - Score: 0.7812\n","Epoch 2 - Save Best Score: 0.7812 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.7812 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 0m 49s (remain 0m 0s) Loss: 0.2225(0.4438) \n","Epoch: [3][0/458] Elapsed 0m 1s (remain 11m 25s) Loss: 0.4143(0.4143) Grad: 520409.2812  LR: 0.00001001  \n","Epoch: [3][100/458] Elapsed 1m 54s (remain 6m 44s) Loss: 0.5281(0.3077) Grad: 137806.0469  LR: 0.00000830  \n","Epoch: [3][200/458] Elapsed 3m 47s (remain 4m 50s) Loss: 0.4018(0.2941) Grad: 150054.4062  LR: 0.00000665  \n","Epoch: [3][300/458] Elapsed 5m 40s (remain 2m 57s) Loss: 0.4431(0.2807) Grad: 229112.5469  LR: 0.00000509  \n","Epoch: [3][400/458] Elapsed 7m 33s (remain 1m 4s) Loss: 0.3193(0.2795) Grad: 242901.1562  LR: 0.00000368  \n","Epoch: [3][457/458] Elapsed 8m 37s (remain 0m 0s) Loss: 0.3641(0.2833) Grad: 320985.5312  LR: 0.00000296  \n","EVAL: [0/77] Elapsed 0m 1s (remain 1m 18s) Loss: 0.4124(0.4124) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.2833  avg_val_loss: 0.4772  time: 568s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.2833  avg_val_loss: 0.4772  time: 568s\n","Epoch 3 - Score: 0.8009\n","INFO:__main__:Epoch 3 - Score: 0.8009\n","Epoch 3 - Save Best Score: 0.8009 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.8009 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 0m 49s (remain 0m 0s) Loss: 0.1701(0.4772) \n","Epoch: [4][0/458] Elapsed 0m 1s (remain 11m 14s) Loss: 0.1600(0.1600) Grad: 355437.4688  LR: 0.00000294  \n","Epoch: [4][100/458] Elapsed 1m 54s (remain 6m 44s) Loss: 0.2915(0.1654) Grad: 302143.7188  LR: 0.00000184  \n","Epoch: [4][200/458] Elapsed 3m 47s (remain 4m 50s) Loss: 0.1215(0.1703) Grad: 283360.3125  LR: 0.00000097  \n","Epoch: [4][300/458] Elapsed 5m 40s (remain 2m 57s) Loss: 0.2565(0.1773) Grad: 167906.5156  LR: 0.00000037  \n","Epoch: [4][400/458] Elapsed 7m 33s (remain 1m 4s) Loss: 0.1336(0.1750) Grad: 102879.1016  LR: 0.00000005  \n","Epoch: [4][457/458] Elapsed 8m 37s (remain 0m 0s) Loss: 0.0613(0.1748) Grad: 28696.3281  LR: 0.00000000  \n","EVAL: [0/77] Elapsed 0m 1s (remain 1m 22s) Loss: 0.5343(0.5343) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.1748  avg_val_loss: 0.6382  time: 568s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.1748  avg_val_loss: 0.6382  time: 568s\n","Epoch 4 - Score: 0.8030\n","INFO:__main__:Epoch 4 - Score: 0.8030\n","Epoch 4 - Save Best Score: 0.8030 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.8030 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 0m 49s (remain 0m 0s) Loss: 0.2508(0.6382) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 2 result ==========\n","INFO:__main__:========== fold: 2 result ==========\n","Score: 0.8030\n","INFO:__main__:Score: 0.8030\n","========== fold: 3 training ==========\n","INFO:__main__:========== fold: 3 training ==========\n","BartConfig {\n","  \"_name_or_path\": \"facebook/bart-large-mnli\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForSequenceClassification\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"id2label\": {\n","    \"0\": \"contradiction\",\n","    \"1\": \"neutral\",\n","    \"2\": \"entailment\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"contradiction\": 0,\n","    \"entailment\": 2,\n","    \"neutral\": 1\n","  },\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"bart\",\n","  \"normalize_before\": false,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"output_past\": false,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": false,\n","  \"transformers_version\": \"4.22.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","INFO:__main__:BartConfig {\n","  \"_name_or_path\": \"facebook/bart-large-mnli\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForSequenceClassification\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"id2label\": {\n","    \"0\": \"contradiction\",\n","    \"1\": \"neutral\",\n","    \"2\": \"entailment\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"contradiction\": 0,\n","    \"entailment\": 2,\n","    \"neutral\": 1\n","  },\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"bart\",\n","  \"normalize_before\": false,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"output_past\": false,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": false,\n","  \"transformers_version\": \"4.22.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","Some weights of the model checkpoint at facebook/bart-large-mnli were not used when initializing BartModel: ['classification_head.dense.weight', 'classification_head.dense.bias', 'classification_head.out_proj.weight', 'classification_head.out_proj.bias']\n","- This IS expected if you are initializing BartModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BartModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/459] Elapsed 0m 1s (remain 13m 51s) Loss: 0.6624(0.6624) Grad: 269454.1875  LR: 0.00002000  \n","Epoch: [1][100/459] Elapsed 1m 54s (remain 6m 46s) Loss: 0.6403(0.6697) Grad: 263257.8438  LR: 0.00001985  \n","Epoch: [1][200/459] Elapsed 3m 47s (remain 4m 52s) Loss: 0.4869(0.6366) Grad: 191153.6719  LR: 0.00001941  \n","Epoch: [1][300/459] Elapsed 5m 40s (remain 2m 58s) Loss: 0.3984(0.6107) Grad: 124220.4062  LR: 0.00001870  \n","Epoch: [1][400/459] Elapsed 7m 33s (remain 1m 5s) Loss: 0.6138(0.5841) Grad: 214795.4844  LR: 0.00001774  \n","Epoch: [1][458/459] Elapsed 8m 39s (remain 0m 0s) Loss: 0.4172(0.5726) Grad: 75575.7891  LR: 0.00001707  \n","EVAL: [0/77] Elapsed 0m 1s (remain 1m 27s) Loss: 0.4019(0.4019) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.5726  avg_val_loss: 0.4614  time: 570s\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 0m 49s (remain 0m 0s) Loss: 0.5963(0.4614) \n"]},{"output_type":"stream","name":"stderr","text":["INFO:__main__:Epoch 1 - avg_train_loss: 0.5726  avg_val_loss: 0.4614  time: 570s\n","Epoch 1 - Score: 0.7190\n","INFO:__main__:Epoch 1 - Score: 0.7190\n","Epoch 1 - Save Best Score: 0.7190 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7190 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][0/459] Elapsed 0m 1s (remain 11m 24s) Loss: 0.4393(0.4393) Grad: 259854.6406  LR: 0.00001706  \n","Epoch: [2][100/459] Elapsed 1m 54s (remain 6m 46s) Loss: 0.2117(0.4134) Grad: 207405.5625  LR: 0.00001575  \n","Epoch: [2][200/459] Elapsed 3m 47s (remain 4m 52s) Loss: 0.2856(0.4030) Grad: 251915.6250  LR: 0.00001427  \n","Epoch: [2][300/459] Elapsed 5m 40s (remain 2m 58s) Loss: 0.6026(0.3899) Grad: 370860.7188  LR: 0.00001267  \n","Epoch: [2][400/459] Elapsed 7m 33s (remain 1m 5s) Loss: 0.1766(0.3877) Grad: 57564.8242  LR: 0.00001099  \n","Epoch: [2][458/459] Elapsed 8m 39s (remain 0m 0s) Loss: 0.2897(0.3902) Grad: 66220.7109  LR: 0.00001000  \n","EVAL: [0/77] Elapsed 0m 1s (remain 1m 21s) Loss: 0.4327(0.4327) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.3902  avg_val_loss: 0.3902  time: 569s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.3902  avg_val_loss: 0.3902  time: 569s\n","Epoch 2 - Score: 0.8072\n","INFO:__main__:Epoch 2 - Score: 0.8072\n","Epoch 2 - Save Best Score: 0.8072 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.8072 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 0m 49s (remain 0m 0s) Loss: 0.4301(0.3902) \n","Epoch: [3][0/459] Elapsed 0m 1s (remain 11m 18s) Loss: 0.3475(0.3475) Grad: 460313.4375  LR: 0.00000998  \n","Epoch: [3][100/459] Elapsed 1m 54s (remain 6m 46s) Loss: 0.4563(0.3262) Grad: 460285.3438  LR: 0.00000828  \n","Epoch: [3][200/459] Elapsed 3m 47s (remain 4m 52s) Loss: 0.4063(0.3140) Grad: 176267.6406  LR: 0.00000663  \n","Epoch: [3][300/459] Elapsed 5m 40s (remain 2m 58s) Loss: 0.2947(0.3077) Grad: 188056.5469  LR: 0.00000507  \n","Epoch: [3][400/459] Elapsed 7m 33s (remain 1m 5s) Loss: 0.5726(0.2913) Grad: 259780.8125  LR: 0.00000366  \n","Epoch: [3][458/459] Elapsed 8m 39s (remain 0m 0s) Loss: 0.3686(0.2968) Grad: 160262.8750  LR: 0.00000293  \n","EVAL: [0/77] Elapsed 0m 1s (remain 1m 18s) Loss: 0.4246(0.4246) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.2968  avg_val_loss: 0.4230  time: 569s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.2968  avg_val_loss: 0.4230  time: 569s\n","Epoch 3 - Score: 0.8150\n","INFO:__main__:Epoch 3 - Score: 0.8150\n","Epoch 3 - Save Best Score: 0.8150 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.8150 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 0m 49s (remain 0m 0s) Loss: 0.4134(0.4230) \n","Epoch: [4][0/459] Elapsed 0m 1s (remain 11m 14s) Loss: 0.4163(0.4163) Grad: 504424.2812  LR: 0.00000292  \n","Epoch: [4][100/459] Elapsed 1m 54s (remain 6m 45s) Loss: 0.2504(0.2151) Grad: 426893.9688  LR: 0.00000182  \n","Epoch: [4][200/459] Elapsed 3m 47s (remain 4m 52s) Loss: 0.1114(0.2056) Grad: 257770.2344  LR: 0.00000096  \n","Epoch: [4][300/459] Elapsed 5m 40s (remain 2m 58s) Loss: 0.1750(0.1940) Grad: 203207.9219  LR: 0.00000036  \n","Epoch: [4][400/459] Elapsed 7m 33s (remain 1m 5s) Loss: 0.2813(0.1898) Grad: 236803.5000  LR: 0.00000005  \n","Epoch: [4][458/459] Elapsed 8m 39s (remain 0m 0s) Loss: 0.1067(0.1899) Grad: 236133.5625  LR: 0.00000000  \n","EVAL: [0/77] Elapsed 0m 1s (remain 1m 21s) Loss: 0.5363(0.5363) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.1899  avg_val_loss: 0.5374  time: 569s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.1899  avg_val_loss: 0.5374  time: 569s\n","Epoch 4 - Score: 0.8147\n","INFO:__main__:Epoch 4 - Score: 0.8147\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 0m 49s (remain 0m 0s) Loss: 0.6104(0.5374) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 3 result ==========\n","INFO:__main__:========== fold: 3 result ==========\n","Score: 0.8150\n","INFO:__main__:Score: 0.8150\n","========== CV ==========\n","INFO:__main__:========== CV ==========\n","Score: 0.8115\n","INFO:__main__:Score: 0.8115\n"]}]},{"cell_type":"code","source":["A = pd.read_pickle(OUTPUT_MODEL_DIR+'oof_df.pkl')\n","A.head()"],"metadata":{"id":"0cHG0TUuknq7","colab":{"base_uri":"https://localhost:8080/","height":337},"executionInfo":{"status":"ok","timestamp":1663579851026,"user_tz":-540,"elapsed":17,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"136215c0-d9d8-4134-d31d-fa5ce5b66615"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["            id         goal country  duration   category1        category2  \\\n","0  train_00002    2001-3000      US        38         art  performance art   \n","1  train_00006    2001-3000      CA        30       music  classical music   \n","2  train_00016    3001-4000      GB        30  journalism              web   \n","3  train_00017  11001-12000      US        30        food           drinks   \n","4  train_00018  12001-13000      US        28  journalism              web   \n","\n","                                        html_content  state goal_max goal_min  \\\n","0  I want to perform this piece guerilla style, o...      0   2001.0   3000.0   \n","1  The Crimson String Quartet (CSQ) is returning ...      1   2001.0   3000.0   \n","2  I am interested in setting up a small news web...      0   3001.0   4000.0   \n","3  Why Schenk-Atwood?Our neighborhood has just ab...      1  11001.0  12000.0   \n","4  Mega Visions app has been approved on all majo...      1  12001.0  13000.0   \n","\n","   goal_median                                             inputs  kfold  \\\n","0         2500  2500 [SEP] 38 [SEP] US [SEP] art [SEP] perform...      0   \n","1         2500  2500 [SEP] 30 [SEP] CA [SEP] music [SEP] class...      0   \n","2         3500  3500 [SEP] 30 [SEP] GB [SEP] journalism [SEP] ...      0   \n","3        11500  11500 [SEP] 30 [SEP] US [SEP] food [SEP] drink...      0   \n","4        12500  12500 [SEP] 28 [SEP] US [SEP] journalism [SEP]...      0   \n","\n","       pred  \n","0  0.618032  \n","1  0.944546  \n","2  0.000720  \n","3  0.819439  \n","4  0.113744  "],"text/html":["\n","  <div id=\"df-0aedd5e7-f92a-4e14-b6c9-fb423d2e2933\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>goal</th>\n","      <th>country</th>\n","      <th>duration</th>\n","      <th>category1</th>\n","      <th>category2</th>\n","      <th>html_content</th>\n","      <th>state</th>\n","      <th>goal_max</th>\n","      <th>goal_min</th>\n","      <th>goal_median</th>\n","      <th>inputs</th>\n","      <th>kfold</th>\n","      <th>pred</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>train_00002</td>\n","      <td>2001-3000</td>\n","      <td>US</td>\n","      <td>38</td>\n","      <td>art</td>\n","      <td>performance art</td>\n","      <td>I want to perform this piece guerilla style, o...</td>\n","      <td>0</td>\n","      <td>2001.0</td>\n","      <td>3000.0</td>\n","      <td>2500</td>\n","      <td>2500 [SEP] 38 [SEP] US [SEP] art [SEP] perform...</td>\n","      <td>0</td>\n","      <td>0.618032</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>train_00006</td>\n","      <td>2001-3000</td>\n","      <td>CA</td>\n","      <td>30</td>\n","      <td>music</td>\n","      <td>classical music</td>\n","      <td>The Crimson String Quartet (CSQ) is returning ...</td>\n","      <td>1</td>\n","      <td>2001.0</td>\n","      <td>3000.0</td>\n","      <td>2500</td>\n","      <td>2500 [SEP] 30 [SEP] CA [SEP] music [SEP] class...</td>\n","      <td>0</td>\n","      <td>0.944546</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>train_00016</td>\n","      <td>3001-4000</td>\n","      <td>GB</td>\n","      <td>30</td>\n","      <td>journalism</td>\n","      <td>web</td>\n","      <td>I am interested in setting up a small news web...</td>\n","      <td>0</td>\n","      <td>3001.0</td>\n","      <td>4000.0</td>\n","      <td>3500</td>\n","      <td>3500 [SEP] 30 [SEP] GB [SEP] journalism [SEP] ...</td>\n","      <td>0</td>\n","      <td>0.000720</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>train_00017</td>\n","      <td>11001-12000</td>\n","      <td>US</td>\n","      <td>30</td>\n","      <td>food</td>\n","      <td>drinks</td>\n","      <td>Why Schenk-Atwood?Our neighborhood has just ab...</td>\n","      <td>1</td>\n","      <td>11001.0</td>\n","      <td>12000.0</td>\n","      <td>11500</td>\n","      <td>11500 [SEP] 30 [SEP] US [SEP] food [SEP] drink...</td>\n","      <td>0</td>\n","      <td>0.819439</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>train_00018</td>\n","      <td>12001-13000</td>\n","      <td>US</td>\n","      <td>28</td>\n","      <td>journalism</td>\n","      <td>web</td>\n","      <td>Mega Visions app has been approved on all majo...</td>\n","      <td>1</td>\n","      <td>12001.0</td>\n","      <td>13000.0</td>\n","      <td>12500</td>\n","      <td>12500 [SEP] 28 [SEP] US [SEP] journalism [SEP]...</td>\n","      <td>0</td>\n","      <td>0.113744</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0aedd5e7-f92a-4e14-b6c9-fb423d2e2933')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0aedd5e7-f92a-4e14-b6c9-fb423d2e2933 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0aedd5e7-f92a-4e14-b6c9-fb423d2e2933');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":[],"metadata":{"id":"3vgWEX03TZjr","executionInfo":{"status":"ok","timestamp":1663579851027,"user_tz":-540,"elapsed":6,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":21,"outputs":[]}]}