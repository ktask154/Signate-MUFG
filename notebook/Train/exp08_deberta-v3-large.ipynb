{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyPwugD7VDP4c5r+Ts/pyFc2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"f72c60214096401abd749cf61bbbf70e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f9a7e7dce1ce4a1685567d96d35f9ebf","IPY_MODEL_c8745f0aef614026b7ba298f55bbbf05","IPY_MODEL_1123b57985614510be4046d115dbec55"],"layout":"IPY_MODEL_e001b7a968434a97b8a35d585cd9a99c"}},"f9a7e7dce1ce4a1685567d96d35f9ebf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a33cd88db4de48f48334fe26130b2ab8","placeholder":"​","style":"IPY_MODEL_160c9e5deb344adaa612ac07b07f1e9b","value":"Downloading tokenizer_config.json: 100%"}},"c8745f0aef614026b7ba298f55bbbf05":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d6d525ddb9040f39150524d3fd9ddc5","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_949b8a2fb2a3442d9cdb03924c39b9c2","value":52}},"1123b57985614510be4046d115dbec55":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d87323133524862aafdd6527fb8ed14","placeholder":"​","style":"IPY_MODEL_8ae365625b8f446da1db3010cae90eeb","value":" 52.0/52.0 [00:00&lt;00:00, 1.32kB/s]"}},"e001b7a968434a97b8a35d585cd9a99c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a33cd88db4de48f48334fe26130b2ab8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"160c9e5deb344adaa612ac07b07f1e9b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8d6d525ddb9040f39150524d3fd9ddc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"949b8a2fb2a3442d9cdb03924c39b9c2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2d87323133524862aafdd6527fb8ed14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ae365625b8f446da1db3010cae90eeb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"93e16f8dbb5f45a1b1e2caf130c646d1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9f1606b081ed489b81728839fa5f6177","IPY_MODEL_dc4e97cb91f1470baac31dfa90d64a75","IPY_MODEL_3130369e5d1e45409ac9578dd0861130"],"layout":"IPY_MODEL_e9c927c807f44968afbb7fe649f3cbaa"}},"9f1606b081ed489b81728839fa5f6177":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_50d062eecc944e85a0b5481d24448c80","placeholder":"​","style":"IPY_MODEL_e33f8f49ce444f4180f60690202c3d1a","value":"Downloading config.json: 100%"}},"dc4e97cb91f1470baac31dfa90d64a75":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2bf8bedb30d1466fbb8f0fd4e5782184","max":580,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b081f9bbcacb4438830a6e7c442ee718","value":580}},"3130369e5d1e45409ac9578dd0861130":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_231fcdd190bd4679998e004d0943bd02","placeholder":"​","style":"IPY_MODEL_496f7a21b2264b95aee3ca2824323815","value":" 580/580 [00:00&lt;00:00, 10.2kB/s]"}},"e9c927c807f44968afbb7fe649f3cbaa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50d062eecc944e85a0b5481d24448c80":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e33f8f49ce444f4180f60690202c3d1a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2bf8bedb30d1466fbb8f0fd4e5782184":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b081f9bbcacb4438830a6e7c442ee718":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"231fcdd190bd4679998e004d0943bd02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"496f7a21b2264b95aee3ca2824323815":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d9e5447a8d41414f8e1c3d102f2243e8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_66a75e3ed453465382047721ca6959bc","IPY_MODEL_e62f42100a024814b4c829e00d99f66a","IPY_MODEL_3417f5c17fb84ad3a246b45536321213"],"layout":"IPY_MODEL_0543c1cffe8740a1ad9992392d3068fe"}},"66a75e3ed453465382047721ca6959bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f1a787ea0ea490ea1f805fde1cacc8f","placeholder":"​","style":"IPY_MODEL_d43a2d9f5b0b4efa8fecd4ecf5d1b69a","value":"Downloading spm.model: 100%"}},"e62f42100a024814b4c829e00d99f66a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e96dd0e7c1e14a3194deff01deda3397","max":2464616,"min":0,"orientation":"horizontal","style":"IPY_MODEL_126e0e847703403fa5fab4d6645641dd","value":2464616}},"3417f5c17fb84ad3a246b45536321213":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bcbfff97dcbe45e8a35083824e5b73a1","placeholder":"​","style":"IPY_MODEL_7e6436eff80242f09df7e14e1beee5eb","value":" 2.35M/2.35M [00:00&lt;00:00, 3.88MB/s]"}},"0543c1cffe8740a1ad9992392d3068fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f1a787ea0ea490ea1f805fde1cacc8f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d43a2d9f5b0b4efa8fecd4ecf5d1b69a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e96dd0e7c1e14a3194deff01deda3397":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"126e0e847703403fa5fab4d6645641dd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bcbfff97dcbe45e8a35083824e5b73a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e6436eff80242f09df7e14e1beee5eb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"de3c1f4996164e21bad4ef08be998842":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_116c53d2fe274ed1b44c4e0d3227c03e","IPY_MODEL_f7d94fb050b441afa6639aefae307786","IPY_MODEL_79f6b9ff110343c4b64a079e73acd0cf"],"layout":"IPY_MODEL_2e5b786a4fa04e9ca8c95093e7b9833a"}},"116c53d2fe274ed1b44c4e0d3227c03e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_43b91d3dc0234917acf1f40a913af70b","placeholder":"​","style":"IPY_MODEL_63f214f3a6a84561b3b4113e384b82da","value":"Downloading pytorch_model.bin: 100%"}},"f7d94fb050b441afa6639aefae307786":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_019d9a86d65049e79ed62bf2eadbd95d","max":873673253,"min":0,"orientation":"horizontal","style":"IPY_MODEL_148a42999a054e469a71f033a0aa3526","value":873673253}},"79f6b9ff110343c4b64a079e73acd0cf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d62be9470b44b209105024d5bfed0dc","placeholder":"​","style":"IPY_MODEL_e413a9739dae4ba9bdbe72dd7fa2bf1e","value":" 833M/833M [00:13&lt;00:00, 68.8MB/s]"}},"2e5b786a4fa04e9ca8c95093e7b9833a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43b91d3dc0234917acf1f40a913af70b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63f214f3a6a84561b3b4113e384b82da":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"019d9a86d65049e79ed62bf2eadbd95d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"148a42999a054e469a71f033a0aa3526":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7d62be9470b44b209105024d5bfed0dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e413a9739dae4ba9bdbe72dd7fa2bf1e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x6HNPEbHjjXg","executionInfo":{"status":"ok","timestamp":1662638908052,"user_tz":-540,"elapsed":17581,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"f03dc525-e9f2-40fb-e3ed-1ae1a213cef9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rMKSmAYLjrMd","executionInfo":{"status":"ok","timestamp":1662638915867,"user_tz":-540,"elapsed":7818,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"fbbcd6d5-5ef4-4b28-9280-6a3461ff9739"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.21.3-py3-none-any.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 6.8 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 67.8 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n","\u001b[K     |████████████████████████████████| 120 kB 93.5 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.21.3\n"]}]},{"cell_type":"code","source":["!pip install datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GirEflrPMKRs","executionInfo":{"status":"ok","timestamp":1662638921531,"user_tz":-540,"elapsed":5675,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"c744ec29-edd3-4d32-d51b-0111906993e5"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n","\u001b[K     |████████████████████████████████| 365 kB 8.7 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.8.1)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.9.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.12.0)\n","Collecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 99.0 MB/s \n","\u001b[?25hCollecting multiprocess\n","  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n","\u001b[K     |████████████████████████████████| 115 kB 74.9 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.8.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 92.6 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.2.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: urllib3, xxhash, responses, multiprocess, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed datasets-2.4.0 multiprocess-0.70.13 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0\n"]}]},{"cell_type":"code","source":["!pip install sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SbPlkmItj1Vh","executionInfo":{"status":"ok","timestamp":1662638925476,"user_tz":-540,"elapsed":3948,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"4602d9c3-e916-4c2b-9fb0-f6549e1a4b80"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 6.1 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n"]}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aVpxpObEj8AP","executionInfo":{"status":"ok","timestamp":1662638925477,"user_tz":-540,"elapsed":7,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"d7b44b72-7c19-4e0c-f191-df6e35eef4ab"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Sep  8 12:08:44 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["import os\n","import gc\n","import math\n","import time\n","import random\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.simplefilter('ignore')\n","from tqdm import tqdm\n","import re\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim import Adam, SGD, AdamW, RAdam\n","from torch.optim import lr_scheduler\n","from torch.utils.data import DataLoader, Dataset\n","\n","from sklearn.model_selection import StratifiedKFold,StratifiedGroupKFold,GroupKFold\n","from sklearn.metrics import log_loss,f1_score\n","\n","from transformers import AutoModel, AutoConfig, AutoTokenizer, AdamW, DataCollatorWithPadding\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"XwpQFbjMj35Z","executionInfo":{"status":"ok","timestamp":1662638931078,"user_tz":-540,"elapsed":5605,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["DIR = '/content/drive/MyDrive/Competitions/Signate/MUFJ'\n","INPUT_DIR = os.path.join(DIR,'input')\n","OUTPUT_DIR = os.path.join(DIR,'output')\n","OUTPUT_SUB_DIR = os.path.join(OUTPUT_DIR,'submission')\n","#OUTPUT_MODEL_DIR = os.path.join(OUTPUT_DIR,'model')\n","OUTPUT_MODEL_DIR = DIR + '/output/model/EXP08/'\n","if not os.path.exists(OUTPUT_MODEL_DIR):\n","    os.makedirs(OUTPUT_MODEL_DIR)"],"metadata":{"id":"5_JiwdzIkOOr","executionInfo":{"status":"ok","timestamp":1662638932165,"user_tz":-540,"elapsed":1092,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["class CFG:\n","    wandb = False\n","    apex = True\n","    model = 'microsoft/deberta-v3-large'\n","    seed = 42\n","    n_splits = 4\n","    max_len = 256\n","    dropout = 0.2\n","    target_size=1\n","    n_accumulate=1\n","    print_freq = 50\n","    min_lr=1e-6\n","    scheduler = 'cosine' #'linear','cosine'\n","    batch_size = 16\n","    num_workers = 2\n","    lr = 2e-5\n","    weigth_decay = 0.01\n","    epochs = 4\n","    n_fold = 4\n","    trn_fold = [0, 1, 2, 3]\n","    train = True \n","    num_warmup_steps = 0\n","    num_cycles=0.5\n","    debug = False\n","    gradient_checkpointing = True\n","    freezing = True\n","    #loss_fn = 'focal_loss'\n","    #alpha = 0.0\n","    #gamma = 1\n","    #logits=True\n","    #weights=[1, 4, 1, 1]\n","    optimizer = 'AdamW'\n","    reinit_layer=5\n","    encoder_lr=2e-5\n","    decoder_lr=2e-5\n","    min_lr=1e-6\n","    eps=1e-6\n","    betas=(0.9, 0.999)\n","\n","if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.trn_fold = [0, 1]"],"metadata":{"id":"8le11BhOK9xa","executionInfo":{"status":"ok","timestamp":1662638932165,"user_tz":-540,"elapsed":2,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Loss Func\n","class ClassificationFocalLoss(nn.Module):\n","    def __init__(self, n_classes: int, alpha=0.3, gamma=2, weights = None, logits=False):\n","        \"\"\"\n","        :param n_classes: \n","        :param gamma: 簡単なサンプルの重み. 大きいほど簡単なサンプルを重視しない.\n","        :param weights: weights by classes,\n","        :param logits:\n","        \"\"\"\n","        super().__init__()\n","        self._alpha = alpha\n","        self._n_classes = n_classes\n","        self._noise_val = alpha / n_classes\n","        self.gamma = gamma\n","        self.class_weight_tensor = torch.tensor(weights).view(-1, ).to(device) if weights else None\n","        self.logits = logits\n","        if not logits and weights is not None:\n","            RuntimeWarning(\"重みを適用するにはlogitsをTrueにしてください.\")\n","\n","    def forward(self, pred: torch.Tensor, teacher: torch.Tensor) -> float:\n","        \"\"\"\n","        :param pred: batch_size, n_classes\n","        :param teacher: batch_size, \n","        :return: \n","        \"\"\"\n","        if self.logits:\n","            if teacher.ndim == 1:  # 1次元ならonehotの2次元tensorにする\n","                teacher = torch.eye(self._n_classes)[teacher]\n","            teacher = teacher * (1 - self._alpha) + self._noise_val\n","            ce_loss = F.binary_cross_entropy_with_logits(pred, teacher, reduce=False)\n","            pt = torch.exp(-ce_loss)\n","\n","            if not self.class_weight_tensor == None:\n","                class_weight_tensor = self.class_weight_tensor.expand(pred.shape[0],\n","                                                                      self.class_weight_tensor.shape[0], )\n","                focal_loss = (1. - pt) ** self.gamma * (ce_loss * class_weight_tensor)\n","            else:\n","                focal_loss = (1. - pt) ** self.gamma * ce_loss\n","        else:\n","            # if teacher.ndim == 2:  # onehotの2次元tensorなら1次元にする\n","            #     teacher = teacher.argmax(1).to(torch.long)\n","            teacher = teacher * (1 - self._alpha) + self._noise_val\n","            ce_loss = F.cross_entropy(pred, teacher, reduce=False)\n","            pt = torch.exp(-ce_loss)\n","            focal_loss = (1. - pt) ** self.gamma * ce_loss\n","        return torch.mean(focal_loss)\n","\n","def criterion(outputs, labels):\n","    return nn.BCEWithLogitsLoss()(outputs, labels)\n","\n","def get_score(labels, outputs):\n","    thresh = 0.5\n","    y_pred = outputs\n","    y_true = labels\n","    return f1_score(y_true, (y_pred>thresh).astype(int))\n","\n","\n","def get_logger(filename=OUTPUT_MODEL_DIR+'train'):\n","    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","def seed_everything(seed=CFG.seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(seed=42)"],"metadata":{"id":"okau4QdCLWjl","executionInfo":{"status":"ok","timestamp":1662638932442,"user_tz":-540,"elapsed":3,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["train = pd.read_csv(os.path.join(INPUT_DIR,'train.csv'))\n","test = pd.read_csv(os.path.join(INPUT_DIR,'test.csv'))\n","sub = pd.read_csv(os.path.join(INPUT_DIR,'sample_submit.csv'),header=None)\n","sub.columns = ['id','state']"],"metadata":{"id":"mVJSFqAGkRiW","executionInfo":{"status":"ok","timestamp":1662638934841,"user_tz":-540,"elapsed":2401,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def create_ctg2(df):\n","  group = df.groupby(['country', 'category1']).agg({\"category2\":list}).reset_index()\n","  group[\"category2\"] = group[\"category2\"].map(lambda s: \"; \".join(s))\n","  group.rename(columns={\"category2\":\"country_category1\"}, inplace=True)\n","  df = df.merge(group, how='left', on=[\"category1\", \"country\"])\n","  return df"],"metadata":{"id":"nYyxH_ak2bVi","executionInfo":{"status":"ok","timestamp":1662638934841,"user_tz":-540,"elapsed":4,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def freeze(module):\n","    \"\"\"\n","    Freezes module's parameters.\n","    \"\"\"\n","    \n","    for parameter in module.parameters():\n","        parameter.requires_grad = False\n","        \n","def get_freezed_parameters(module):\n","    \"\"\"\n","    Returns names of freezed parameters of the given module.\n","    \"\"\"\n","    \n","    freezed_parameters = []\n","    for name, parameter in module.named_parameters():\n","        if not parameter.requires_grad:\n","            freezed_parameters.append(name)\n","            \n","    return freezed_parameters\n","\n","def set_embedding_parameters_bits(embeddings_path, optim_bits=32):\n","    \"\"\"\n","    https://github.com/huggingface/transformers/issues/14819#issuecomment-1003427930\n","    \"\"\"\n","    \n","    embedding_types = (\"word\", \"position\", \"token_type\")\n","    for embedding_type in embedding_types:\n","        attr_name = f\"{embedding_type}_embeddings\"\n","        \n","        if hasattr(embeddings_path, attr_name): \n","            bnb.optim.GlobalOptimManager.get_instance().register_module_override(\n","                getattr(embeddings_path, attr_name), 'weight', {'optim_bits': optim_bits}\n","            )"],"metadata":{"id":"BNx-Q9upJp06","executionInfo":{"status":"ok","timestamp":1662638934841,"user_tz":-540,"elapsed":3,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def remove_URL(text):\n","    url = re.compile(r'https?://\\S+|www\\.\\S+')\n","    return url.sub('',text)\n","\n","def remove_html(text):\n","    html=re.compile(r\"<[^>]*?>\")\n","    return html.sub('',text)\n","\n","def cleaning(texts):\n","    clean_texts = []\n","    for text in texts:\n","        # htmlタグを削除\n","        text = remove_URL(text)\n","        text = remove_html(text)\n","        #アルファベット以外をスペースに置き換え\n","        #clean_punc = re.sub(r'[^a-zA-Z]', ' ', text)\n","        #改行削除\n","        text = text.replace(\"\\n\",\"\")\n","        clean_texts.append(text)\n","    return clean_texts\n","\n","\n","from text_unidecode import unidecode\n","from typing import Dict, List, Tuple\n","import codecs\n","\n","def replace_encoding_with_utf8(error: UnicodeError) -> Tuple[bytes, int]:\n","    return error.object[error.start : error.end].encode(\"utf-8\"), error.end\n","\n","\n","def replace_decoding_with_cp1252(error: UnicodeError) -> Tuple[str, int]:\n","    return error.object[error.start : error.end].decode(\"cp1252\"), error.end\n","\n","# Register the encoding and decoding error handlers for `utf-8` and `cp1252`.\n","codecs.register_error(\"replace_encoding_with_utf8\", replace_encoding_with_utf8)\n","codecs.register_error(\"replace_decoding_with_cp1252\", replace_decoding_with_cp1252)\n","\n","def resolve_encodings_and_normalize(text: str) -> str:\n","    \"\"\"Resolve the encoding problems and normalize the abnormal characters.\"\"\"\n","    text = (\n","        text.encode(\"raw_unicode_escape\")\n","        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n","        .encode(\"cp1252\", errors=\"replace_encoding_with_utf8\")\n","        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n","    )\n","    text = unidecode(text)\n","    return text\n","\n","\n","train['html_content'] = cleaning(train['html_content'])\n","#train = create_ctg2(train)\n","train['html_content'] = train['html_content'].apply(lambda x : resolve_encodings_and_normalize(x))\n","train['html_content'] = train['html_content'].fillna('missing')\n","#train['inputs'] = train.goal + '  ' + train.duration.astype(str) + ' [SEP] ' + train.country + ' ; ' + train.category1 + ' ; ' + train.country_category1 + ' [SEP] ' + train.html_content\n","train['inputs'] = train.goal + ' ; ' + train.duration.astype(str) + ' [SEP] ' + train.country + ' [SEP] ' + train.category1 + ' ; ' + train.category2 + ' [SEP] ' + train.html_content\n","train = train.rename(columns = {\"state\": \"label\"})"],"metadata":{"id":"HXV4Z1PckToF","executionInfo":{"status":"ok","timestamp":1662638941611,"user_tz":-540,"elapsed":6773,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["skf = StratifiedKFold(n_splits=CFG.n_splits,shuffle=True,random_state=CFG.seed)\n","for fold, ( _, val_) in enumerate(skf.split(train, train.label)):\n","    train.loc[val_ , \"kfold\"] = int(fold)\n","    \n","train[\"kfold\"] = train[\"kfold\"].astype(int)\n","\n","if CFG.debug:\n","    display(train.groupby('kfold').size())\n","    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n","    display(train.groupby('kfold').size())"],"metadata":{"id":"SGtnMdKwkhH8","executionInfo":{"status":"ok","timestamp":1662638941612,"user_tz":-540,"elapsed":14,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n","#tokenizer.add_tokens([f\"\\n\"], special_tokens=True)\n","tokenizer.save_pretrained(OUTPUT_MODEL_DIR+'tokenizer/')\n","CFG.tokenizer = tokenizer\n","SEP = tokenizer.sep_token"],"metadata":{"id":"bVGqhi8skoNu","executionInfo":{"status":"ok","timestamp":1662638948313,"user_tz":-540,"elapsed":6712,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"colab":{"base_uri":"https://localhost:8080/","height":149,"referenced_widgets":["f72c60214096401abd749cf61bbbf70e","f9a7e7dce1ce4a1685567d96d35f9ebf","c8745f0aef614026b7ba298f55bbbf05","1123b57985614510be4046d115dbec55","e001b7a968434a97b8a35d585cd9a99c","a33cd88db4de48f48334fe26130b2ab8","160c9e5deb344adaa612ac07b07f1e9b","8d6d525ddb9040f39150524d3fd9ddc5","949b8a2fb2a3442d9cdb03924c39b9c2","2d87323133524862aafdd6527fb8ed14","8ae365625b8f446da1db3010cae90eeb","93e16f8dbb5f45a1b1e2caf130c646d1","9f1606b081ed489b81728839fa5f6177","dc4e97cb91f1470baac31dfa90d64a75","3130369e5d1e45409ac9578dd0861130","e9c927c807f44968afbb7fe649f3cbaa","50d062eecc944e85a0b5481d24448c80","e33f8f49ce444f4180f60690202c3d1a","2bf8bedb30d1466fbb8f0fd4e5782184","b081f9bbcacb4438830a6e7c442ee718","231fcdd190bd4679998e004d0943bd02","496f7a21b2264b95aee3ca2824323815","d9e5447a8d41414f8e1c3d102f2243e8","66a75e3ed453465382047721ca6959bc","e62f42100a024814b4c829e00d99f66a","3417f5c17fb84ad3a246b45536321213","0543c1cffe8740a1ad9992392d3068fe","7f1a787ea0ea490ea1f805fde1cacc8f","d43a2d9f5b0b4efa8fecd4ecf5d1b69a","e96dd0e7c1e14a3194deff01deda3397","126e0e847703403fa5fab4d6645641dd","bcbfff97dcbe45e8a35083824e5b73a1","7e6436eff80242f09df7e14e1beee5eb"]},"outputId":"085fa0c5-d2bf-48cc-bbf2-b1824fd05c39"},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f72c60214096401abd749cf61bbbf70e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading config.json:   0%|          | 0.00/580 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93e16f8dbb5f45a1b1e2caf130c646d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading spm.model:   0%|          | 0.00/2.35M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9e5447a8d41414f8e1c3d102f2243e8"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"code","source":["class Dataset(Dataset):\n","    def __init__(self, df, tokenizer, max_length):\n","        self.df = df\n","        self.max_len = CFG.max_len\n","        self.text = df['inputs'].values\n","        self.tokenizer = CFG.tokenizer\n","        self.targets = df['label'].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, index):\n","        text = self.text[index]\n","        inputs = tokenizer.encode_plus(\n","            text,\n","            truncation=True,\n","            add_special_tokens=True,\n","            max_length = self.max_len\n","        )\n","        samples = {\n","            'input_ids': inputs['input_ids'],\n","            'attention_mask': inputs['attention_mask'],\n","            'target': self.targets[index]\n","        }\n","\n","        if 'token_type_ids' in inputs:\n","            samples['token_type_ids'] = inputs['token_type_ids']\n","            \n","        return samples"],"metadata":{"id":"tbQtUv8FkpqK","executionInfo":{"status":"ok","timestamp":1662638948313,"user_tz":-540,"elapsed":18,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["class Collate:\n","    def __init__(self, tokenizer, isTrain=True):\n","        self.tokenizer = tokenizer\n","        self.isTrain = isTrain\n","        # self.args = args\n","\n","    def __call__(self, batch):\n","        output = dict()\n","        output[\"input_ids\"] = [sample[\"input_ids\"] for sample in batch]\n","        output[\"attention_mask\"] = [sample[\"attention_mask\"] for sample in batch]\n","        if self.isTrain:\n","            output[\"target\"] = [sample[\"target\"] for sample in batch]\n","\n","        # calculate max token length of this batch\n","        batch_max = max([len(ids) for ids in output[\"input_ids\"]])\n","\n","        # add padding\n","        if self.tokenizer.padding_side == \"right\":\n","            output[\"input_ids\"] = [s + (batch_max - len(s)) * [self.tokenizer.pad_token_id] for s in output[\"input_ids\"]]\n","            output[\"attention_mask\"] = [s + (batch_max - len(s)) * [0] for s in output[\"attention_mask\"]]\n","        else:\n","            output[\"input_ids\"] = [(batch_max - len(s)) * [self.tokenizer.pad_token_id] + s for s in output[\"input_ids\"]]\n","            output[\"attention_mask\"] = [(batch_max - len(s)) * [0] + s for s in output[\"attention_mask\"]]\n","\n","        # convert to tensors\n","        output[\"input_ids\"] = torch.tensor(output[\"input_ids\"], dtype=torch.long)\n","        output[\"attention_mask\"] = torch.tensor(output[\"attention_mask\"], dtype=torch.long)\n","        if self.isTrain:\n","            output[\"target\"] = torch.tensor(output[\"target\"], dtype=torch.long)\n","\n","        return output\n","    \n","collate_fn = Collate(CFG.tokenizer, isTrain=True)\n","#collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)"],"metadata":{"id":"UhIn8JjRkrUp","executionInfo":{"status":"ok","timestamp":1662638948314,"user_tz":-540,"elapsed":17,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["class MeanPooling(nn.Module):\n","    def __init__(self):\n","        super(MeanPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9) #\n","        mean_embeddings = sum_embeddings / sum_mask\n","        return mean_embeddings\n","\n","class MaxPooling(nn.Module):\n","    def __init__(self):\n","        super(MaxPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        embeddings = last_hidden_state.clone()\n","        embeddings[input_mask_expanded == 0] = -1e4\n","        max_embeddings, _ = torch.max(embeddings, dim=1)\n","        return max_embeddings"],"metadata":{"id":"eFiS-2FClBny","executionInfo":{"status":"ok","timestamp":1662638948314,"user_tz":-540,"elapsed":16,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Model\n","# ====================================================\n","class CustomModel(nn.Module):\n","    def __init__(self, model_name):\n","        super(CustomModel, self).__init__()\n","        # Header (fast or normal)\n","\n","        hidden_dropout_prob: float = 0.15\n","\n","        self.config = AutoConfig.from_pretrained(model_name)\n","\n","        self.model = AutoModel.from_pretrained(model_name)\n","\n","        self.config.update(\n","            {\n","                \"output_hidden_states\": True,\n","                \"hidden_dropout_prob\": hidden_dropout_prob,\n","                \"num_labels\": CFG.target_size,\n","            }\n","        )\n","\n","        self.dropout = nn.Dropout(self.config.hidden_dropout_prob)\n","        self.mean_pooler = MeanPooling()\n","        self.max_pooler = MaxPooling()\n","        self.output = nn.Linear(self.config.hidden_size*2, CFG.target_size)\n","        self._init_weights(self.output)\n","        self.layer_norm1 = nn.LayerNorm(self.config.hidden_size*2)\n","\n","        \n","        # Gradient_checkpointing\n","        if CFG.gradient_checkpointing:\n","            (self.model).gradient_checkpointing_enable()\n","        \n","        # Freezing\n","        if CFG.freezing:\n","            # freezing embeddings and first 2 layers of encoder\n","            freeze((self.model).embeddings)\n","            freeze((self.model).encoder.layer[:2])\n","            CFG.after_freezed_parameters = filter(lambda parameter: parameter.requires_grad, (self.model).parameters())\n","        \n","        \n","\n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","\n","    def feature(self, ids, mask):\n","        output = self.model(input_ids=ids, \n","                         attention_mask=mask,\n","                         output_hidden_states=False)\n","        last_hidden_states = output[0]\n","        #feature = torch.mean(last_hidden_states, 1)\n","        weights = self.attention(last_hidden_states)\n","        feature = torch.sum(weights * last_hidden_states, dim=1)\n","        return feature\n","    \n","    def forward(self, ids, mask):\n","\n","        #feature = self.feature(ids, mask)\n","        transformer_out = self.model(input_ids=ids, \n","                         attention_mask=mask,\n","                         output_hidden_states=False)\n","        output = transformer_out.last_hidden_state\n","        output = self.dropout(output)\n","      \n","        mean_pool = self.mean_pooler(output, mask)\n","        max_pool = self.max_pooler(output,mask)\n","\n","        concat = torch.cat([mean_pool,max_pool],dim=1)\n","\n","        sequence_output = self.layer_norm1(concat)\n","\n","        logits = self.output(sequence_output)\n","    \n","        return logits"],"metadata":{"id":"5OTwfZ4plIoS","executionInfo":{"status":"ok","timestamp":1662638948314,"user_tz":-540,"elapsed":15,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","def asMinutes(s):\n","    m = math.floor(s/60)\n","    s -= m * 60\n","    return \"%dm %ds\" % (m, s)\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n","\n","def get_scheduler(cfg, optimizer, num_train_steps):\n","    if cfg.scheduler == 'linear':\n","        scheduler = get_linear_schedule_with_warmup(\n","            optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n","        )\n","    elif cfg.scheduler == 'cosine':\n","        scheduler = get_cosine_schedule_with_warmup(\n","            optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","        )\n","    return scheduler\n","\n","def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n","    model.train()\n","\n","    dataset_size = 0\n","    running_loss = 0\n","\n","    start = end = time.time()\n","\n","    for step, data in enumerate(dataloader):\n","        ids = data['input_ids'].to(device)\n","        mask = data['attention_mask'].to(device)\n","        targets = data['target'].to(device)\n","\n","        batch_size = ids.size(0)\n","        outputs = model(ids, mask)\n","        loss = criterion(outputs.view(-1, 1).float(), targets.view(-1, 1).float())\n","\n","        #accumulate\n","        loss = loss / CFG.n_accumulate\n","        loss.backward()\n","        if (step +1) % CFG.n_accumulate == 0:\n","            optimizer.step()\n","\n","            optimizer.zero_grad()\n","            if scheduler is not None:\n","                scheduler.step()\n","        running_loss += (loss.item() * batch_size)\n","        dataset_size += batch_size\n","\n","        epoch_loss = running_loss / dataset_size\n","\n","        end = time.time()\n","        \n","        if step % CFG.print_freq == 0 or step == (len(dataloader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                  'Elapsed {remain:s} '\n","                  .format(epoch+1, step, len(dataloader), \n","                          remain=timeSince(start, float(step+1)/len(dataloader))))\n","\n","    gc.collect()\n","\n","    return epoch_loss\n","\n","\n","@torch.no_grad()\n","def valid_one_epoch(model, dataloader, device, epoch):\n","    model.eval()\n","\n","    dataset_size = 0\n","    running_loss = 0\n","\n","    start = end = time.time()\n","    pred = []\n","\n","    for step, data in enumerate(dataloader):\n","        ids = data['input_ids'].to(device)\n","        mask = data['attention_mask'].to(device)\n","        targets = data['target'].to(device)\n","\n","        batch_size = ids.size(0)\n","        outputs = model(ids, mask)\n","        loss = criterion(outputs.view(-1, 1).float(), targets.view(-1, 1).float())\n","        pred.append(outputs.sigmoid().to('cpu').numpy())\n","\n","        running_loss += (loss.item()* batch_size)\n","        dataset_size += batch_size\n","\n","        epoch_loss = running_loss / dataset_size\n","\n","        end = time.time()\n","\n","        if step % CFG.print_freq == 0 or step == (len(dataloader)-1):\n","            print('EVAL: [{0}/{1}] '\n","                  'Elapsed {remain:s} '\n","                  .format(step, len(dataloader),\n","                          remain=timeSince(start, float(step+1)/len(dataloader))))\n","            \n","    pred = np.concatenate(pred)\n","            \n","    return epoch_loss, pred"],"metadata":{"id":"uxCPb-FplLTD","executionInfo":{"status":"ok","timestamp":1662638948314,"user_tz":-540,"elapsed":15,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n","    param_optimizer = list(model.named_parameters())\n","    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","    optimizer_parameters = [\n","        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n","          'lr': encoder_lr, 'weight_decay': weight_decay},\n","        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n","          'lr': encoder_lr, 'weight_decay': 0.0},\n","        {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n","          'lr': decoder_lr, 'weight_decay': 0.0}\n","    ]\n","    return optimizer_parameters\n","\n","\n","def train_loop(fold):\n","    #wandb.watch(model, log_freq=100)\n","\n","    LOGGER.info(f'-------------fold:{fold} training-------------')\n","\n","    train_data = train[train.kfold != fold].reset_index(drop=True)\n","    valid_data = train[train.kfold == fold].reset_index(drop=True)\n","    valid_labels = valid_data.label.values\n","\n","    trainDataset = Dataset(train_data, CFG.tokenizer, CFG.max_len)\n","    validDataset = Dataset(valid_data, CFG.tokenizer, CFG.max_len)\n","\n","    train_loader = DataLoader(trainDataset,\n","                              batch_size = CFG.batch_size,\n","                              shuffle=True,\n","                              collate_fn = collate_fn,\n","                              num_workers = CFG.num_workers,\n","                              pin_memory = True,\n","                              drop_last=True)\n","    \n","    valid_loader = DataLoader(validDataset,\n","                              batch_size = CFG.batch_size*2,\n","                              shuffle=False,\n","                              collate_fn = collate_fn,\n","                              num_workers = CFG.num_workers,\n","                              pin_memory = True,\n","                              drop_last=False)\n","    \n","    model = CustomModel(CFG.model)\n","    torch.save(model.config, OUTPUT_MODEL_DIR+'config.pth')\n","    model.to(device)\n","    optimizer_parameters = get_optimizer_params(model=model,\n","                                                encoder_lr=CFG.encoder_lr, \n","                                                decoder_lr=CFG.decoder_lr,\n","                                                weight_decay=CFG.weigth_decay,\n","                                                )\n","    \n","    if CFG.optimizer == 'AdamW':\n","        optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n","        #optimizer = AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weigth_decay)\n","    if CFG.optimizer == 'RAdam':\n","        optimizer = RAdam(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n","        #optimizer = RAdam(model.parameters(), lr=CFG.lr, weight_decay=CFG.weigth_decay)\n","    num_train_steps = int(len(train_data) / CFG.batch_size * CFG.epochs)\n","    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n","\n","    # loop\n","    best_score = 0\n","\n","    for epoch in range(CFG.epochs):\n","        start_time = time.time()\n","\n","        train_epoch_loss = train_one_epoch(model, optimizer, scheduler, train_loader, device, epoch)\n","        valid_epoch_loss, pred = valid_one_epoch(model, valid_loader, device, epoch)\n","\n","        score = get_score(valid_labels,pred)\n","\n","        elapsed = time.time() - start_time\n","\n","        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {train_epoch_loss:.4f}  avg_val_loss: {valid_epoch_loss:.4f}  time: {elapsed:.0f}s')\n","        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n","\n","            \n","        if score > best_score:\n","            best_score = score\n","            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","            torch.save({'model': model.state_dict(),\n","                        'predictions': pred},\n","                        OUTPUT_MODEL_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n","            \n","    predictions = torch.load(OUTPUT_MODEL_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", \n","                             map_location=torch.device('cpu'))['predictions']\n","    valid_data['pred'] = predictions\n","    \n","    \n","    temp = valid_data['pred'].values\n","    print(get_score(valid_data['label'].values,temp))\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    \n","    return valid_data"],"metadata":{"id":"zOkzlUIXlMw0","executionInfo":{"status":"ok","timestamp":1662638948315,"user_tz":-540,"elapsed":16,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["if __name__ == '__main__':\n","    \n","    def get_result(oof_df):\n","        labels = oof_df['label'].values\n","        preds = oof_df['pred'].values\n","        score = get_score(labels, preds)\n","        LOGGER.info(f'Score: {score:<.4f}')\n","    \n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for fold in range(CFG.n_fold):\n","            if fold in CFG.trn_fold:\n","                _oof_df = train_loop(fold)\n","                oof_df = pd.concat([oof_df, _oof_df])\n","                LOGGER.info(f\"========== fold: {fold} result ==========\")\n","                get_result(_oof_df)\n","            \n","        oof_df = oof_df.reset_index(drop=True)\n","        LOGGER.info(f\"========== CV ==========\")\n","        get_result(oof_df)\n","        oof_df.to_pickle(OUTPUT_MODEL_DIR+'oof_df.pkl')\n","        oof_df.to_csv(OUTPUT_MODEL_DIR+f'oof_df.csv', index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["de3c1f4996164e21bad4ef08be998842","116c53d2fe274ed1b44c4e0d3227c03e","f7d94fb050b441afa6639aefae307786","79f6b9ff110343c4b64a079e73acd0cf","2e5b786a4fa04e9ca8c95093e7b9833a","43b91d3dc0234917acf1f40a913af70b","63f214f3a6a84561b3b4113e384b82da","019d9a86d65049e79ed62bf2eadbd95d","148a42999a054e469a71f033a0aa3526","7d62be9470b44b209105024d5bfed0dc","e413a9739dae4ba9bdbe72dd7fa2bf1e"]},"id":"2dIMwG7IlPmS","executionInfo":{"status":"ok","timestamp":1662656331338,"user_tz":-540,"elapsed":17383038,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"5f355238-57b9-40ee-ccde-8556d224fe8c"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["-------------fold:0 training-------------\n","INFO:__main__:-------------fold:0 training-------------\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/833M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de3c1f4996164e21bad4ef08be998842"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/458] Elapsed 0m 7s (remain 54m 44s) \n","Epoch: [1][50/458] Elapsed 1m 56s (remain 15m 31s) \n","Epoch: [1][100/458] Elapsed 3m 45s (remain 13m 18s) \n","Epoch: [1][150/458] Elapsed 5m 35s (remain 11m 21s) \n","Epoch: [1][200/458] Elapsed 7m 24s (remain 9m 28s) \n","Epoch: [1][250/458] Elapsed 9m 14s (remain 7m 37s) \n","Epoch: [1][300/458] Elapsed 11m 3s (remain 5m 46s) \n","Epoch: [1][350/458] Elapsed 12m 53s (remain 3m 55s) \n","Epoch: [1][400/458] Elapsed 14m 43s (remain 2m 5s) \n","Epoch: [1][450/458] Elapsed 16m 32s (remain 0m 15s) \n","Epoch: [1][457/458] Elapsed 16m 48s (remain 0m 0s) \n","EVAL: [0/77] Elapsed 0m 1s (remain 1m 54s) \n","EVAL: [50/77] Elapsed 0m 53s (remain 0m 27s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.5232  avg_val_loss: 0.5979  time: 1089s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.5232  avg_val_loss: 0.5979  time: 1089s\n","Epoch 1 - Score: 0.6304\n","INFO:__main__:Epoch 1 - Score: 0.6304\n","Epoch 1 - Save Best Score: 0.6304 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.6304 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 1m 20s (remain 0m 0s) \n","Epoch: [2][0/458] Elapsed 0m 2s (remain 19m 16s) \n","Epoch: [2][50/458] Elapsed 1m 52s (remain 14m 55s) \n","Epoch: [2][100/458] Elapsed 3m 41s (remain 13m 3s) \n","Epoch: [2][150/458] Elapsed 5m 31s (remain 11m 13s) \n","Epoch: [2][200/458] Elapsed 7m 20s (remain 9m 23s) \n","Epoch: [2][250/458] Elapsed 9m 10s (remain 7m 34s) \n","Epoch: [2][300/458] Elapsed 11m 0s (remain 5m 44s) \n","Epoch: [2][350/458] Elapsed 12m 49s (remain 3m 54s) \n","Epoch: [2][400/458] Elapsed 14m 39s (remain 2m 4s) \n","Epoch: [2][450/458] Elapsed 16m 28s (remain 0m 15s) \n","Epoch: [2][457/458] Elapsed 16m 44s (remain 0m 0s) \n","EVAL: [0/77] Elapsed 0m 1s (remain 1m 53s) \n","EVAL: [50/77] Elapsed 0m 53s (remain 0m 27s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.3585  avg_val_loss: 0.3935  time: 1085s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.3585  avg_val_loss: 0.3935  time: 1085s\n","Epoch 2 - Score: 0.7942\n","INFO:__main__:Epoch 2 - Score: 0.7942\n","Epoch 2 - Save Best Score: 0.7942 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.7942 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 1m 20s (remain 0m 0s) \n","Epoch: [3][0/458] Elapsed 0m 2s (remain 19m 10s) \n","Epoch: [3][50/458] Elapsed 1m 52s (remain 14m 55s) \n","Epoch: [3][100/458] Elapsed 3m 41s (remain 13m 3s) \n","Epoch: [3][150/458] Elapsed 5m 31s (remain 11m 13s) \n","Epoch: [3][200/458] Elapsed 7m 20s (remain 9m 23s) \n","Epoch: [3][250/458] Elapsed 9m 10s (remain 7m 33s) \n","Epoch: [3][300/458] Elapsed 10m 59s (remain 5m 44s) \n","Epoch: [3][350/458] Elapsed 12m 49s (remain 3m 54s) \n","Epoch: [3][400/458] Elapsed 14m 38s (remain 2m 4s) \n","Epoch: [3][450/458] Elapsed 16m 27s (remain 0m 15s) \n","Epoch: [3][457/458] Elapsed 16m 43s (remain 0m 0s) \n","EVAL: [0/77] Elapsed 0m 1s (remain 1m 53s) \n","EVAL: [50/77] Elapsed 0m 53s (remain 0m 27s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.2029  avg_val_loss: 0.4252  time: 1084s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.2029  avg_val_loss: 0.4252  time: 1084s\n","Epoch 3 - Score: 0.8090\n","INFO:__main__:Epoch 3 - Score: 0.8090\n","Epoch 3 - Save Best Score: 0.8090 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.8090 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 1m 20s (remain 0m 0s) \n","Epoch: [4][0/458] Elapsed 0m 2s (remain 18m 57s) \n","Epoch: [4][50/458] Elapsed 1m 52s (remain 14m 54s) \n","Epoch: [4][100/458] Elapsed 3m 41s (remain 13m 2s) \n","Epoch: [4][150/458] Elapsed 5m 30s (remain 11m 12s) \n","Epoch: [4][200/458] Elapsed 7m 20s (remain 9m 23s) \n","Epoch: [4][250/458] Elapsed 9m 9s (remain 7m 33s) \n","Epoch: [4][300/458] Elapsed 10m 59s (remain 5m 43s) \n","Epoch: [4][350/458] Elapsed 12m 48s (remain 3m 54s) \n","Epoch: [4][400/458] Elapsed 14m 38s (remain 2m 4s) \n","Epoch: [4][450/458] Elapsed 16m 27s (remain 0m 15s) \n","Epoch: [4][457/458] Elapsed 16m 43s (remain 0m 0s) \n","EVAL: [0/77] Elapsed 0m 1s (remain 1m 52s) \n","EVAL: [50/77] Elapsed 0m 53s (remain 0m 27s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.0739  avg_val_loss: 0.5162  time: 1084s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0739  avg_val_loss: 0.5162  time: 1084s\n","Epoch 4 - Score: 0.8108\n","INFO:__main__:Epoch 4 - Score: 0.8108\n","Epoch 4 - Save Best Score: 0.8108 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.8108 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 1m 20s (remain 0m 0s) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 0 result ==========\n","INFO:__main__:========== fold: 0 result ==========\n","Score: 0.8108\n","INFO:__main__:Score: 0.8108\n","-------------fold:1 training-------------\n","INFO:__main__:-------------fold:1 training-------------\n"]},{"output_type":"stream","name":"stdout","text":["0.8108108108108107\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/458] Elapsed 0m 2s (remain 18m 3s) \n","Epoch: [1][50/458] Elapsed 1m 50s (remain 14m 43s) \n","Epoch: [1][100/458] Elapsed 3m 39s (remain 12m 54s) \n","Epoch: [1][150/458] Elapsed 5m 27s (remain 11m 5s) \n","Epoch: [1][200/458] Elapsed 7m 15s (remain 9m 17s) \n","Epoch: [1][250/458] Elapsed 9m 4s (remain 7m 28s) \n","Epoch: [1][300/458] Elapsed 10m 52s (remain 5m 40s) \n","Epoch: [1][350/458] Elapsed 12m 40s (remain 3m 51s) \n","Epoch: [1][400/458] Elapsed 14m 29s (remain 2m 3s) \n","Epoch: [1][450/458] Elapsed 16m 17s (remain 0m 15s) \n","Epoch: [1][457/458] Elapsed 16m 32s (remain 0m 0s) \n","EVAL: [0/77] Elapsed 0m 1s (remain 1m 28s) \n","EVAL: [50/77] Elapsed 0m 52s (remain 0m 26s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.5234  avg_val_loss: 0.4310  time: 1071s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.5234  avg_val_loss: 0.4310  time: 1071s\n","Epoch 1 - Score: 0.8074\n","INFO:__main__:Epoch 1 - Score: 0.8074\n","Epoch 1 - Save Best Score: 0.8074 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.8074 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 1m 18s (remain 0m 0s) \n","Epoch: [2][0/458] Elapsed 0m 2s (remain 17m 51s) \n","Epoch: [2][50/458] Elapsed 1m 50s (remain 14m 43s) \n","Epoch: [2][100/458] Elapsed 3m 39s (remain 12m 54s) \n","Epoch: [2][150/458] Elapsed 5m 27s (remain 11m 5s) \n","Epoch: [2][200/458] Elapsed 7m 15s (remain 9m 17s) \n","Epoch: [2][250/458] Elapsed 9m 3s (remain 7m 28s) \n","Epoch: [2][300/458] Elapsed 10m 52s (remain 5m 40s) \n","Epoch: [2][350/458] Elapsed 12m 40s (remain 3m 51s) \n","Epoch: [2][400/458] Elapsed 14m 28s (remain 2m 3s) \n","Epoch: [2][450/458] Elapsed 16m 17s (remain 0m 15s) \n","Epoch: [2][457/458] Elapsed 16m 32s (remain 0m 0s) \n","EVAL: [0/77] Elapsed 0m 1s (remain 1m 29s) \n","EVAL: [50/77] Elapsed 0m 52s (remain 0m 26s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.3523  avg_val_loss: 0.4225  time: 1071s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.3523  avg_val_loss: 0.4225  time: 1071s\n","Epoch 2 - Score: 0.7804\n","INFO:__main__:Epoch 2 - Score: 0.7804\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 1m 18s (remain 0m 0s) \n","Epoch: [3][0/458] Elapsed 0m 2s (remain 17m 32s) \n","Epoch: [3][50/458] Elapsed 1m 50s (remain 14m 42s) \n","Epoch: [3][100/458] Elapsed 3m 38s (remain 12m 53s) \n","Epoch: [3][150/458] Elapsed 5m 27s (remain 11m 5s) \n","Epoch: [3][200/458] Elapsed 7m 15s (remain 9m 16s) \n","Epoch: [3][250/458] Elapsed 9m 3s (remain 7m 28s) \n","Epoch: [3][300/458] Elapsed 10m 51s (remain 5m 40s) \n","Epoch: [3][350/458] Elapsed 12m 40s (remain 3m 51s) \n","Epoch: [3][400/458] Elapsed 14m 28s (remain 2m 3s) \n","Epoch: [3][450/458] Elapsed 16m 16s (remain 0m 15s) \n","Epoch: [3][457/458] Elapsed 16m 31s (remain 0m 0s) \n","EVAL: [0/77] Elapsed 0m 1s (remain 1m 28s) \n","EVAL: [50/77] Elapsed 0m 52s (remain 0m 26s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.1781  avg_val_loss: 0.4595  time: 1070s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.1781  avg_val_loss: 0.4595  time: 1070s\n","Epoch 3 - Score: 0.8140\n","INFO:__main__:Epoch 3 - Score: 0.8140\n","Epoch 3 - Save Best Score: 0.8140 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.8140 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 1m 18s (remain 0m 0s) \n","Epoch: [4][0/458] Elapsed 0m 2s (remain 17m 59s) \n","Epoch: [4][50/458] Elapsed 1m 50s (remain 14m 42s) \n","Epoch: [4][100/458] Elapsed 3m 38s (remain 12m 53s) \n","Epoch: [4][150/458] Elapsed 5m 27s (remain 11m 4s) \n","Epoch: [4][200/458] Elapsed 7m 15s (remain 9m 16s) \n","Epoch: [4][250/458] Elapsed 9m 3s (remain 7m 28s) \n","Epoch: [4][300/458] Elapsed 10m 51s (remain 5m 39s) \n","Epoch: [4][350/458] Elapsed 12m 40s (remain 3m 51s) \n","Epoch: [4][400/458] Elapsed 14m 28s (remain 2m 3s) \n","Epoch: [4][450/458] Elapsed 16m 16s (remain 0m 15s) \n","Epoch: [4][457/458] Elapsed 16m 31s (remain 0m 0s) \n","EVAL: [0/77] Elapsed 0m 1s (remain 1m 29s) \n","EVAL: [50/77] Elapsed 0m 52s (remain 0m 26s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.0584  avg_val_loss: 0.5341  time: 1070s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0584  avg_val_loss: 0.5341  time: 1070s\n","Epoch 4 - Score: 0.8125\n","INFO:__main__:Epoch 4 - Score: 0.8125\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 1m 18s (remain 0m 0s) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 1 result ==========\n","INFO:__main__:========== fold: 1 result ==========\n","Score: 0.8140\n","INFO:__main__:Score: 0.8140\n","-------------fold:2 training-------------\n","INFO:__main__:-------------fold:2 training-------------\n"]},{"output_type":"stream","name":"stdout","text":["0.813953488372093\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/458] Elapsed 0m 2s (remain 17m 48s) \n","Epoch: [1][50/458] Elapsed 1m 50s (remain 14m 42s) \n","Epoch: [1][100/458] Elapsed 3m 38s (remain 12m 53s) \n","Epoch: [1][150/458] Elapsed 5m 26s (remain 11m 4s) \n","Epoch: [1][200/458] Elapsed 7m 15s (remain 9m 16s) \n","Epoch: [1][250/458] Elapsed 9m 3s (remain 7m 28s) \n","Epoch: [1][300/458] Elapsed 10m 51s (remain 5m 39s) \n","Epoch: [1][350/458] Elapsed 12m 39s (remain 3m 51s) \n","Epoch: [1][400/458] Elapsed 14m 28s (remain 2m 3s) \n","Epoch: [1][450/458] Elapsed 16m 16s (remain 0m 15s) \n","Epoch: [1][457/458] Elapsed 16m 31s (remain 0m 0s) \n","EVAL: [0/77] Elapsed 0m 1s (remain 1m 31s) \n","EVAL: [50/77] Elapsed 0m 52s (remain 0m 26s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.5166  avg_val_loss: 0.4441  time: 1070s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.5166  avg_val_loss: 0.4441  time: 1070s\n","Epoch 1 - Score: 0.7832\n","INFO:__main__:Epoch 1 - Score: 0.7832\n","Epoch 1 - Save Best Score: 0.7832 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7832 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 1m 18s (remain 0m 0s) \n","Epoch: [2][0/458] Elapsed 0m 2s (remain 17m 52s) \n","Epoch: [2][50/458] Elapsed 1m 50s (remain 14m 42s) \n","Epoch: [2][100/458] Elapsed 3m 38s (remain 12m 53s) \n","Epoch: [2][150/458] Elapsed 5m 27s (remain 11m 4s) \n","Epoch: [2][200/458] Elapsed 7m 15s (remain 9m 16s) \n","Epoch: [2][250/458] Elapsed 9m 3s (remain 7m 28s) \n","Epoch: [2][300/458] Elapsed 10m 51s (remain 5m 40s) \n","Epoch: [2][350/458] Elapsed 12m 40s (remain 3m 51s) \n","Epoch: [2][400/458] Elapsed 14m 28s (remain 2m 3s) \n","Epoch: [2][450/458] Elapsed 16m 16s (remain 0m 15s) \n","Epoch: [2][457/458] Elapsed 16m 31s (remain 0m 0s) \n","EVAL: [0/77] Elapsed 0m 1s (remain 1m 30s) \n","EVAL: [50/77] Elapsed 0m 52s (remain 0m 26s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.3385  avg_val_loss: 0.4145  time: 1070s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.3385  avg_val_loss: 0.4145  time: 1070s\n","Epoch 2 - Score: 0.7898\n","INFO:__main__:Epoch 2 - Score: 0.7898\n","Epoch 2 - Save Best Score: 0.7898 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.7898 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 1m 18s (remain 0m 0s) \n","Epoch: [3][0/458] Elapsed 0m 2s (remain 18m 7s) \n","Epoch: [3][50/458] Elapsed 1m 50s (remain 14m 43s) \n","Epoch: [3][100/458] Elapsed 3m 39s (remain 12m 54s) \n","Epoch: [3][150/458] Elapsed 5m 27s (remain 11m 5s) \n","Epoch: [3][200/458] Elapsed 7m 15s (remain 9m 17s) \n","Epoch: [3][250/458] Elapsed 9m 4s (remain 7m 28s) \n","Epoch: [3][300/458] Elapsed 10m 52s (remain 5m 40s) \n","Epoch: [3][350/458] Elapsed 12m 40s (remain 3m 51s) \n","Epoch: [3][400/458] Elapsed 14m 29s (remain 2m 3s) \n","Epoch: [3][450/458] Elapsed 16m 17s (remain 0m 15s) \n","Epoch: [3][457/458] Elapsed 16m 32s (remain 0m 0s) \n","EVAL: [0/77] Elapsed 0m 1s (remain 1m 30s) \n","EVAL: [50/77] Elapsed 0m 52s (remain 0m 26s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.1720  avg_val_loss: 0.5416  time: 1071s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.1720  avg_val_loss: 0.5416  time: 1071s\n","Epoch 3 - Score: 0.8148\n","INFO:__main__:Epoch 3 - Score: 0.8148\n","Epoch 3 - Save Best Score: 0.8148 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.8148 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 1m 18s (remain 0m 0s) \n","Epoch: [4][0/458] Elapsed 0m 2s (remain 18m 17s) \n","Epoch: [4][50/458] Elapsed 1m 50s (remain 14m 43s) \n","Epoch: [4][100/458] Elapsed 3m 38s (remain 12m 54s) \n","Epoch: [4][150/458] Elapsed 5m 27s (remain 11m 5s) \n","Epoch: [4][200/458] Elapsed 7m 15s (remain 9m 16s) \n","Epoch: [4][250/458] Elapsed 9m 3s (remain 7m 28s) \n","Epoch: [4][300/458] Elapsed 10m 51s (remain 5m 40s) \n","Epoch: [4][350/458] Elapsed 12m 40s (remain 3m 51s) \n","Epoch: [4][400/458] Elapsed 14m 28s (remain 2m 3s) \n","Epoch: [4][450/458] Elapsed 16m 16s (remain 0m 15s) \n","Epoch: [4][457/458] Elapsed 16m 31s (remain 0m 0s) \n","EVAL: [0/77] Elapsed 0m 1s (remain 1m 29s) \n","EVAL: [50/77] Elapsed 0m 52s (remain 0m 26s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.0582  avg_val_loss: 0.6068  time: 1070s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0582  avg_val_loss: 0.6068  time: 1070s\n","Epoch 4 - Score: 0.8079\n","INFO:__main__:Epoch 4 - Score: 0.8079\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 1m 18s (remain 0m 0s) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 2 result ==========\n","INFO:__main__:========== fold: 2 result ==========\n","Score: 0.8148\n","INFO:__main__:Score: 0.8148\n","-------------fold:3 training-------------\n","INFO:__main__:-------------fold:3 training-------------\n"]},{"output_type":"stream","name":"stdout","text":["0.8147584632940281\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/459] Elapsed 0m 2s (remain 18m 25s) \n","Epoch: [1][50/459] Elapsed 1m 50s (remain 14m 45s) \n","Epoch: [1][100/459] Elapsed 3m 38s (remain 12m 55s) \n","Epoch: [1][150/459] Elapsed 5m 27s (remain 11m 7s) \n","Epoch: [1][200/459] Elapsed 7m 15s (remain 9m 18s) \n","Epoch: [1][250/459] Elapsed 9m 3s (remain 7m 30s) \n","Epoch: [1][300/459] Elapsed 10m 51s (remain 5m 42s) \n","Epoch: [1][350/459] Elapsed 12m 39s (remain 3m 53s) \n","Epoch: [1][400/459] Elapsed 14m 28s (remain 2m 5s) \n","Epoch: [1][450/459] Elapsed 16m 16s (remain 0m 17s) \n","Epoch: [1][458/459] Elapsed 16m 33s (remain 0m 0s) \n","EVAL: [0/77] Elapsed 0m 1s (remain 1m 32s) \n","EVAL: [50/77] Elapsed 0m 52s (remain 0m 26s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.5390  avg_val_loss: 0.4574  time: 1072s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.5390  avg_val_loss: 0.4574  time: 1072s\n","Epoch 1 - Score: 0.7406\n","INFO:__main__:Epoch 1 - Score: 0.7406\n","Epoch 1 - Save Best Score: 0.7406 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7406 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 1m 18s (remain 0m 0s) \n","Epoch: [2][0/459] Elapsed 0m 2s (remain 18m 5s) \n","Epoch: [2][50/459] Elapsed 1m 50s (remain 14m 44s) \n","Epoch: [2][100/459] Elapsed 3m 38s (remain 12m 55s) \n","Epoch: [2][150/459] Elapsed 5m 27s (remain 11m 7s) \n","Epoch: [2][200/459] Elapsed 7m 15s (remain 9m 18s) \n","Epoch: [2][250/459] Elapsed 9m 3s (remain 7m 30s) \n","Epoch: [2][300/459] Elapsed 10m 51s (remain 5m 42s) \n","Epoch: [2][350/459] Elapsed 12m 40s (remain 3m 53s) \n","Epoch: [2][400/459] Elapsed 14m 28s (remain 2m 5s) \n","Epoch: [2][450/459] Elapsed 16m 16s (remain 0m 17s) \n","Epoch: [2][458/459] Elapsed 16m 34s (remain 0m 0s) \n","EVAL: [0/77] Elapsed 0m 1s (remain 1m 32s) \n","EVAL: [50/77] Elapsed 0m 52s (remain 0m 26s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.3573  avg_val_loss: 0.3795  time: 1072s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.3573  avg_val_loss: 0.3795  time: 1072s\n","Epoch 2 - Score: 0.8139\n","INFO:__main__:Epoch 2 - Score: 0.8139\n","Epoch 2 - Save Best Score: 0.8139 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.8139 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 1m 18s (remain 0m 0s) \n","Epoch: [3][0/459] Elapsed 0m 2s (remain 18m 19s) \n","Epoch: [3][50/459] Elapsed 1m 50s (remain 14m 45s) \n","Epoch: [3][100/459] Elapsed 3m 38s (remain 12m 56s) \n","Epoch: [3][150/459] Elapsed 5m 27s (remain 11m 7s) \n","Epoch: [3][200/459] Elapsed 7m 15s (remain 9m 18s) \n","Epoch: [3][250/459] Elapsed 9m 3s (remain 7m 30s) \n","Epoch: [3][300/459] Elapsed 10m 52s (remain 5m 42s) \n","Epoch: [3][350/459] Elapsed 12m 40s (remain 3m 53s) \n","Epoch: [3][400/459] Elapsed 14m 28s (remain 2m 5s) \n","Epoch: [3][450/459] Elapsed 16m 16s (remain 0m 17s) \n","Epoch: [3][458/459] Elapsed 16m 34s (remain 0m 0s) \n","EVAL: [0/77] Elapsed 0m 1s (remain 1m 32s) \n","EVAL: [50/77] Elapsed 0m 52s (remain 0m 26s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.1960  avg_val_loss: 0.4111  time: 1073s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.1960  avg_val_loss: 0.4111  time: 1073s\n","Epoch 3 - Score: 0.8222\n","INFO:__main__:Epoch 3 - Score: 0.8222\n","Epoch 3 - Save Best Score: 0.8222 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.8222 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 1m 18s (remain 0m 0s) \n","Epoch: [4][0/459] Elapsed 0m 2s (remain 18m 17s) \n","Epoch: [4][50/459] Elapsed 1m 50s (remain 14m 45s) \n","Epoch: [4][100/459] Elapsed 3m 38s (remain 12m 56s) \n","Epoch: [4][150/459] Elapsed 5m 27s (remain 11m 7s) \n","Epoch: [4][200/459] Elapsed 7m 15s (remain 9m 19s) \n","Epoch: [4][250/459] Elapsed 9m 3s (remain 7m 30s) \n","Epoch: [4][300/459] Elapsed 10m 52s (remain 5m 42s) \n","Epoch: [4][350/459] Elapsed 12m 40s (remain 3m 53s) \n","Epoch: [4][400/459] Elapsed 14m 28s (remain 2m 5s) \n","Epoch: [4][450/459] Elapsed 16m 16s (remain 0m 17s) \n","Epoch: [4][458/459] Elapsed 16m 34s (remain 0m 0s) \n","EVAL: [0/77] Elapsed 0m 1s (remain 1m 31s) \n","EVAL: [50/77] Elapsed 0m 52s (remain 0m 26s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.0659  avg_val_loss: 0.5109  time: 1073s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0659  avg_val_loss: 0.5109  time: 1073s\n","Epoch 4 - Score: 0.8203\n","INFO:__main__:Epoch 4 - Score: 0.8203\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 1m 18s (remain 0m 0s) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 3 result ==========\n","INFO:__main__:========== fold: 3 result ==========\n","Score: 0.8222\n","INFO:__main__:Score: 0.8222\n","========== CV ==========\n","INFO:__main__:========== CV ==========\n"]},{"output_type":"stream","name":"stdout","text":["0.8222133439872154\n"]},{"output_type":"stream","name":"stderr","text":["Score: 0.8155\n","INFO:__main__:Score: 0.8155\n"]}]},{"cell_type":"code","source":["A = pd.read_csv(OUTPUT_MODEL_DIR+'oof_df.csv')\n","A.head()"],"metadata":{"id":"_PiTcgQSD--O","executionInfo":{"status":"ok","timestamp":1662656331877,"user_tz":-540,"elapsed":549,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"colab":{"base_uri":"https://localhost:8080/","height":600},"outputId":"2323f6ce-72d0-4a7d-c92b-bf0ba89788a0"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["            id         goal country  duration   category1        category2  \\\n","0  train_00002    2001-3000      US        38         art  performance art   \n","1  train_00006    2001-3000      CA        30       music  classical music   \n","2  train_00016    3001-4000      GB        30  journalism              web   \n","3  train_00017  11001-12000      US        30        food           drinks   \n","4  train_00018  12001-13000      US        28  journalism              web   \n","\n","                                        html_content  label  \\\n","0  I want to perform this piece guerilla style, o...      0   \n","1  The Crimson String Quartet (CSQ) is returning ...      1   \n","2  I am interested in setting up a small news web...      0   \n","3  Why Schenk-Atwood?Our neighborhood has just ab...      1   \n","4  Mega Visions app has been approved on all majo...      1   \n","\n","                                              inputs  kfold      pred  \n","0  2001-3000 ; 38 [SEP] US [SEP] art ; performanc...      0  0.816360  \n","1  2001-3000 ; 30 [SEP] CA [SEP] music ; classica...      0  0.742539  \n","2  3001-4000 ; 30 [SEP] GB [SEP] journalism ; web...      0  0.001581  \n","3  11001-12000 ; 30 [SEP] US [SEP] food ; drinks ...      0  0.540023  \n","4  12001-13000 ; 28 [SEP] US [SEP] journalism ; w...      0  0.840174  "],"text/html":["\n","  <div id=\"df-0ff6375b-5a79-4f53-848e-72866aec1bd1\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>goal</th>\n","      <th>country</th>\n","      <th>duration</th>\n","      <th>category1</th>\n","      <th>category2</th>\n","      <th>html_content</th>\n","      <th>label</th>\n","      <th>inputs</th>\n","      <th>kfold</th>\n","      <th>pred</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>train_00002</td>\n","      <td>2001-3000</td>\n","      <td>US</td>\n","      <td>38</td>\n","      <td>art</td>\n","      <td>performance art</td>\n","      <td>I want to perform this piece guerilla style, o...</td>\n","      <td>0</td>\n","      <td>2001-3000 ; 38 [SEP] US [SEP] art ; performanc...</td>\n","      <td>0</td>\n","      <td>0.816360</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>train_00006</td>\n","      <td>2001-3000</td>\n","      <td>CA</td>\n","      <td>30</td>\n","      <td>music</td>\n","      <td>classical music</td>\n","      <td>The Crimson String Quartet (CSQ) is returning ...</td>\n","      <td>1</td>\n","      <td>2001-3000 ; 30 [SEP] CA [SEP] music ; classica...</td>\n","      <td>0</td>\n","      <td>0.742539</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>train_00016</td>\n","      <td>3001-4000</td>\n","      <td>GB</td>\n","      <td>30</td>\n","      <td>journalism</td>\n","      <td>web</td>\n","      <td>I am interested in setting up a small news web...</td>\n","      <td>0</td>\n","      <td>3001-4000 ; 30 [SEP] GB [SEP] journalism ; web...</td>\n","      <td>0</td>\n","      <td>0.001581</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>train_00017</td>\n","      <td>11001-12000</td>\n","      <td>US</td>\n","      <td>30</td>\n","      <td>food</td>\n","      <td>drinks</td>\n","      <td>Why Schenk-Atwood?Our neighborhood has just ab...</td>\n","      <td>1</td>\n","      <td>11001-12000 ; 30 [SEP] US [SEP] food ; drinks ...</td>\n","      <td>0</td>\n","      <td>0.540023</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>train_00018</td>\n","      <td>12001-13000</td>\n","      <td>US</td>\n","      <td>28</td>\n","      <td>journalism</td>\n","      <td>web</td>\n","      <td>Mega Visions app has been approved on all majo...</td>\n","      <td>1</td>\n","      <td>12001-13000 ; 28 [SEP] US [SEP] journalism ; w...</td>\n","      <td>0</td>\n","      <td>0.840174</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ff6375b-5a79-4f53-848e-72866aec1bd1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0ff6375b-5a79-4f53-848e-72866aec1bd1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0ff6375b-5a79-4f53-848e-72866aec1bd1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":[],"metadata":{"id":"UczAxlAEOTq7","executionInfo":{"status":"ok","timestamp":1662656331878,"user_tz":-540,"elapsed":10,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"4HAagBcvUL2D","executionInfo":{"status":"ok","timestamp":1662656331878,"user_tz":-540,"elapsed":9,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":23,"outputs":[]}]}