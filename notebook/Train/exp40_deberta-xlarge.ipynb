{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","collapsed_sections":[],"authorship_tag":"ABX9TyMZGQPAwXLB8N8pKbPxyXHk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"862aab6073f1473ebc8ba046a0aa972a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fff95a8905834bcdb5d53d41967635e0","IPY_MODEL_9454c251bfa941e78b864967e3adbef5","IPY_MODEL_ac814f0589e64199955c4ebbc6544795"],"layout":"IPY_MODEL_5b774e84ae04497ba998bb2518df63bb"}},"fff95a8905834bcdb5d53d41967635e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a741c1ce48a43f0b4b4880e185e8b95","placeholder":"​","style":"IPY_MODEL_5a61484bfe8346a8afd877d6888499c2","value":""}},"9454c251bfa941e78b864967e3adbef5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3bbd0681388b40a9929521dfc52462ae","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f5e3f616f81843d1bfa54a86c36fc116","value":0}},"ac814f0589e64199955c4ebbc6544795":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3e4e61aa45e4544b62bb9aa5b39bf33","placeholder":"​","style":"IPY_MODEL_48d81eece25848b184bc8222a8913b4a","value":" 0/0 [00:00&lt;?, ?it/s]"}},"5b774e84ae04497ba998bb2518df63bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a741c1ce48a43f0b4b4880e185e8b95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a61484bfe8346a8afd877d6888499c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3bbd0681388b40a9929521dfc52462ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"f5e3f616f81843d1bfa54a86c36fc116":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c3e4e61aa45e4544b62bb9aa5b39bf33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48d81eece25848b184bc8222a8913b4a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e1cc33894ed4aba8832ab8e7e5ec0c7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_da6a560f40d24d0eab8e38f3c43983d3","IPY_MODEL_b94e3aeb07674b7690633b3418fe97cd","IPY_MODEL_4de29545015d4f28b0096ba11238d237"],"layout":"IPY_MODEL_ab4f0f30717745fd832aac5e04cb62ba"}},"da6a560f40d24d0eab8e38f3c43983d3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_665dca990d154131aa1c7dff1354af78","placeholder":"​","style":"IPY_MODEL_0a509799e5b343a4b57337ff7210fa67","value":"Downloading: 100%"}},"b94e3aeb07674b7690633b3418fe97cd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_539145ab46714d7f8f7daaddc02d4e5a","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ba1626a73857472ab6ffbdf8cb56c12c","value":52}},"4de29545015d4f28b0096ba11238d237":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a5308ea2ae74e31ace5d0e00bb70a08","placeholder":"​","style":"IPY_MODEL_9c3d49fc2f5444e387dfc0dd04f156b8","value":" 52.0/52.0 [00:00&lt;00:00, 637B/s]"}},"ab4f0f30717745fd832aac5e04cb62ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"665dca990d154131aa1c7dff1354af78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a509799e5b343a4b57337ff7210fa67":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"539145ab46714d7f8f7daaddc02d4e5a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba1626a73857472ab6ffbdf8cb56c12c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6a5308ea2ae74e31ace5d0e00bb70a08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c3d49fc2f5444e387dfc0dd04f156b8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cc07047b857848efb01463e365024f4d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_86a59b5aef8547afa8334d0fbad30fd6","IPY_MODEL_2a99427b494c4d9a801da02c7db78b5d","IPY_MODEL_700b861979fb492c8340f17489016e82"],"layout":"IPY_MODEL_7dfcc449ab064ebba4558cf3576ace55"}},"86a59b5aef8547afa8334d0fbad30fd6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_14942b061eb543a1a738f11b1c7e1628","placeholder":"​","style":"IPY_MODEL_eae561863c524888a0af389e69d35317","value":"Downloading: 100%"}},"2a99427b494c4d9a801da02c7db78b5d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a93727d3b18d4e008640e5ec37822ccb","max":475,"min":0,"orientation":"horizontal","style":"IPY_MODEL_64e00907b87c4d1aaebe0428f8e1045b","value":475}},"700b861979fb492c8340f17489016e82":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_33e541363a9f4ac8b8a1710f799e4453","placeholder":"​","style":"IPY_MODEL_8cfdf03a3c1e4aa4aab36c65d38f7823","value":" 475/475 [00:00&lt;00:00, 5.15kB/s]"}},"7dfcc449ab064ebba4558cf3576ace55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14942b061eb543a1a738f11b1c7e1628":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eae561863c524888a0af389e69d35317":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a93727d3b18d4e008640e5ec37822ccb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64e00907b87c4d1aaebe0428f8e1045b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"33e541363a9f4ac8b8a1710f799e4453":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8cfdf03a3c1e4aa4aab36c65d38f7823":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d75dc707837e4e70b9c9f4bcd154784b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c275f4d6635d4d8abd6fdebfe4b5be31","IPY_MODEL_281d00ff1760437d91e70cd8c1fb389c","IPY_MODEL_a978631659aa40f08588fecaed30c272"],"layout":"IPY_MODEL_3e9af97268bd452788389b3283b1f2f9"}},"c275f4d6635d4d8abd6fdebfe4b5be31":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_00f1511014a746d492da411fa84677ab","placeholder":"​","style":"IPY_MODEL_c40e6d64ae5f41aeb8744a6fab75d19b","value":"Downloading: 100%"}},"281d00ff1760437d91e70cd8c1fb389c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d55ffe72d6bf4d578305ba832d16b36b","max":898825,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cfb988a24f4e4a3a96deb65aa96b4886","value":898825}},"a978631659aa40f08588fecaed30c272":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ee4c33a1e1a4b709342693ec29bb61b","placeholder":"​","style":"IPY_MODEL_fc79f45593564a689ef9dbb4ad5fb3a4","value":" 899k/899k [00:00&lt;00:00, 2.43MB/s]"}},"3e9af97268bd452788389b3283b1f2f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"00f1511014a746d492da411fa84677ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c40e6d64ae5f41aeb8744a6fab75d19b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d55ffe72d6bf4d578305ba832d16b36b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfb988a24f4e4a3a96deb65aa96b4886":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9ee4c33a1e1a4b709342693ec29bb61b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc79f45593564a689ef9dbb4ad5fb3a4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0465d4b56c124e6c8b5020bbd908bd01":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_80ca3a40808b41c789e5f7b4f28f18d3","IPY_MODEL_77529b4ebdf4486cb9226ade71c169a4","IPY_MODEL_f8ce242241064d66b63e93198368e457"],"layout":"IPY_MODEL_5b101ee78e9344f1b656cfb4f0f64ddd"}},"80ca3a40808b41c789e5f7b4f28f18d3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a765ece33c643189314046dd323eec4","placeholder":"​","style":"IPY_MODEL_36d5c8aef5f4471ca77c17faf2ff9054","value":"Downloading: 100%"}},"77529b4ebdf4486cb9226ade71c169a4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_07e09661df804695acd4840af4ce08b3","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bb6a9bbb66f443c2a29d7d89cf5a8841","value":456318}},"f8ce242241064d66b63e93198368e457":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c37d1aabcb8d49d081d7e1ba25838495","placeholder":"​","style":"IPY_MODEL_67acf558c5a54026b3da07cf5ce01352","value":" 456k/456k [00:00&lt;00:00, 784kB/s]"}},"5b101ee78e9344f1b656cfb4f0f64ddd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a765ece33c643189314046dd323eec4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36d5c8aef5f4471ca77c17faf2ff9054":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"07e09661df804695acd4840af4ce08b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb6a9bbb66f443c2a29d7d89cf5a8841":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c37d1aabcb8d49d081d7e1ba25838495":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67acf558c5a54026b3da07cf5ce01352":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"523ea0cb9dd6425aaad0ef50686aa6d5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d706b7bb574c439080aa7241417ce80b","IPY_MODEL_78d68a817c4e4febaed2d566841cf85b","IPY_MODEL_8e4a45d47ee84a2eb3744718d0d9d5cc"],"layout":"IPY_MODEL_41a8b04188684f58b9881d90fa2e4ea3"}},"d706b7bb574c439080aa7241417ce80b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c7b30b1324a4519b45eee681350c539","placeholder":"​","style":"IPY_MODEL_b074afa665b14c35808b827d74dad8cd","value":"Downloading: 100%"}},"78d68a817c4e4febaed2d566841cf85b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_19bac2e918f048a88cb4ee2166b720d3","max":1518990915,"min":0,"orientation":"horizontal","style":"IPY_MODEL_051619b784c040a8993dce17c1595161","value":1518990915}},"8e4a45d47ee84a2eb3744718d0d9d5cc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_36a3c618029148bcab0b9a6c6a40ad16","placeholder":"​","style":"IPY_MODEL_d1d57740207947339fd4abb32320f4ab","value":" 1.52G/1.52G [00:23&lt;00:00, 66.6MB/s]"}},"41a8b04188684f58b9881d90fa2e4ea3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c7b30b1324a4519b45eee681350c539":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b074afa665b14c35808b827d74dad8cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"19bac2e918f048a88cb4ee2166b720d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"051619b784c040a8993dce17c1595161":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"36a3c618029148bcab0b9a6c6a40ad16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1d57740207947339fd4abb32320f4ab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["出力先を2つにする"],"metadata":{"id":"f8aGHNX0A0ZI"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UtHPx5o75TKH","executionInfo":{"status":"ok","timestamp":1663520100631,"user_tz":-540,"elapsed":16974,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"c8bf9da5-edf4-4da3-b513-8b9ad3ab6858"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","source":["!pip install transformers\n","!pip install datasets\n","!pip install sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ign_5QW05bpr","executionInfo":{"status":"ok","timestamp":1663520117019,"user_tz":-540,"elapsed":16393,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"b3e90d1d-e6f8-49c8-8b70-f716cd1857d8"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.22.1-py3-none-any.whl (4.9 MB)\n","\u001b[K     |████████████████████████████████| 4.9 MB 8.3 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 72.6 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Collecting huggingface-hub<1.0,>=0.9.0\n","  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n","\u001b[K     |████████████████████████████████| 120 kB 91.2 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.22.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n","\u001b[K     |████████████████████████████████| 365 kB 8.1 MB/s \n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.8.2)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n","\u001b[K     |████████████████████████████████| 115 kB 84.0 MB/s \n","\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n","Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.12.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Collecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 82.4 MB/s \n","\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.9.1)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 96.5 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.2.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: urllib3, xxhash, responses, multiprocess, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed datasets-2.4.0 multiprocess-0.70.13 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 8.5 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n"]}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NHtchefz5goV","executionInfo":{"status":"ok","timestamp":1663520117469,"user_tz":-540,"elapsed":454,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"a0e11d9b-306e-45ab-8a51-6b23f1b623a5"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Sep 18 16:55:17 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["import os\n","import gc\n","import math\n","import time\n","import random\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.simplefilter('ignore')\n","from tqdm import tqdm\n","import re\n","import html\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim import Adam, SGD, AdamW, RAdam\n","from torch.optim import lr_scheduler\n","from torch.utils.data import DataLoader, Dataset\n","\n","from sklearn.model_selection import StratifiedKFold,StratifiedGroupKFold,GroupKFold\n","#from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import log_loss,f1_score\n","\n","from transformers import AutoModel, AutoConfig, AutoTokenizer, AdamW, DataCollatorWithPadding\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"_O7dPzvG5lLe","executionInfo":{"status":"ok","timestamp":1663520122712,"user_tz":-540,"elapsed":5244,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"colab":{"base_uri":"https://localhost:8080/","height":105,"referenced_widgets":["862aab6073f1473ebc8ba046a0aa972a","fff95a8905834bcdb5d53d41967635e0","9454c251bfa941e78b864967e3adbef5","ac814f0589e64199955c4ebbc6544795","5b774e84ae04497ba998bb2518df63bb","1a741c1ce48a43f0b4b4880e185e8b95","5a61484bfe8346a8afd877d6888499c2","3bbd0681388b40a9929521dfc52462ae","f5e3f616f81843d1bfa54a86c36fc116","c3e4e61aa45e4544b62bb9aa5b39bf33","48d81eece25848b184bc8222a8913b4a"]},"outputId":"0a1dbe32-f30c-4b1e-e4e3-6827903205da"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"]},{"output_type":"stream","name":"stdout","text":["Moving 0 files to the new cache system\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"862aab6073f1473ebc8ba046a0aa972a"}},"metadata":{}}]},{"cell_type":"code","source":["# ====================================================\n","# CFG\n","# ====================================================\n","class CFG:\n","    debug=False\n","    debug2 = False\n","    apex=True\n","    print_freq=100\n","    num_workers=4\n","    # model=\"microsoft/deberta-v3-base\" #o\n","    # model='microsoft/deberta-base'  △\n","    # model='roberta-base'  x\n","    # model='roberta-large'  x\n","    # model='roberta-large-mnli'\n","    # model='google/bigbird-roberta-base'\n","    # model='google/bigbird-roberta-large'\n","    # model='xlnet-large-cased'  △\n","    # model='albert-xxlarge-v2'\n","    # model=\"microsoft/deberta-large\" o\n","    # model=\"microsoft/deberta-v3-large\"  #o\n","    # model='microsoft/deberta-v2-xlarge' x\n","    # model='microsoft/deberta-v2-xxlarge'\n","    model='microsoft/deberta-xlarge' #o\n","    # model='funnel-transformer/large' o\n","    # model='funnel-transformer/medium' △\n","    # model='albert-base-v2'\n","    # model='albert-large-v2'  x\n","    # model='google/electra-large-discriminator'  x\n","    # model='google/electra-base-discriminator'  x\n","    # model=\"facebook/bart-large-mnli\"\n","    # model=\"facebook/bart-large\"  o\n","    # model=\"facebook/bart-base\"\n","    # model = \"distilbert-base-uncased\" x\n","    # model = \"allenai/longformer-large-4096\" x\n","    # model = \"allenai/longformer-base-4096\"\n","    # model = \"uw-madison/yoso-4096\"  x\n","    # model = \"xlm-roberta-large\"\n","    # model = \"xlm-roberta-base\"\n","    # model = \"google/muril-large-cased\" x\n","    # model = \"google/rembert\" x\n","    scheduler='cosine' # ['linear', 'cosine']\n","    batch_scheduler=True\n","    num_cycles=0.5\n","    num_warmup_steps=0\n","    epochs=4\n","    encoder_lr=2e-5\n","    decoder_lr=2e-5\n","    min_lr=1e-6\n","    eps=1e-6\n","    betas=(0.9, 0.999)\n","    batch_size=16\n","    fc_dropout=0.2\n","    target_size=2\n","    max_len=256\n","    weight_decay=0.01\n","    gradient_accumulation_steps=1\n","    max_grad_norm=1000\n","    seed=42\n","    n_fold=4\n","    trn_fold=[0, 1, 2, 3]\n","    train=True\n","    nth_awp_start_epoch=1\n","    gradient_checkpointing = True\n","    freezing = True\n","    clean_content = True\n","    target_cols = [\"state\",\"category1\"]\n","\n","if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.trn_fold = [0, 1]\n","\n","if CFG.debug2:\n","    CFG.epochs = 3\n","    CFG.trn_fold = [0]"],"metadata":{"id":"4b5Y6si363K7","executionInfo":{"status":"ok","timestamp":1663520122713,"user_tz":-540,"elapsed":4,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["DIR = '/content/drive/MyDrive/Competitions/Signate/MUFJ'\n","INPUT_DIR = os.path.join(DIR,'input')\n","OUTPUT_DIR = os.path.join(DIR,'output')\n","OUTPUT_SUB_DIR = os.path.join(OUTPUT_DIR,'submission')\n","#OUTPUT_MODEL_DIR = os.path.join(OUTPUT_DIR,'model')\n","OUTPUT_MODEL_DIR = DIR + '/output/model/EXP40/'\n","if not os.path.exists(OUTPUT_MODEL_DIR):\n","    os.makedirs(OUTPUT_MODEL_DIR)"],"metadata":{"id":"Lo7k9Uzp93_J","executionInfo":{"status":"ok","timestamp":1663520123852,"user_tz":-540,"elapsed":1142,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def get_score(labels, outputs):\n","    thresh = 0.5\n","    y_pred = outputs[:,0]\n","    y_true = labels[:,0]\n","    return f1_score(y_true, (y_pred>thresh).astype(int))\n","\n","\n","def get_logger(filename=OUTPUT_MODEL_DIR+'train'):\n","    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","def seed_everything(seed=CFG.seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(seed=CFG.seed)"],"metadata":{"id":"7yfBWz8D99ZZ","executionInfo":{"status":"ok","timestamp":1663520123852,"user_tz":-540,"elapsed":3,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def freeze(module):\n","    \"\"\"\n","    Freezes module's parameters.\n","    \"\"\"\n","    \n","    for parameter in module.parameters():\n","        parameter.requires_grad = False\n","        \n","def get_freezed_parameters(module):\n","    \"\"\"\n","    Returns names of freezed parameters of the given module.\n","    \"\"\"\n","    \n","    freezed_parameters = []\n","    for name, parameter in module.named_parameters():\n","        if not parameter.requires_grad:\n","            freezed_parameters.append(name)\n","            \n","    return freezed_parameters\n","\n","def set_embedding_parameters_bits(embeddings_path, optim_bits=32):\n","    \"\"\"\n","    https://github.com/huggingface/transformers/issues/14819#issuecomment-1003427930\n","    \"\"\"\n","    \n","    embedding_types = (\"word\", \"position\", \"token_type\")\n","    for embedding_type in embedding_types:\n","        attr_name = f\"{embedding_type}_embeddings\"\n","        \n","        if hasattr(embeddings_path, attr_name): \n","            bnb.optim.GlobalOptimManager.get_instance().register_module_override(\n","                getattr(embeddings_path, attr_name), 'weight', {'optim_bits': optim_bits}\n","            )"],"metadata":{"id":"7Msw-Z4V-Q5q","executionInfo":{"status":"ok","timestamp":1663520123853,"user_tz":-540,"elapsed":4,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["train = pd.read_csv(os.path.join(INPUT_DIR,'train.csv'))\n","test = pd.read_csv(os.path.join(INPUT_DIR,'test.csv'))\n","sub = pd.read_csv(os.path.join(INPUT_DIR,'sample_submit.csv'),header=None)\n","sub.columns = ['id','state']"],"metadata":{"id":"Q988lRbI-AzX","executionInfo":{"status":"ok","timestamp":1663520126047,"user_tz":-540,"elapsed":2198,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def remove_URL(text):\n","    url = re.compile(r'https?://\\S+|www\\.\\S+')\n","    return url.sub('',text)\n","\n","def remove_html(text):\n","    html=re.compile(r\"<[^>]*?>\")\n","    return html.sub('',text)\n","\n","def cleaning(texts):\n","    clean_texts = []\n","    for text in texts:\n","        # htmlタグを削除\n","        text = remove_URL(text)\n","        text = remove_html(text)\n","        #アルファベット以外をスペースに置き換え\n","        #clean_punc = re.sub(r'[^a-zA-Z]', ' ', text)\n","        #改行削除\n","        #text = text.replace(\"\\n\",\"\")\n","        clean_texts.append(text)\n","    return clean_texts\n","\n","def get_goal_values(df):\n","  df[\"goal\"].replace(\"100000+\",\"100000-100000\",inplace=True)\n","  _df = df[\"goal\"].str.split('-').apply(pd.Series).astype(float)\n","  _df.columns = [\"goal_max\",\"goal_min\"]\n","  df[\"goal_max\"] = _df[\"goal_max\"].astype(str)\n","  df[\"goal_min\"] = _df[\"goal_min\"].astype(str)\n","  df[\"goal_median\"] = _df[[\"goal_max\",\"goal_min\"]].median(axis=1)\n","  df[\"goal_median\"] = df[\"goal_median\"].astype(int)\n","  return df\n","\n","if CFG.clean_content==True:\n","    train['html_content'] = train['html_content'].map(lambda x: str(x))\n","    train['html_content'] = train['html_content'].apply(html.unescape)\n","    p = re.compile(r\"<[^>]*?>|&amp;|[/'’\\\"”]\")\n","    train['html_content'] = train['html_content'].map(lambda x: p.sub(\"\", x))\n","    train['html_content'] = train['html_content'].map(lambda x: x.lstrip())\n","    train['html_content'] = train['html_content'].fillna('missing')\n","\n","train = get_goal_values(train)\n","train['inputs'] = train.goal_median.astype(str) + ' [SEP] ' + train.duration.astype(str) + ' [SEP] ' + train.country  + ' [SEP] ' + train.category2 + ' [SEP] ' + train.html_content\n","le =  LabelEncoder()\n","train[\"category1\"] = le.fit_transform(train[\"category1\"])"],"metadata":{"id":"VZDywrmo-G71","executionInfo":{"status":"ok","timestamp":1663520128830,"user_tz":-540,"elapsed":2785,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":641},"id":"haCa8vqHj4_Q","executionInfo":{"status":"ok","timestamp":1663520128832,"user_tz":-540,"elapsed":7,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"66441b03-5ede-45c9-c40a-c5f1f837e0e1"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["               id           goal country  duration  category1  \\\n","0     train_00000    20001-21000      US        45          0   \n","1     train_00001    19001-20000      US        59          7   \n","2     train_00002      2001-3000      US        38          0   \n","3     train_00003      1001-2000      US        30          0   \n","4     train_00004      1001-2000      US        29          6   \n","...           ...            ...     ...       ...        ...   \n","9786  train_09786         1-1000      US        15         10   \n","9787  train_09787      3001-4000      CA        30          5   \n","9788  train_09788  100000-100000      GB        30         13   \n","9789  train_09789    79001-80000      US        35         13   \n","9790  train_09790      1001-2000      ES        30          0   \n","\n","             category2                                       html_content  \\\n","0          mixed media  http:dummy.comIn its first year, The Shillitos...   \n","1          restaurants  Cultural Pretzel Sports Bar is a place where p...   \n","2      performance art  I want to perform this piece guerilla style, o...   \n","3          mixed media  Canyon de Chelley, Dine (Navajo) Reservation, ...   \n","4            webseries  The story of the show, both on and off screen,...   \n","...                ...                                                ...   \n","9786  electronic music  So the story behind this is that Ive been maki...   \n","9787     ready-to-wear  THE HIGH CLOTHINGMy vision is to create high q...   \n","9788          software  We dont think anybody looks forward to filling...   \n","9789           gadgets  What is Droplet?\\nDroplet is a wireless button...   \n","9790    conceptual art  Artyoutube Art inspired in YoutubeMany popular...   \n","\n","      state  goal_max  goal_min  goal_median  \\\n","0         1   20001.0   21000.0        20500   \n","1         0   19001.0   20000.0        19500   \n","2         0    2001.0    3000.0         2500   \n","3         1    1001.0    2000.0         1500   \n","4         1    1001.0    2000.0         1500   \n","...     ...       ...       ...          ...   \n","9786      0       1.0    1000.0          500   \n","9787      0    3001.0    4000.0         3500   \n","9788      0  100000.0  100000.0       100000   \n","9789      1   79001.0   80000.0        79500   \n","9790      0    1001.0    2000.0         1500   \n","\n","                                                 inputs  \n","0     20500 [SEP] 45 [SEP] US [SEP] mixed media [SEP...  \n","1     19500 [SEP] 59 [SEP] US [SEP] restaurants [SEP...  \n","2     2500 [SEP] 38 [SEP] US [SEP] performance art [...  \n","3     1500 [SEP] 30 [SEP] US [SEP] mixed media [SEP]...  \n","4     1500 [SEP] 29 [SEP] US [SEP] webseries [SEP] T...  \n","...                                                 ...  \n","9786  500 [SEP] 15 [SEP] US [SEP] electronic music [...  \n","9787  3500 [SEP] 30 [SEP] CA [SEP] ready-to-wear [SE...  \n","9788  100000 [SEP] 30 [SEP] GB [SEP] software [SEP] ...  \n","9789  79500 [SEP] 35 [SEP] US [SEP] gadgets [SEP] Wh...  \n","9790  1500 [SEP] 30 [SEP] ES [SEP] conceptual art [S...  \n","\n","[9791 rows x 12 columns]"],"text/html":["\n","  <div id=\"df-50ddeb21-d6e6-4922-823f-5fc7356fdaab\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>goal</th>\n","      <th>country</th>\n","      <th>duration</th>\n","      <th>category1</th>\n","      <th>category2</th>\n","      <th>html_content</th>\n","      <th>state</th>\n","      <th>goal_max</th>\n","      <th>goal_min</th>\n","      <th>goal_median</th>\n","      <th>inputs</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>train_00000</td>\n","      <td>20001-21000</td>\n","      <td>US</td>\n","      <td>45</td>\n","      <td>0</td>\n","      <td>mixed media</td>\n","      <td>http:dummy.comIn its first year, The Shillitos...</td>\n","      <td>1</td>\n","      <td>20001.0</td>\n","      <td>21000.0</td>\n","      <td>20500</td>\n","      <td>20500 [SEP] 45 [SEP] US [SEP] mixed media [SEP...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>train_00001</td>\n","      <td>19001-20000</td>\n","      <td>US</td>\n","      <td>59</td>\n","      <td>7</td>\n","      <td>restaurants</td>\n","      <td>Cultural Pretzel Sports Bar is a place where p...</td>\n","      <td>0</td>\n","      <td>19001.0</td>\n","      <td>20000.0</td>\n","      <td>19500</td>\n","      <td>19500 [SEP] 59 [SEP] US [SEP] restaurants [SEP...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>train_00002</td>\n","      <td>2001-3000</td>\n","      <td>US</td>\n","      <td>38</td>\n","      <td>0</td>\n","      <td>performance art</td>\n","      <td>I want to perform this piece guerilla style, o...</td>\n","      <td>0</td>\n","      <td>2001.0</td>\n","      <td>3000.0</td>\n","      <td>2500</td>\n","      <td>2500 [SEP] 38 [SEP] US [SEP] performance art [...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>train_00003</td>\n","      <td>1001-2000</td>\n","      <td>US</td>\n","      <td>30</td>\n","      <td>0</td>\n","      <td>mixed media</td>\n","      <td>Canyon de Chelley, Dine (Navajo) Reservation, ...</td>\n","      <td>1</td>\n","      <td>1001.0</td>\n","      <td>2000.0</td>\n","      <td>1500</td>\n","      <td>1500 [SEP] 30 [SEP] US [SEP] mixed media [SEP]...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>train_00004</td>\n","      <td>1001-2000</td>\n","      <td>US</td>\n","      <td>29</td>\n","      <td>6</td>\n","      <td>webseries</td>\n","      <td>The story of the show, both on and off screen,...</td>\n","      <td>1</td>\n","      <td>1001.0</td>\n","      <td>2000.0</td>\n","      <td>1500</td>\n","      <td>1500 [SEP] 29 [SEP] US [SEP] webseries [SEP] T...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>9786</th>\n","      <td>train_09786</td>\n","      <td>1-1000</td>\n","      <td>US</td>\n","      <td>15</td>\n","      <td>10</td>\n","      <td>electronic music</td>\n","      <td>So the story behind this is that Ive been maki...</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>1000.0</td>\n","      <td>500</td>\n","      <td>500 [SEP] 15 [SEP] US [SEP] electronic music [...</td>\n","    </tr>\n","    <tr>\n","      <th>9787</th>\n","      <td>train_09787</td>\n","      <td>3001-4000</td>\n","      <td>CA</td>\n","      <td>30</td>\n","      <td>5</td>\n","      <td>ready-to-wear</td>\n","      <td>THE HIGH CLOTHINGMy vision is to create high q...</td>\n","      <td>0</td>\n","      <td>3001.0</td>\n","      <td>4000.0</td>\n","      <td>3500</td>\n","      <td>3500 [SEP] 30 [SEP] CA [SEP] ready-to-wear [SE...</td>\n","    </tr>\n","    <tr>\n","      <th>9788</th>\n","      <td>train_09788</td>\n","      <td>100000-100000</td>\n","      <td>GB</td>\n","      <td>30</td>\n","      <td>13</td>\n","      <td>software</td>\n","      <td>We dont think anybody looks forward to filling...</td>\n","      <td>0</td>\n","      <td>100000.0</td>\n","      <td>100000.0</td>\n","      <td>100000</td>\n","      <td>100000 [SEP] 30 [SEP] GB [SEP] software [SEP] ...</td>\n","    </tr>\n","    <tr>\n","      <th>9789</th>\n","      <td>train_09789</td>\n","      <td>79001-80000</td>\n","      <td>US</td>\n","      <td>35</td>\n","      <td>13</td>\n","      <td>gadgets</td>\n","      <td>What is Droplet?\\nDroplet is a wireless button...</td>\n","      <td>1</td>\n","      <td>79001.0</td>\n","      <td>80000.0</td>\n","      <td>79500</td>\n","      <td>79500 [SEP] 35 [SEP] US [SEP] gadgets [SEP] Wh...</td>\n","    </tr>\n","    <tr>\n","      <th>9790</th>\n","      <td>train_09790</td>\n","      <td>1001-2000</td>\n","      <td>ES</td>\n","      <td>30</td>\n","      <td>0</td>\n","      <td>conceptual art</td>\n","      <td>Artyoutube Art inspired in YoutubeMany popular...</td>\n","      <td>0</td>\n","      <td>1001.0</td>\n","      <td>2000.0</td>\n","      <td>1500</td>\n","      <td>1500 [SEP] 30 [SEP] ES [SEP] conceptual art [S...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>9791 rows × 12 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50ddeb21-d6e6-4922-823f-5fc7356fdaab')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-50ddeb21-d6e6-4922-823f-5fc7356fdaab button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-50ddeb21-d6e6-4922-823f-5fc7356fdaab');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["skf = StratifiedKFold(n_splits=CFG.n_fold,shuffle=True,random_state=CFG.seed)\n","for fold, ( _, val_) in enumerate(skf.split(train, train.state)):\n","    train.loc[val_ , \"kfold\"] = int(fold)\n","    \n","train[\"kfold\"] = train[\"kfold\"].astype(int)\n","\n","if CFG.debug:\n","    display(train.groupby('kfold').size())\n","    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n","    display(train.groupby('kfold').size())"],"metadata":{"id":"FR5JQ4UF-cjJ","executionInfo":{"status":"ok","timestamp":1663520128832,"user_tz":-540,"elapsed":5,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# tokenizer\n","# ====================================================\n","tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n","tokenizer.save_pretrained(OUTPUT_MODEL_DIR+'tokenizer/')\n","CFG.tokenizer = tokenizer"],"metadata":{"id":"fz40KlX9-l-9","executionInfo":{"status":"ok","timestamp":1663520133246,"user_tz":-540,"elapsed":4419,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["4e1cc33894ed4aba8832ab8e7e5ec0c7","da6a560f40d24d0eab8e38f3c43983d3","b94e3aeb07674b7690633b3418fe97cd","4de29545015d4f28b0096ba11238d237","ab4f0f30717745fd832aac5e04cb62ba","665dca990d154131aa1c7dff1354af78","0a509799e5b343a4b57337ff7210fa67","539145ab46714d7f8f7daaddc02d4e5a","ba1626a73857472ab6ffbdf8cb56c12c","6a5308ea2ae74e31ace5d0e00bb70a08","9c3d49fc2f5444e387dfc0dd04f156b8","cc07047b857848efb01463e365024f4d","86a59b5aef8547afa8334d0fbad30fd6","2a99427b494c4d9a801da02c7db78b5d","700b861979fb492c8340f17489016e82","7dfcc449ab064ebba4558cf3576ace55","14942b061eb543a1a738f11b1c7e1628","eae561863c524888a0af389e69d35317","a93727d3b18d4e008640e5ec37822ccb","64e00907b87c4d1aaebe0428f8e1045b","33e541363a9f4ac8b8a1710f799e4453","8cfdf03a3c1e4aa4aab36c65d38f7823","d75dc707837e4e70b9c9f4bcd154784b","c275f4d6635d4d8abd6fdebfe4b5be31","281d00ff1760437d91e70cd8c1fb389c","a978631659aa40f08588fecaed30c272","3e9af97268bd452788389b3283b1f2f9","00f1511014a746d492da411fa84677ab","c40e6d64ae5f41aeb8744a6fab75d19b","d55ffe72d6bf4d578305ba832d16b36b","cfb988a24f4e4a3a96deb65aa96b4886","9ee4c33a1e1a4b709342693ec29bb61b","fc79f45593564a689ef9dbb4ad5fb3a4","0465d4b56c124e6c8b5020bbd908bd01","80ca3a40808b41c789e5f7b4f28f18d3","77529b4ebdf4486cb9226ade71c169a4","f8ce242241064d66b63e93198368e457","5b101ee78e9344f1b656cfb4f0f64ddd","4a765ece33c643189314046dd323eec4","36d5c8aef5f4471ca77c17faf2ff9054","07e09661df804695acd4840af4ce08b3","bb6a9bbb66f443c2a29d7d89cf5a8841","c37d1aabcb8d49d081d7e1ba25838495","67acf558c5a54026b3da07cf5ce01352"]},"outputId":"0d1a3a9e-53c4-401b-b973-22e6c9fe405b"},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e1cc33894ed4aba8832ab8e7e5ec0c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/475 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc07047b857848efb01463e365024f4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d75dc707837e4e70b9c9f4bcd154784b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0465d4b56c124e6c8b5020bbd908bd01"}},"metadata":{}}]},{"cell_type":"code","source":["# ====================================================\n","# Define max_len\n","# ====================================================\n","#lengths = []\n","#tk0 = tqdm(train['inputs'].fillna(\"\").values, total=len(train))\n","#for text in tk0:\n","#    length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n","#    lengths.append(length)\n","#CFG.max_len = max(lengths) + 6 # cls & sep & sep\n","#LOGGER.info(f\"max_len: {CFG.max_len}\")"],"metadata":{"id":"DWuZSetq_jYN","executionInfo":{"status":"ok","timestamp":1663520133246,"user_tz":-540,"elapsed":13,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Dataset\n","# ====================================================\n","def prepare_input(cfg, text):\n","    inputs = cfg.tokenizer(text,\n","                           add_special_tokens=True,\n","                           max_length=cfg.max_len,\n","                           padding=\"max_length\",\n","                           return_offsets_mapping=False,\n","                           truncation=True)\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","    return inputs\n","\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.inputs = df['inputs'].values\n","        self.labels = df[cfg.target_cols].values\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, item):\n","        inputs = prepare_input(self.cfg, self.inputs[item])\n","        label = torch.tensor(self.labels[item], dtype=torch.float)\n","        return inputs, label\n","\n","#collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)"],"metadata":{"id":"krrca9D6-sja","executionInfo":{"status":"ok","timestamp":1663520133247,"user_tz":-540,"elapsed":13,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Model\n","# ====================================================\n","class MeanPooling(nn.Module):\n","    def __init__(self):\n","        super(MeanPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        mean_embeddings = sum_embeddings / sum_mask\n","        return mean_embeddings\n","\n","class MaxPooling(nn.Module):\n","    def __init__(self):\n","        super(MaxPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        embeddings = last_hidden_state.clone()\n","        embeddings[input_mask_expanded == 0] = -1e4\n","        max_embeddings, _ = torch.max(embeddings, dim=1)\n","        return max_embeddings\n","    \n","\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","            self.config.hidden_dropout = 0.\n","            self.config.hidden_dropout_prob = 0.\n","            self.config.attention_dropout = 0.\n","            self.config.attention_probs_dropout_prob = 0.\n","            LOGGER.info(self.config)\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel(self.config)\n","        if self.cfg.gradient_checkpointing:\n","            self.model.gradient_checkpointing_enable()\n","\n","        # Freezing\n","        if cfg.freezing:\n","            # freezing embeddings and first 2 layers of encoder\n","            freeze((self.model).embeddings)\n","            freeze((self.model).encoder.layer[:2])\n","            cfg.after_freezed_parameters = filter(lambda parameter: parameter.requires_grad, (self.model).parameters())\n","\n","        self.pool = MeanPooling()\n","        self.fc = nn.Linear(self.config.hidden_size, cfg.target_size)\n","        self._init_weights(self.fc)\n","        \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","        \n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs[0]\n","        feature = self.pool(last_hidden_states, inputs['attention_mask'])\n","        return feature\n","\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","        output = self.fc(feature)\n","        return output"],"metadata":{"id":"5c5Z1XB3_HrT","executionInfo":{"status":"ok","timestamp":1663520133247,"user_tz":-540,"elapsed":13,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["class AWP:\n","    def __init__(\n","        self,\n","        model,\n","        optimizer,\n","        criterion,\n","        adv_param=\"weight\",\n","        adv_lr=1e-4,\n","        adv_eps=1e-2,\n","        start_epoch=0,\n","        adv_step=1,\n","        device=\"cpu\",\n","    ):\n","        self.model = model\n","        self.optimizer = optimizer\n","        self.criterion = criterion\n","        self.adv_param = adv_param\n","        self.adv_lr = adv_lr\n","        self.adv_eps = adv_eps\n","        self.start_epoch = start_epoch\n","        self.adv_step = adv_step\n","        self.backup = {}\n","        self.backup_eps = {}\n","        self.device = device\n","\n","    def attack_backward(self, inputs, label):\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            self.save()\n","            self.attack_step() # モデルを近傍の悪い方へ改変\n","            y_preds = self.model(inputs)\n","            adv_loss = self.criterion(\n","                y_preds.view(-1, 1), label.view(-1, 1))\n","            mask = (label.view(-1, 1) != -1)\n","            adv_loss = torch.masked_select(adv_loss, mask).mean()\n","            self.optimizer.zero_grad()\n","        return adv_loss\n","        \n","        \n","\n","    def attack_step(self):\n","        e = 1e-6\n","        for name, param in self.model.named_parameters():\n","            if param.requires_grad and param.grad is not None and self.adv_param in name:\n","                norm1 = torch.norm(param.grad)\n","                norm2 = torch.norm(param.data.detach())\n","                if norm1 != 0 and not torch.isnan(norm1):\n","                    r_at = self.adv_lr * param.grad / (norm1 + e) * (norm2 + e)\n","                    param.data.add_(r_at)\n","                    param.data = torch.min(\n","                        torch.max(param.data, self.backup_eps[name][0]), self.backup_eps[name][1]\n","                    )\n","                # param.data.clamp_(*self.backup_eps[name])\n","\n","    def save(self):\n","        for name, param in self.model.named_parameters():\n","            if param.requires_grad and param.grad is not None and self.adv_param in name:\n","                if name not in self.backup:\n","                    self.backup[name] = param.data.clone()\n","                    grad_eps = self.adv_eps * param.abs().detach()\n","                    self.backup_eps[name] = (\n","                        self.backup[name] - grad_eps,\n","                        self.backup[name] + grad_eps,\n","                    )\n","\n","    def restore(self,):\n","        for name, param in self.model.named_parameters():\n","            if name in self.backup:\n","                param.data = self.backup[name]\n","        self.backup = {}\n","        self.backup_eps = {}"],"metadata":{"id":"SvURRSnUJn6A","executionInfo":{"status":"ok","timestamp":1663520133247,"user_tz":-540,"elapsed":13,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Helper functions\n","# ====================================================\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","\n","def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n","    #if not epoch < CFG.nth_awp_start_epoch:\n","    #    LOGGER.info(f'AWP training with epoch {epoch+1}')\n","    model.train()\n","    #awp = AWP(model=model,\n","    #          optimizer=optimizer,\n","    #          criterion=criterion,\n","    #          adv_eps=0.01, \n","    #          device=device)\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    global_step = 0\n","    #tot_loss = 0\n","    for step, (inputs, labels) in enumerate(train_loader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            y_preds = model(inputs)\n","        loss = criterion(y_preds[:,0].view(-1, 1), labels[:,0].view(-1, 1))\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","        #if CFG.nth_awp_start_epoch <= epoch:\n","        #      loss = awp.attack_backward(inputs, labels)\n","        #      scaler.scale(loss).backward()\n","        #      awp.restore()\n","        #tot_loss += loss.item()\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","            global_step += 1\n","            if CFG.batch_scheduler:\n","                scheduler.step()\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  'Grad: {grad_norm:.4f}  '\n","                  'LR: {lr:.8f}  '\n","                  .format(epoch+1, step, len(train_loader), \n","                          remain=timeSince(start, float(step+1)/len(train_loader)),\n","                          loss=losses,\n","                          grad_norm=grad_norm,\n","                          lr=scheduler.get_lr()[0]))\n","\n","    return losses.avg\n","    #model.train()\n","    #return tot_loss/(step+1)\n","\n","\n","def valid_fn(valid_loader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    preds = []\n","    start = end = time.time()\n","    for step, (inputs, labels) in enumerate(valid_loader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        loss = criterion(y_preds[:,0].view(-1, 1), labels[:,0].view(-1, 1))\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n","            print('EVAL: [{0}/{1}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  .format(step, len(valid_loader),\n","                          loss=losses,\n","                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n","    predictions = np.concatenate(preds)\n","    #predictions = np.concatenate(predictions)\n","    return losses.avg, predictions\n","\n","\n","def inference_fn(test_loader, model, device):\n","    preds = []\n","    model.eval()\n","    model.to(device)\n","    tk0 = tqdm(test_loader, total=len(test_loader))\n","    for inputs in tk0:\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","    predictions = np.concatenate(preds)\n","    return predictions"],"metadata":{"id":"DTVWyY33BVR1","executionInfo":{"status":"ok","timestamp":1663520133247,"user_tz":-540,"elapsed":13,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# train loop\n","# ====================================================\n","def train_loop(folds, fold):\n","    \n","    LOGGER.info(f\"========== fold: {fold} training ==========\")\n","\n","    # ====================================================\n","    # loader\n","    # ====================================================\n","    train_folds = folds[folds['kfold'] != fold].reset_index(drop=True)\n","    valid_folds = folds[folds['kfold'] == fold].reset_index(drop=True)\n","    valid_labels = valid_folds[CFG.target_cols].values\n","    \n","    train_dataset = TrainDataset(CFG, train_folds)\n","    valid_dataset = TrainDataset(CFG, valid_folds)\n","\n","\n","    train_loader = DataLoader(train_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=True,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset,\n","                              batch_size=CFG.batch_size*2,\n","                              shuffle=False,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","\n","    # ====================================================\n","    # model & optimizer\n","    # ====================================================\n","    model = CustomModel(CFG, config_path=None, pretrained=True)\n","    torch.save(model.config, OUTPUT_MODEL_DIR+'config.pth')\n","    model.to(device)\n","    \n","    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n","        param_optimizer = list(model.named_parameters())\n","        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","        optimizer_parameters = [\n","            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': weight_decay},\n","            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': 0.0},\n","            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n","             'lr': decoder_lr, 'weight_decay': 0.0}\n","        ]\n","        return optimizer_parameters\n","\n","    optimizer_parameters = get_optimizer_params(model,\n","                                                encoder_lr=CFG.encoder_lr, \n","                                                decoder_lr=CFG.decoder_lr,\n","                                                weight_decay=CFG.weight_decay)\n","    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n","    \n","    # ====================================================\n","    # scheduler\n","    # ====================================================\n","    def get_scheduler(cfg, optimizer, num_train_steps):\n","        if cfg.scheduler == 'linear':\n","            scheduler = get_linear_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n","            )\n","        elif cfg.scheduler == 'cosine':\n","            scheduler = get_cosine_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","            )\n","        return scheduler\n","    \n","    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n","    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n","\n","    # ====================================================\n","    # loop\n","    # ====================================================\n","    #criterion = nn.SmoothL1Loss(reduction='mean')\n","    criterion = nn.BCEWithLogitsLoss(reduction=\"mean\")\n","    \n","    best_score = 0\n","\n","    for epoch in range(CFG.epochs):\n","\n","        start_time = time.time()\n","\n","        # train\n","        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n","\n","        # eval\n","        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n","        \n","        # scoring\n","        score = get_score(valid_labels, predictions)\n","\n","        elapsed = time.time() - start_time\n","\n","        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n","        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n","\n","        \n","        if best_score < score:\n","            best_score = score\n","            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","            torch.save({'model': model.state_dict(),\n","                        'predictions': predictions},\n","                        OUTPUT_MODEL_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n","\n","    predictions = torch.load(OUTPUT_MODEL_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", \n","                             map_location=torch.device('cpu'))['predictions']\n","    valid_folds[[f\"pred_{c}\" for c in CFG.target_cols]] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    \n","    return valid_folds"],"metadata":{"id":"teu8DfxeCm1h","executionInfo":{"status":"ok","timestamp":1663520133248,"user_tz":-540,"elapsed":13,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["if __name__ == '__main__':\n","    \n","    def get_result(oof_df):\n","        labels = oof_df[CFG.target_cols].values\n","        preds = oof_df[[f\"pred_{c}\" for c in CFG.target_cols]].values\n","        score = get_score(labels, preds)\n","        LOGGER.info(f'Score: {score:<.4f}')\n","    \n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for fold in range(CFG.n_fold):\n","            if fold in CFG.trn_fold:\n","                _oof_df = train_loop(train, fold)\n","                oof_df = pd.concat([oof_df, _oof_df])\n","                LOGGER.info(f\"========== fold: {fold} result ==========\")\n","                get_result(_oof_df)\n","        oof_df = oof_df.reset_index(drop=True)\n","        LOGGER.info(f\"========== CV ==========\")\n","        get_result(oof_df)\n","        oof_df.to_pickle(OUTPUT_MODEL_DIR+'oof_df.pkl')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["523ea0cb9dd6425aaad0ef50686aa6d5","d706b7bb574c439080aa7241417ce80b","78d68a817c4e4febaed2d566841cf85b","8e4a45d47ee84a2eb3744718d0d9d5cc","41a8b04188684f58b9881d90fa2e4ea3","8c7b30b1324a4519b45eee681350c539","b074afa665b14c35808b827d74dad8cd","19bac2e918f048a88cb4ee2166b720d3","051619b784c040a8993dce17c1595161","36a3c618029148bcab0b9a6c6a40ad16","d1d57740207947339fd4abb32320f4ab"]},"id":"6Fnuz2nICrxj","outputId":"1ff3e483-258d-4286-e97e-cf29128f3a00","executionInfo":{"status":"ok","timestamp":1663554162242,"user_tz":-540,"elapsed":6280788,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":20,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["========== fold: 0 training ==========\n","INFO:__main__:========== fold: 0 training ==========\n","DebertaConfig {\n","  \"_name_or_path\": \"microsoft/deberta-xlarge\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 48,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"c2p\",\n","    \"p2c\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"relative_attention\": true,\n","  \"transformers_version\": \"4.22.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 50265\n","}\n","\n","INFO:__main__:DebertaConfig {\n","  \"_name_or_path\": \"microsoft/deberta-xlarge\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 48,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"c2p\",\n","    \"p2c\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"relative_attention\": true,\n","  \"transformers_version\": \"4.22.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 50265\n","}\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"523ea0cb9dd6425aaad0ef50686aa6d5","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.52G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-xlarge were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [1][0/458] Elapsed 0m 10s (remain 76m 32s) Loss: 0.7270(0.7270) Grad: 184315.5625  LR: 0.00002000  \n","Epoch: [1][100/458] Elapsed 7m 16s (remain 25m 44s) Loss: 0.3150(0.6078) Grad: 143577.4531  LR: 0.00001985  \n","Epoch: [1][200/458] Elapsed 14m 23s (remain 18m 24s) Loss: 0.5850(0.5755) Grad: 52424.3594  LR: 0.00001941  \n","Epoch: [1][300/458] Elapsed 21m 30s (remain 11m 13s) Loss: 0.6735(0.5633) Grad: 106835.1172  LR: 0.00001870  \n","Epoch: [1][400/458] Elapsed 28m 37s (remain 4m 4s) Loss: 0.4791(0.5484) Grad: 57667.9766  LR: 0.00001773  \n","Epoch: [1][457/458] Elapsed 32m 40s (remain 0m 0s) Loss: 0.2384(0.5403) Grad: 57756.5586  LR: 0.00001708  \n","EVAL: [0/77] Elapsed 0m 3s (remain 4m 47s) Loss: 0.4236(0.4236) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.5403  avg_val_loss: 0.4668  time: 2119s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.5403  avg_val_loss: 0.4668  time: 2119s\n","Epoch 1 - Score: 0.7824\n","INFO:__main__:Epoch 1 - Score: 0.7824\n","Epoch 1 - Save Best Score: 0.7824 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7824 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["EVAL: [76/77] Elapsed 2m 38s (remain 0m 0s) Loss: 0.3699(0.4668) \n","Epoch: [2][0/458] Elapsed 0m 5s (remain 40m 15s) Loss: 0.2172(0.2172) Grad: 231558.1875  LR: 0.00001707  \n","Epoch: [2][100/458] Elapsed 7m 11s (remain 25m 26s) Loss: 0.2061(0.3517) Grad: 158439.7656  LR: 0.00001576  \n","Epoch: [2][200/458] Elapsed 14m 18s (remain 18m 17s) Loss: 0.3614(0.3440) Grad: 234356.2031  LR: 0.00001428  \n","Epoch: [2][300/458] Elapsed 21m 25s (remain 11m 10s) Loss: 0.3408(0.3449) Grad: 90706.3594  LR: 0.00001268  \n","Epoch: [2][400/458] Elapsed 28m 31s (remain 4m 3s) Loss: 0.6167(0.3426) Grad: 217543.8594  LR: 0.00001100  \n","Epoch: [2][457/458] Elapsed 32m 35s (remain 0m 0s) Loss: 0.3598(0.3427) Grad: 123691.8359  LR: 0.00001003  \n","EVAL: [0/77] Elapsed 0m 3s (remain 4m 53s) Loss: 0.6741(0.6741) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.3427  avg_val_loss: 0.4902  time: 2114s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.3427  avg_val_loss: 0.4902  time: 2114s\n","Epoch 2 - Score: 0.7624\n","INFO:__main__:Epoch 2 - Score: 0.7624\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["EVAL: [76/77] Elapsed 2m 38s (remain 0m 0s) Loss: 0.4608(0.4902) \n","Epoch: [3][0/458] Elapsed 0m 5s (remain 41m 6s) Loss: 0.1319(0.1319) Grad: 194525.9219  LR: 0.00001001  \n","Epoch: [3][100/458] Elapsed 7m 11s (remain 25m 26s) Loss: 0.4382(0.2075) Grad: 332438.0938  LR: 0.00000830  \n","Epoch: [3][200/458] Elapsed 14m 18s (remain 18m 17s) Loss: 0.0990(0.2010) Grad: 376104.9062  LR: 0.00000665  \n","Epoch: [3][300/458] Elapsed 21m 24s (remain 11m 10s) Loss: 0.6112(0.1965) Grad: 439881.3438  LR: 0.00000509  \n","Epoch: [3][400/458] Elapsed 28m 30s (remain 4m 3s) Loss: 0.5614(0.2152) Grad: 122100.2734  LR: 0.00000368  \n","Epoch: [3][457/458] Elapsed 32m 33s (remain 0m 0s) Loss: 0.0290(0.2121) Grad: 16506.5586  LR: 0.00000296  \n","EVAL: [0/77] Elapsed 0m 3s (remain 4m 46s) Loss: 0.8832(0.8832) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.2121  avg_val_loss: 0.6533  time: 2112s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.2121  avg_val_loss: 0.6533  time: 2112s\n","Epoch 3 - Score: 0.7867\n","INFO:__main__:Epoch 3 - Score: 0.7867\n","Epoch 3 - Save Best Score: 0.7867 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.7867 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["EVAL: [76/77] Elapsed 2m 38s (remain 0m 0s) Loss: 0.5017(0.6533) \n","Epoch: [4][0/458] Elapsed 0m 5s (remain 39m 56s) Loss: 0.0589(0.0589) Grad: 283136.9062  LR: 0.00000294  \n","Epoch: [4][100/458] Elapsed 7m 11s (remain 25m 25s) Loss: 0.0039(0.1125) Grad: 22019.8066  LR: 0.00000184  \n","Epoch: [4][200/458] Elapsed 14m 17s (remain 18m 16s) Loss: 0.0007(0.1053) Grad: 1091.5098  LR: 0.00000097  \n","Epoch: [4][300/458] Elapsed 21m 23s (remain 11m 9s) Loss: 0.0002(0.1073) Grad: 369.6402  LR: 0.00000037  \n","Epoch: [4][400/458] Elapsed 28m 29s (remain 4m 2s) Loss: 0.0155(0.1088) Grad: 168185.9375  LR: 0.00000005  \n","Epoch: [4][457/458] Elapsed 32m 31s (remain 0m 0s) Loss: 0.4749(0.1070) Grad: 707360.7500  LR: 0.00000000  \n","EVAL: [0/77] Elapsed 0m 3s (remain 4m 52s) Loss: 1.2475(1.2475) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.1070  avg_val_loss: 1.0806  time: 2110s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.1070  avg_val_loss: 1.0806  time: 2110s\n","Epoch 4 - Score: 0.8112\n","INFO:__main__:Epoch 4 - Score: 0.8112\n","Epoch 4 - Save Best Score: 0.8112 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.8112 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["EVAL: [76/77] Elapsed 2m 38s (remain 0m 0s) Loss: 1.0686(1.0806) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["========== fold: 0 result ==========\n","INFO:__main__:========== fold: 0 result ==========\n","Score: 0.8112\n","INFO:__main__:Score: 0.8112\n","========== fold: 1 training ==========\n","INFO:__main__:========== fold: 1 training ==========\n","DebertaConfig {\n","  \"_name_or_path\": \"microsoft/deberta-xlarge\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 48,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"c2p\",\n","    \"p2c\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"relative_attention\": true,\n","  \"transformers_version\": \"4.22.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 50265\n","}\n","\n","INFO:__main__:DebertaConfig {\n","  \"_name_or_path\": \"microsoft/deberta-xlarge\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 48,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"c2p\",\n","    \"p2c\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"relative_attention\": true,\n","  \"transformers_version\": \"4.22.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 50265\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-xlarge were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [1][0/458] Elapsed 0m 4s (remain 35m 19s) Loss: 0.6852(0.6852) Grad: 266759.5938  LR: 0.00002000  \n","Epoch: [1][100/458] Elapsed 7m 11s (remain 25m 23s) Loss: 0.5136(0.6171) Grad: 47824.9883  LR: 0.00001985  \n","Epoch: [1][200/458] Elapsed 14m 17s (remain 18m 16s) Loss: 0.4177(0.5894) Grad: 20576.7559  LR: 0.00001941  \n","Epoch: [1][300/458] Elapsed 21m 24s (remain 11m 9s) Loss: 0.5814(0.5635) Grad: 64417.2305  LR: 0.00001870  \n","Epoch: [1][400/458] Elapsed 28m 30s (remain 4m 3s) Loss: 0.5539(0.5520) Grad: 19883.1055  LR: 0.00001773  \n","Epoch: [1][457/458] Elapsed 32m 33s (remain 0m 0s) Loss: 0.3952(0.5478) Grad: 18720.3691  LR: 0.00001708  \n","EVAL: [0/77] Elapsed 0m 2s (remain 3m 1s) Loss: 0.6191(0.6191) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.5478  avg_val_loss: 0.4722  time: 2111s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.5478  avg_val_loss: 0.4722  time: 2111s\n","Epoch 1 - Score: 0.7575\n","INFO:__main__:Epoch 1 - Score: 0.7575\n","Epoch 1 - Save Best Score: 0.7575 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7575 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["EVAL: [76/77] Elapsed 2m 36s (remain 0m 0s) Loss: 0.5803(0.4722) \n","Epoch: [2][0/458] Elapsed 0m 4s (remain 34m 40s) Loss: 0.3476(0.3476) Grad: 394185.4375  LR: 0.00001707  \n","Epoch: [2][100/458] Elapsed 7m 11s (remain 25m 23s) Loss: 0.3673(0.4155) Grad: 105448.2969  LR: 0.00001576  \n","Epoch: [2][200/458] Elapsed 14m 17s (remain 18m 16s) Loss: 0.4218(0.3908) Grad: 165154.2969  LR: 0.00001428  \n","Epoch: [2][300/458] Elapsed 21m 24s (remain 11m 9s) Loss: 0.1320(0.3789) Grad: 82915.4375  LR: 0.00001268  \n","Epoch: [2][400/458] Elapsed 28m 30s (remain 4m 3s) Loss: 0.1096(0.3643) Grad: 142307.0625  LR: 0.00001100  \n","Epoch: [2][457/458] Elapsed 32m 34s (remain 0m 0s) Loss: 0.7291(0.3594) Grad: 306406.7812  LR: 0.00001003  \n","EVAL: [0/77] Elapsed 0m 2s (remain 2m 56s) Loss: 0.3763(0.3763) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.3594  avg_val_loss: 0.4044  time: 2111s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.3594  avg_val_loss: 0.4044  time: 2111s\n","Epoch 2 - Score: 0.8167\n","INFO:__main__:Epoch 2 - Score: 0.8167\n","Epoch 2 - Save Best Score: 0.8167 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.8167 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["EVAL: [76/77] Elapsed 2m 36s (remain 0m 0s) Loss: 0.4424(0.4044) \n","Epoch: [3][0/458] Elapsed 0m 4s (remain 34m 42s) Loss: 0.3219(0.3219) Grad: 309005.1250  LR: 0.00001001  \n","Epoch: [3][100/458] Elapsed 7m 11s (remain 25m 23s) Loss: 0.1720(0.2642) Grad: 181445.3438  LR: 0.00000830  \n","Epoch: [3][200/458] Elapsed 14m 17s (remain 18m 16s) Loss: 0.5844(0.2627) Grad: 187501.7344  LR: 0.00000665  \n","Epoch: [3][300/458] Elapsed 21m 24s (remain 11m 9s) Loss: 0.1875(0.2575) Grad: 1003032.5625  LR: 0.00000509  \n","Epoch: [3][400/458] Elapsed 28m 30s (remain 4m 3s) Loss: 0.0277(0.2570) Grad: 30679.4844  LR: 0.00000368  \n","Epoch: [3][457/458] Elapsed 32m 34s (remain 0m 0s) Loss: 0.1150(0.2533) Grad: 125969.8828  LR: 0.00000296  \n","EVAL: [0/77] Elapsed 0m 2s (remain 3m 0s) Loss: 0.4849(0.4849) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.2533  avg_val_loss: 0.4895  time: 2111s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.2533  avg_val_loss: 0.4895  time: 2111s\n","Epoch 3 - Score: 0.8160\n","INFO:__main__:Epoch 3 - Score: 0.8160\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["EVAL: [76/77] Elapsed 2m 36s (remain 0m 0s) Loss: 0.4156(0.4895) \n","Epoch: [4][0/458] Elapsed 0m 4s (remain 34m 50s) Loss: 0.0843(0.0843) Grad: 344874.4375  LR: 0.00000294  \n","Epoch: [4][100/458] Elapsed 7m 11s (remain 25m 23s) Loss: 0.3897(0.1177) Grad: 282401.1562  LR: 0.00000184  \n","Epoch: [4][200/458] Elapsed 14m 17s (remain 18m 16s) Loss: 0.0114(0.1157) Grad: 16310.4346  LR: 0.00000097  \n","Epoch: [4][300/458] Elapsed 21m 23s (remain 11m 9s) Loss: 0.2203(0.1230) Grad: 369838.3125  LR: 0.00000037  \n","Epoch: [4][400/458] Elapsed 28m 30s (remain 4m 3s) Loss: 0.1237(0.1296) Grad: 157474.0000  LR: 0.00000005  \n","Epoch: [4][457/458] Elapsed 32m 33s (remain 0m 0s) Loss: 0.1455(0.1285) Grad: 173936.2812  LR: 0.00000000  \n","EVAL: [0/77] Elapsed 0m 2s (remain 2m 59s) Loss: 0.6655(0.6655) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.1285  avg_val_loss: 0.6647  time: 2110s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.1285  avg_val_loss: 0.6647  time: 2110s\n","Epoch 4 - Score: 0.8108\n","INFO:__main__:Epoch 4 - Score: 0.8108\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["EVAL: [76/77] Elapsed 2m 36s (remain 0m 0s) Loss: 0.4985(0.6647) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["========== fold: 1 result ==========\n","INFO:__main__:========== fold: 1 result ==========\n","Score: 0.8167\n","INFO:__main__:Score: 0.8167\n","========== fold: 2 training ==========\n","INFO:__main__:========== fold: 2 training ==========\n","DebertaConfig {\n","  \"_name_or_path\": \"microsoft/deberta-xlarge\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 48,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"c2p\",\n","    \"p2c\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"relative_attention\": true,\n","  \"transformers_version\": \"4.22.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 50265\n","}\n","\n","INFO:__main__:DebertaConfig {\n","  \"_name_or_path\": \"microsoft/deberta-xlarge\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 48,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"c2p\",\n","    \"p2c\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"relative_attention\": true,\n","  \"transformers_version\": \"4.22.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 50265\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-xlarge were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [1][0/458] Elapsed 0m 4s (remain 35m 15s) Loss: 0.6753(0.6753) Grad: 167231.5000  LR: 0.00002000  \n","Epoch: [1][100/458] Elapsed 7m 10s (remain 25m 23s) Loss: 0.5964(0.6216) Grad: 45367.3438  LR: 0.00001985  \n","Epoch: [1][200/458] Elapsed 14m 17s (remain 18m 16s) Loss: 0.5687(0.5943) Grad: 35478.8125  LR: 0.00001941  \n","Epoch: [1][300/458] Elapsed 21m 24s (remain 11m 9s) Loss: 0.1647(0.5693) Grad: 11765.6719  LR: 0.00001870  \n","Epoch: [1][400/458] Elapsed 28m 30s (remain 4m 3s) Loss: 0.5804(0.5529) Grad: 15284.2100  LR: 0.00001773  \n","Epoch: [1][457/458] Elapsed 32m 34s (remain 0m 0s) Loss: 0.4007(0.5404) Grad: 10559.1025  LR: 0.00001708  \n","EVAL: [0/77] Elapsed 0m 2s (remain 3m 6s) Loss: 0.5496(0.5496) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.5404  avg_val_loss: 0.4507  time: 2111s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.5404  avg_val_loss: 0.4507  time: 2111s\n","Epoch 1 - Score: 0.7892\n","INFO:__main__:Epoch 1 - Score: 0.7892\n","Epoch 1 - Save Best Score: 0.7892 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7892 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["EVAL: [76/77] Elapsed 2m 36s (remain 0m 0s) Loss: 0.3126(0.4507) \n","Epoch: [2][0/458] Elapsed 0m 4s (remain 35m 5s) Loss: 0.2900(0.2900) Grad: 356925.0938  LR: 0.00001707  \n","Epoch: [2][100/458] Elapsed 7m 11s (remain 25m 23s) Loss: 0.3906(0.3902) Grad: 144580.7812  LR: 0.00001576  \n","Epoch: [2][200/458] Elapsed 14m 17s (remain 18m 16s) Loss: 0.3178(0.3599) Grad: 79869.8047  LR: 0.00001428  \n","Epoch: [2][300/458] Elapsed 21m 24s (remain 11m 9s) Loss: 0.0501(0.3460) Grad: 47992.7266  LR: 0.00001268  \n","Epoch: [2][400/458] Elapsed 28m 31s (remain 4m 3s) Loss: 0.2806(0.3432) Grad: 66678.1016  LR: 0.00001100  \n","Epoch: [2][457/458] Elapsed 32m 34s (remain 0m 0s) Loss: 0.2022(0.3343) Grad: 90733.2109  LR: 0.00001003  \n","EVAL: [0/77] Elapsed 0m 2s (remain 3m 2s) Loss: 0.5036(0.5036) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.3343  avg_val_loss: 0.4373  time: 2111s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.3343  avg_val_loss: 0.4373  time: 2111s\n","Epoch 2 - Score: 0.8098\n","INFO:__main__:Epoch 2 - Score: 0.8098\n","Epoch 2 - Save Best Score: 0.8098 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.8098 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["EVAL: [76/77] Elapsed 2m 36s (remain 0m 0s) Loss: 0.3381(0.4373) \n","Epoch: [3][0/458] Elapsed 0m 4s (remain 35m 4s) Loss: 0.2494(0.2494) Grad: 268238.6250  LR: 0.00001001  \n","Epoch: [3][100/458] Elapsed 7m 11s (remain 25m 24s) Loss: 0.4584(0.2045) Grad: 592793.8125  LR: 0.00000830  \n","Epoch: [3][200/458] Elapsed 14m 17s (remain 18m 16s) Loss: 0.3565(0.1969) Grad: 307580.7812  LR: 0.00000665  \n","Epoch: [3][300/458] Elapsed 21m 24s (remain 11m 9s) Loss: 0.2059(0.2036) Grad: 108296.7734  LR: 0.00000509  \n","Epoch: [3][400/458] Elapsed 28m 30s (remain 4m 3s) Loss: 0.4748(0.2015) Grad: 159220.0156  LR: 0.00000368  \n","Epoch: [3][457/458] Elapsed 32m 33s (remain 0m 0s) Loss: 0.1351(0.2027) Grad: 60926.7578  LR: 0.00000296  \n","EVAL: [0/77] Elapsed 0m 2s (remain 3m 2s) Loss: 0.6025(0.6025) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.2027  avg_val_loss: 0.5034  time: 2111s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.2027  avg_val_loss: 0.5034  time: 2111s\n","Epoch 3 - Score: 0.8103\n","INFO:__main__:Epoch 3 - Score: 0.8103\n","Epoch 3 - Save Best Score: 0.8103 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.8103 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["EVAL: [76/77] Elapsed 2m 36s (remain 0m 0s) Loss: 0.5119(0.5034) \n","Epoch: [4][0/458] Elapsed 0m 4s (remain 35m 8s) Loss: 0.1787(0.1787) Grad: 445711.9375  LR: 0.00000294  \n","Epoch: [4][100/458] Elapsed 7m 11s (remain 25m 23s) Loss: 0.0436(0.1268) Grad: 124108.1719  LR: 0.00000184  \n","Epoch: [4][200/458] Elapsed 14m 17s (remain 18m 16s) Loss: 0.0131(0.1212) Grad: 74799.0938  LR: 0.00000097  \n","Epoch: [4][300/458] Elapsed 21m 23s (remain 11m 9s) Loss: 0.0428(0.1187) Grad: 87403.0391  LR: 0.00000037  \n","Epoch: [4][400/458] Elapsed 28m 30s (remain 4m 3s) Loss: 0.3104(0.1183) Grad: 111428.1797  LR: 0.00000005  \n","Epoch: [4][457/458] Elapsed 32m 33s (remain 0m 0s) Loss: 0.0268(0.1171) Grad: 42494.1172  LR: 0.00000000  \n","EVAL: [0/77] Elapsed 0m 2s (remain 2m 59s) Loss: 0.7557(0.7557) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.1171  avg_val_loss: 0.6438  time: 2110s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.1171  avg_val_loss: 0.6438  time: 2110s\n","Epoch 4 - Score: 0.8128\n","INFO:__main__:Epoch 4 - Score: 0.8128\n","Epoch 4 - Save Best Score: 0.8128 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.8128 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["EVAL: [76/77] Elapsed 2m 36s (remain 0m 0s) Loss: 0.5831(0.6438) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["========== fold: 2 result ==========\n","INFO:__main__:========== fold: 2 result ==========\n","Score: 0.8128\n","INFO:__main__:Score: 0.8128\n","========== fold: 3 training ==========\n","INFO:__main__:========== fold: 3 training ==========\n","DebertaConfig {\n","  \"_name_or_path\": \"microsoft/deberta-xlarge\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 48,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"c2p\",\n","    \"p2c\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"relative_attention\": true,\n","  \"transformers_version\": \"4.22.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 50265\n","}\n","\n","INFO:__main__:DebertaConfig {\n","  \"_name_or_path\": \"microsoft/deberta-xlarge\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 48,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"c2p\",\n","    \"p2c\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"relative_attention\": true,\n","  \"transformers_version\": \"4.22.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 50265\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-xlarge were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [1][0/459] Elapsed 0m 4s (remain 34m 56s) Loss: 0.7016(0.7016) Grad: inf  LR: 0.00002000  \n","Epoch: [1][100/459] Elapsed 7m 11s (remain 25m 28s) Loss: 0.5959(0.6141) Grad: 127661.0547  LR: 0.00001985  \n","Epoch: [1][200/459] Elapsed 14m 17s (remain 18m 21s) Loss: 0.7932(0.5859) Grad: 814979.9375  LR: 0.00001941  \n","Epoch: [1][300/459] Elapsed 21m 24s (remain 11m 14s) Loss: 0.3849(0.5557) Grad: 104805.8516  LR: 0.00001870  \n","Epoch: [1][400/459] Elapsed 28m 31s (remain 4m 7s) Loss: 0.6273(0.5409) Grad: 88175.2344  LR: 0.00001774  \n","Epoch: [1][458/459] Elapsed 32m 38s (remain 0m 0s) Loss: 0.4812(0.5322) Grad: 117063.8984  LR: 0.00001707  \n","EVAL: [0/77] Elapsed 0m 2s (remain 3m 9s) Loss: 0.4298(0.4298) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.5322  avg_val_loss: 0.4491  time: 2116s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.5322  avg_val_loss: 0.4491  time: 2116s\n","Epoch 1 - Score: 0.8033\n","INFO:__main__:Epoch 1 - Score: 0.8033\n","Epoch 1 - Save Best Score: 0.8033 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.8033 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 2m 36s (remain 0m 0s) Loss: 0.4358(0.4491) \n","Epoch: [2][0/459] Elapsed 0m 4s (remain 34m 45s) Loss: 0.5506(0.5506) Grad: 732430.2500  LR: 0.00001706  \n","Epoch: [2][100/459] Elapsed 7m 10s (remain 25m 27s) Loss: 0.1950(0.4647) Grad: 46177.4805  LR: 0.00001575  \n","Epoch: [2][200/459] Elapsed 14m 17s (remain 18m 20s) Loss: 0.2656(0.4425) Grad: 31817.9844  LR: 0.00001427  \n","Epoch: [2][300/459] Elapsed 21m 24s (remain 11m 14s) Loss: 0.3548(0.4243) Grad: 49412.8633  LR: 0.00001267  \n","Epoch: [2][400/459] Elapsed 28m 30s (remain 4m 7s) Loss: 0.2069(0.4197) Grad: 18564.1836  LR: 0.00001099  \n","Epoch: [2][458/459] Elapsed 32m 38s (remain 0m 0s) Loss: 0.3809(0.4144) Grad: 47380.8750  LR: 0.00001000  \n","EVAL: [0/77] Elapsed 0m 2s (remain 3m 0s) Loss: 0.4393(0.4393) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.4144  avg_val_loss: 0.3928  time: 2115s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.4144  avg_val_loss: 0.3928  time: 2115s\n","Epoch 2 - Score: 0.7998\n","INFO:__main__:Epoch 2 - Score: 0.7998\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 2m 36s (remain 0m 0s) Loss: 0.3809(0.3928) \n","Epoch: [3][0/459] Elapsed 0m 4s (remain 34m 50s) Loss: 0.2950(0.2950) Grad: 333489.3125  LR: 0.00000998  \n","Epoch: [3][100/459] Elapsed 7m 10s (remain 25m 27s) Loss: 0.2275(0.2410) Grad: 145092.3906  LR: 0.00000828  \n","Epoch: [3][200/459] Elapsed 14m 17s (remain 18m 20s) Loss: 0.2000(0.2195) Grad: 228362.6719  LR: 0.00000663  \n","Epoch: [3][300/459] Elapsed 21m 23s (remain 11m 13s) Loss: 0.5857(0.2130) Grad: 184980.4062  LR: 0.00000507  \n","Epoch: [3][400/459] Elapsed 28m 29s (remain 4m 7s) Loss: 0.0568(0.2007) Grad: 152506.1094  LR: 0.00000366  \n","Epoch: [3][458/459] Elapsed 32m 37s (remain 0m 0s) Loss: 0.2415(0.2030) Grad: 598882.6875  LR: 0.00000293  \n","EVAL: [0/77] Elapsed 0m 2s (remain 3m 0s) Loss: 0.5140(0.5140) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.2030  avg_val_loss: 0.5188  time: 2114s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.2030  avg_val_loss: 0.5188  time: 2114s\n","Epoch 3 - Score: 0.8122\n","INFO:__main__:Epoch 3 - Score: 0.8122\n","Epoch 3 - Save Best Score: 0.8122 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.8122 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 2m 36s (remain 0m 0s) Loss: 0.3416(0.5188) \n","Epoch: [4][0/459] Elapsed 0m 4s (remain 34m 39s) Loss: 0.2145(0.2145) Grad: 238407.3438  LR: 0.00000292  \n","Epoch: [4][100/459] Elapsed 7m 10s (remain 25m 27s) Loss: 0.0163(0.0814) Grad: 287840.9062  LR: 0.00000182  \n","Epoch: [4][200/459] Elapsed 14m 17s (remain 18m 20s) Loss: 0.3311(0.0755) Grad: 194484.8750  LR: 0.00000096  \n","Epoch: [4][300/459] Elapsed 21m 23s (remain 11m 13s) Loss: 0.0014(0.0748) Grad: 5665.9561  LR: 0.00000036  \n","Epoch: [4][400/459] Elapsed 28m 29s (remain 4m 7s) Loss: 0.0338(0.0778) Grad: 222543.9688  LR: 0.00000005  \n","Epoch: [4][458/459] Elapsed 32m 36s (remain 0m 0s) Loss: 0.0227(0.0819) Grad: 49278.4922  LR: 0.00000000  \n","EVAL: [0/77] Elapsed 0m 2s (remain 2m 59s) Loss: 1.0098(1.0098) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.0819  avg_val_loss: 0.9167  time: 2113s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0819  avg_val_loss: 0.9167  time: 2113s\n","Epoch 4 - Score: 0.8145\n","INFO:__main__:Epoch 4 - Score: 0.8145\n","Epoch 4 - Save Best Score: 0.8145 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.8145 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [76/77] Elapsed 2m 36s (remain 0m 0s) Loss: 0.7552(0.9167) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 3 result ==========\n","INFO:__main__:========== fold: 3 result ==========\n","Score: 0.8145\n","INFO:__main__:Score: 0.8145\n","========== CV ==========\n","INFO:__main__:========== CV ==========\n","Score: 0.8138\n","INFO:__main__:Score: 0.8138\n"]}]},{"cell_type":"code","source":["A = pd.read_pickle(OUTPUT_MODEL_DIR+'oof_df.pkl')\n","A.head()"],"metadata":{"id":"0cHG0TUuknq7","executionInfo":{"status":"ok","timestamp":1663554162593,"user_tz":-540,"elapsed":352,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"colab":{"base_uri":"https://localhost:8080/","height":493},"outputId":"25c795ab-97b9-4161-d1eb-2cfd2acf7fc3"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["            id         goal country  duration  category1        category2  \\\n","0  train_00002    2001-3000      US        38          0  performance art   \n","1  train_00006    2001-3000      CA        30         10  classical music   \n","2  train_00016    3001-4000      GB        30          9              web   \n","3  train_00017  11001-12000      US        30          7           drinks   \n","4  train_00018  12001-13000      US        28          9              web   \n","\n","                                        html_content  state goal_max goal_min  \\\n","0  I want to perform this piece guerilla style, o...      0   2001.0   3000.0   \n","1  The Crimson String Quartet (CSQ) is returning ...      1   2001.0   3000.0   \n","2  I am interested in setting up a small news web...      0   3001.0   4000.0   \n","3  Why Schenk-Atwood?Our neighborhood has just ab...      1  11001.0  12000.0   \n","4  Mega Visions app has been approved on all majo...      1  12001.0  13000.0   \n","\n","   goal_median                                             inputs  kfold  \\\n","0         2500  2500 [SEP] 38 [SEP] US [SEP] performance art [...      0   \n","1         2500  2500 [SEP] 30 [SEP] CA [SEP] classical music [...      0   \n","2         3500  3500 [SEP] 30 [SEP] GB [SEP] web [SEP] I am in...      0   \n","3        11500  11500 [SEP] 30 [SEP] US [SEP] drinks [SEP] Why...      0   \n","4        12500  12500 [SEP] 28 [SEP] US [SEP] web [SEP] Mega V...      0   \n","\n","   pred_state  pred_category1  \n","0    0.595614        0.456510  \n","1    0.995650        0.393131  \n","2    0.000063        0.606561  \n","3    0.962903        0.468430  \n","4    0.000751        0.560514  "],"text/html":["\n","  <div id=\"df-93d68a9b-9261-4804-a890-11ecf7c7c325\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>goal</th>\n","      <th>country</th>\n","      <th>duration</th>\n","      <th>category1</th>\n","      <th>category2</th>\n","      <th>html_content</th>\n","      <th>state</th>\n","      <th>goal_max</th>\n","      <th>goal_min</th>\n","      <th>goal_median</th>\n","      <th>inputs</th>\n","      <th>kfold</th>\n","      <th>pred_state</th>\n","      <th>pred_category1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>train_00002</td>\n","      <td>2001-3000</td>\n","      <td>US</td>\n","      <td>38</td>\n","      <td>0</td>\n","      <td>performance art</td>\n","      <td>I want to perform this piece guerilla style, o...</td>\n","      <td>0</td>\n","      <td>2001.0</td>\n","      <td>3000.0</td>\n","      <td>2500</td>\n","      <td>2500 [SEP] 38 [SEP] US [SEP] performance art [...</td>\n","      <td>0</td>\n","      <td>0.595614</td>\n","      <td>0.456510</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>train_00006</td>\n","      <td>2001-3000</td>\n","      <td>CA</td>\n","      <td>30</td>\n","      <td>10</td>\n","      <td>classical music</td>\n","      <td>The Crimson String Quartet (CSQ) is returning ...</td>\n","      <td>1</td>\n","      <td>2001.0</td>\n","      <td>3000.0</td>\n","      <td>2500</td>\n","      <td>2500 [SEP] 30 [SEP] CA [SEP] classical music [...</td>\n","      <td>0</td>\n","      <td>0.995650</td>\n","      <td>0.393131</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>train_00016</td>\n","      <td>3001-4000</td>\n","      <td>GB</td>\n","      <td>30</td>\n","      <td>9</td>\n","      <td>web</td>\n","      <td>I am interested in setting up a small news web...</td>\n","      <td>0</td>\n","      <td>3001.0</td>\n","      <td>4000.0</td>\n","      <td>3500</td>\n","      <td>3500 [SEP] 30 [SEP] GB [SEP] web [SEP] I am in...</td>\n","      <td>0</td>\n","      <td>0.000063</td>\n","      <td>0.606561</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>train_00017</td>\n","      <td>11001-12000</td>\n","      <td>US</td>\n","      <td>30</td>\n","      <td>7</td>\n","      <td>drinks</td>\n","      <td>Why Schenk-Atwood?Our neighborhood has just ab...</td>\n","      <td>1</td>\n","      <td>11001.0</td>\n","      <td>12000.0</td>\n","      <td>11500</td>\n","      <td>11500 [SEP] 30 [SEP] US [SEP] drinks [SEP] Why...</td>\n","      <td>0</td>\n","      <td>0.962903</td>\n","      <td>0.468430</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>train_00018</td>\n","      <td>12001-13000</td>\n","      <td>US</td>\n","      <td>28</td>\n","      <td>9</td>\n","      <td>web</td>\n","      <td>Mega Visions app has been approved on all majo...</td>\n","      <td>1</td>\n","      <td>12001.0</td>\n","      <td>13000.0</td>\n","      <td>12500</td>\n","      <td>12500 [SEP] 28 [SEP] US [SEP] web [SEP] Mega V...</td>\n","      <td>0</td>\n","      <td>0.000751</td>\n","      <td>0.560514</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93d68a9b-9261-4804-a890-11ecf7c7c325')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-93d68a9b-9261-4804-a890-11ecf7c7c325 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-93d68a9b-9261-4804-a890-11ecf7c7c325');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":[],"metadata":{"id":"3vgWEX03TZjr","executionInfo":{"status":"ok","timestamp":1663558583957,"user_tz":-540,"elapsed":281,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":21,"outputs":[]}]}